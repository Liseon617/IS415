{
  "hash": "8321a81d4d3b70d1894fbfcba524d903",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In Class exercise 6\"\nauthor: \"Brian Lim\"\ndate: \"September 23, 2024\"\ndate-modified: \"last-modified\"\ncategories:\n  - Analysis\n  - R\n  - sf\n  - tidyverse\nformat: html\neditor: visual\nexecute: \n  eval: true\n  echo: true\n  warning: false\n  freeze: true  \n  cache: true\n---\n\n\n## **6.0 Notes:**\n\n-   Local statistics\n\n    -   Identifying outliers based on a certain attribute of its neighbours\n\n    -   Tobler's First law of Geography: Everything is related to everything else, but near things are more related than distant things\n\n-   Geospatial Dependency\n\n    -   Spatial dependence is the spatial relationship of variable values (for themes defined over space, such as rainfall) or locations (for themes defined as objects, such as cities).\n\n-   Spatial Autocorrelation\n\n    -   Spatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable.\n    -   Inferred after the rejections of the null hypothesis\n    -   Positive autocorrelation: A big lump, congregation of points on the grid\n    -   Negative autocorrelation: More outliers can be seen, checkers board pattern seen\n\n-   Local Indicator of Spatial Analysis (LISA)\n\n    -   A subset of localised geospatial statistics methods.\n\n    -   Any spatial statistics that satisfies the following two requirements (Anselin, L. 1995):\n\n        -   the LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation;\n\n        -   the sum of LISAs for all observations is proportional to a global indicator of spatial association.\n\n    -   Identify outliers or clusters\n\n## **6.1 Installing and Loading the R packages**\n\nFor the purpose of this study, five R packages will be used. They are:\n\n-   [**sf**](https://r-spatial.github.io/sf/), a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\n\n-   [**spatstat**](https://spatstat.org/), a comprehensive package for point pattern analysis. We'll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\n\n-   [**sfdep**](https://cran.r-project.org/web/packages/sfdep/), an R package that acts as an interface to 'spdep' to integrate with 'sf' objects and the 'tidyverse'.\n\n-   [**tidyverse**](https://cran.r-project.org/web/packages/tidyverse/index.html), a collection of R packages designed for data science. It includes packages like `dplyr` for data manipulation, `ggplot2` for data visualization, and `tidyr` for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(sf, sfdep, tmap, tidyverse)\n```\n:::\n\n\n### **6.1.1 Import shapefile into r environment**\n\nThe code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_sf <- st_read(dsn = \"data/In-class_Ex05/geospatial\", \n                 layer = \"Hunan\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nReading layer `Hunan' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\In-class_Ex05\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n```\n\n\n:::\n:::\n\n\n### **6.1.2 Import csv file into r environment**\n\nNext, we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R dataframe class.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan2012 <- read_csv(\"data/In-class_Ex05/aspatial/Hunan_2012.csv\")\nhunan2012\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   <chr>     <chr>     <dbl>    <dbl>  <dbl>   <dbl>   <dbl>  <dbl> <dbl>  <dbl>\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan <dbl>, NIPCR <dbl>, Bed <dbl>, Emp <dbl>,\n#   EmpR <dbl>, EmpRT <dbl>, Pri_Stu <dbl>, Sec_Stu <dbl>, Household <dbl>,\n#   Household_R <dbl>, NOIP <dbl>, Pop_R <dbl>, RSCG <dbl>, Pop_T <dbl>,\n#   Agri <dbl>, Service <dbl>, Disp_Inc <dbl>, RORP <dbl>, ROREmp <dbl>\n```\n\n\n:::\n:::\n\n\n### **6.1.3 Performing relational join**\n\nThe code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* data frame. This is performed by using *left_join()* of **dplyr** package.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhunan_GDPPC <- left_join(hunan_sf,hunan2012)%>%\n  select(1:4, 7, 15)\n```\n:::\n\n\n### **6.2 Plotting the chloropleth map**\n\n#### **Deriving Queen's contiguity weights: sfdep methods**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_q <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n```\n:::\n\n\n#### **Computing Global Moran's I**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmoranI <- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\nglimpse(moranI)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n```\n\n\n:::\n:::\n\n\nIn general, Moran's I test will be performed instead of just computing the Moran's statistics. With sfdep package, Moran's I test can be performed by using `global_moran_test()` as shown in the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMoran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n```\n\n\n:::\n:::\n\n\n`Expectation: -0.011494253` negative value suggests clustering\n\np-value will determine whether the null hypothesis is rejected or not. Not rejecting the null hypothesis would result in the statistic derived from Moran I to be unusable\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglobal_moran_perm(wm_q$GDPPC, wm_q$nb, wm_q$wt, nsim=99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tMonte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value < 2.2e-16\nalternative hypothesis: two.sided\n```\n\n\n:::\n:::\n\n\nAs seen from the moran I statistic, even thought the p-value is far smaller, the statistic is stable, approaching `0.30075`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n```\n:::\n\n\nIt is always good to `set.seed()` before performing simulation, to ensure reproducibility.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa <- wm_q %>%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %>%\n  unnest(local_moran)\n```\n:::\n\n\nTo ensure consistency, stay with 1 type of p-value **either p_ii, p_ii_sim or p_folded_sim**\n\nMean useful if the data follows the trend of standard distribution and Median would be useful if skewness (close to 0) is detected - Note that row consistency also applies to mean or median - Examine the current trend of the skewness to make these decisions\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nmap2 <- tm_shape(lisa) + \n  tm_fill(\"p_ii\", breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"p-value of local Moran's I\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n#### Visualising LISA map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlisa_sig <- lisa %>%\n  filter(p_ii < 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nLISA map is categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low\n\n#### Computing local Gi\\* statistics\n\nAs usual we will need to derive a spatial weight matrix before we can compute local Gi\\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwm_idw <- hunan_GDPPC %>%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n```\n:::\n\n\nCalculating the local Gi\\* by using the code chunk below:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA <- wm_idw %>% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %>%\n  unnest(local_Gi)\nHCSA\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     <dbl> <fct>    <dbl>      <dbl>   <dbl>   <dbl> <dbl>        <dbl>    <dbl>\n 1  0.0416 Low     0.0114 0.00000721  0.0376 9.70e-1  0.8          0.4     0.901\n 2 -0.333  Low     0.0111 0.00000553 -0.299  7.65e-1  0.92         0.46    0.941\n 3  0.281  High    0.0121 0.00000832  0.0405 9.68e-1  0.8          0.4     0.912\n 4  0.411  High    0.0117 0.00000943  0.298  7.66e-1  0.68         0.34    1.09 \n 5  0.387  High    0.0113 0.00000869  0.415  6.78e-1  0.5          0.25    0.992\n 6 -0.368  High    0.0116 0.00000605 -0.498  6.18e-1  0.76         0.38    1.15 \n 7  3.56   High    0.0149 0.00000745  2.67   7.56e-3  0.04         0.02    0.950\n 8  2.52   High    0.0135 0.00000482  1.74   8.17e-2  0.14         0.07    0.434\n 9  4.56   High    0.0144 0.00000514  3.77   1.64e-4  0.02         0.01    0.634\n10  1.16   Low     0.0108 0.00000479  1.45   1.48e-1  0.18         0.09    0.476\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis <dbl>, nb <nb>, wts <list>, NAME_2 <chr>,\n#   ID_3 <int>, NAME_3 <chr>, ENGTYPE_3 <chr>, County <chr>, GDPPC <dbl>,\n#   geometry <POLYGON [°]>\n```\n\n\n:::\n:::\n\n\n#### Visualising hot spot and cold spot areas\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"true\" code-summary=\"Show the code\"}\ntmap_mode(\"plot\")\nmap1 <- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 <- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nHCSA_sig <- HCSA %>% \n  filter(p_sim < 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.4)\n```\n\n::: {.cell-output-display}\n![](In-class_Ex06_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}