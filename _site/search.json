[
  {
    "objectID": "Take-home_ex/Take-home_ex01.html",
    "href": "Take-home_ex/Take-home_ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nIn this study, I will apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#exercise-overview",
    "href": "Take-home_ex/Take-home_ex01.html#exercise-overview",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nIn this study, I will apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#data-acquisition",
    "href": "Take-home_ex/Take-home_ex01.html#data-acquisition",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nThe data sets that we will be using are the following: - Armed conflict data of Myanmar between 2021-2024. This data can be downloaded from Armed Conflict Location & Event Data ACLED, an independent, impartial, international non-profit organization collecting data on violent conflict and protest in all countries and territories in the world, should be used. - The shapefile of the Myanmar State and Region Boundaries with Sub-regions. This data can be downloaded from Myanmar Information Management Unit, MIMU."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#getting-started",
    "href": "Take-home_ex/Take-home_ex01.html#getting-started",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nraster, a package for reading, writing, manipulating, and modeling gridded spatial data (rasters). We will use it to convert image outputs generated by spatstat into raster format.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nRColorBrewer for creating nice looking color palettes especially for thematic maps.\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, RColorBrewer, lubridate, ggplot2, parallel)"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#importing-data-into-r",
    "href": "Take-home_ex/Take-home_ex01.html#importing-data-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.4 Importing Data into R",
    "text": "1.4 Importing Data into R\nNext, we will import the ACLED-Southeast_Asia-Myanmar(1).csv file into the R environment and save it into an R dataframe called acled_sf. The task can be performed using the read_csv() function from the readr package, as shown below:\n\nacled_sf &lt;- read_csv(\"data/ACLED-Southeast_Asia-Myanmar(1).csv\") %&gt;% \n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs= 32647)%&gt;%\n  mutate(event_date = dmy(event_date)) %&gt;%\n  mutate(quarter = paste0(year, \" Q\", quarter(event_date)))\n\n\n\n\n\n\n\nNotes\n\n\n\nWe used the mutate() function to ensure that the event_data column is in the right format of dmy(), while also creating a quarter column to represent the current  that the row belongs to\n\n\nWe can check the validity of the imported dataset, ensuring that it is in the right format with the st_crs() and summary() function:\n\nst_crs(acled_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nsummary(acled_sf)\n\n event_id_cnty        event_date              year      time_precision \n Length:42608       Min.   :2021-01-01   Min.   :2021   Min.   :1.000  \n Class :character   1st Qu.:2022-01-10   1st Qu.:2022   1st Qu.:1.000  \n Mode  :character   Median :2022-10-13   Median :2022   Median :1.000  \n                    Mean   :2022-10-29   Mean   :2022   Mean   :1.053  \n                    3rd Qu.:2023-08-29   3rd Qu.:2023   3rd Qu.:1.000  \n                    Max.   :2024-06-30   Max.   :2024   Max.   :3.000  \n disorder_type       event_type        sub_event_type        actor1         \n Length:42608       Length:42608       Length:42608       Length:42608      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n assoc_actor_1          inter1         actor2          assoc_actor_2     \n Length:42608       Min.   :1.000   Length:42608       Length:42608      \n Class :character   1st Qu.:1.000   Class :character   Class :character  \n Mode  :character   Median :1.000   Mode  :character   Mode  :character  \n                    Mean   :1.947                                        \n                    3rd Qu.:3.000                                        \n                    Max.   :8.000                                        \n     inter2       interaction    civilian_targeting      iso     \n Min.   :0.000   Min.   :10.00   Length:42608       Min.   :104  \n 1st Qu.:1.000   1st Qu.:13.00   Class :character   1st Qu.:104  \n Median :3.000   Median :17.00   Mode  :character   Median :104  \n Mean   :3.597   Mean   :18.86                      Mean   :104  \n 3rd Qu.:7.000   3rd Qu.:17.00                      3rd Qu.:104  \n Max.   :8.000   Max.   :80.00                      Max.   :104  \n    region            country             admin1             admin2         \n Length:42608       Length:42608       Length:42608       Length:42608      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    admin3            location         geo_precision      source         \n Length:42608       Length:42608       Min.   :1.000   Length:42608      \n Class :character   Class :character   1st Qu.:1.000   Class :character  \n Mode  :character   Mode  :character   Median :1.000   Mode  :character  \n                                       Mean   :1.495                     \n                                       3rd Qu.:2.000                     \n                                       Max.   :3.000                     \n source_scale          notes             fatalities         tags          \n Length:42608       Length:42608       Min.   :  0.00   Length:42608      \n Class :character   Class :character   1st Qu.:  0.00   Class :character  \n Mode  :character   Mode  :character   Median :  0.00   Mode  :character  \n                                       Mean   :  1.27                     \n                                       3rd Qu.:  1.00                     \n                                       Max.   :201.00                     \n   timestamp                  geometry       quarter         \n Min.   :1.611e+09   POINT        :42608   Length:42608      \n 1st Qu.:1.702e+09   epsg:32647   :    0   Class :character  \n Median :1.714e+09   +proj=utm ...:    0   Mode  :character  \n Mean   :1.702e+09                                           \n 3rd Qu.:1.719e+09                                           \n Max.   :1.726e+09                                           \n\n\nWe then import the boundaries and regions of Myanmar using the st_read() function to import the mmr_polbnda2_adm1_250k_mimu_1 shapefile into R as a simple feature data frame named regions_sf:\n\nregions_sf &lt;- st_read(dsn = \"data/myanmar\", \n                layer = \"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\myanmar' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nregions_sf &lt;- st_transform(regions_sf, crs = 32647)\n\n\n\n\n\n\n\nNotes\n\n\n\nThe acled_sf and regions_sf data are being transformed to EPSG 32647, which corresponds to UTM Zone 47N. This CSR is fine for Myanmar. This consistency also ensures that the UTM zone transformation makes sense for the study area, and prevents any distortion in KDE results.\n\n\nAfter importing the boundary and region data, we can check that what was imported is correct by checking the summary and plotting the views:\n\nSummaryDetailed Regional View\n\n\n\nsummary(regions_sf)\n\n    OBJECTID          ST              ST_PCODE            ST_RG          \n Min.   : 1.00   Length:18          Length:18          Length:18         \n 1st Qu.: 5.25   Class :character   Class :character   Class :character  \n Median : 9.50   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 9.50                                                           \n 3rd Qu.:13.75                                                           \n Max.   :18.00                                                           \n    ST_MMR             PCode_V             geometry \n Length:18          Min.   :9.4   MULTIPOLYGON :18  \n Class :character   1st Qu.:9.4   epsg:32647   : 0  \n Mode  :character   Median :9.4   +proj=utm ...: 0  \n                    Mean   :9.4                     \n                    3rd Qu.:9.4                     \n                    Max.   :9.4                     \n\n\n\n\n\nnum_colors &lt;- length(unique(regions_sf$ST))\ncolors &lt;- brewer.pal(n = num_colors, name = \"Set1\")\n\ntm_shape(regions_sf) +\n  tm_polygons(col = \"ST\", palette = colors) +\n  tm_text(\"ST\", size = 0.9, col = \"black\", bg.color = \"white\", \n          just = c(\"center\", \"center\"), xmod = 0, ymod = 0) +\n  tm_layout(main.title = \"Region and Boundaries in Myanmar\",\n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_legend(title = \"Sub-regions\")\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.1 Focused Event Types\nFor the study, we focus on the following four event types from the ACLED dataset for Myanmar:\n\nBattles\nStrategic developments\nViolence against civilians\nExplosion/Remote violence\n\nThe study period spans from January 2021 to June 2024, broken down into quarterly intervals. We aim to visualize and analyze the spatial distribution of these armed conflict events in Myanmar.\nThe following function is used to generate spatial point pattern plots for each event type within the defined region throughout the stated time span:\n\n# Function to create combined events object with owin object\nplot_event_by_quarter &lt;- function(event_data, event_name) {\n  quarter_data_ppp &lt;- as.ppp(st_coordinates(event_data), st_bbox(event_data))\n  regions_owin &lt;- as.owin(regions_sf)\n  quarter_data_regions_ppp = quarter_data_ppp[regions_owin]\n  \n  plot(quarter_data_regions_ppp,\n     main = paste(\"Events in Myanmar -\", event_name, \"(2021 - 2024)\"),\n     xlab = \"Longitude\", ylab = \"Latitude\")\n}\n\n\n# Get a list of unique quarters\nevents &lt;- unique(acled_sf$event_type)\n\n# Loop over each quarter and generate the plot\nmap(events, ~ {\n  event_data &lt;- acled_sf %&gt;% filter(event_type == .x)\n  plot_event_by_quarter(event_data, .x)\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #00000033\n\n[[2]]\nSymbol map with constant values\ncols: #00000033\n\n[[3]]\nSymbol map with constant values\ncols: #00000033\n\n[[4]]\nSymbol map with constant values\ncols: #00000033"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#determining-kde-layer",
    "href": "Take-home_ex/Take-home_ex01.html#determining-kde-layer",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.5 Determining KDE Layer",
    "text": "1.5 Determining KDE Layer\n\n1.5.1 Choosing Sample Dataset\nIn this section, we focus on determining the appropriate Kernel Density Estimate (KDE) layer format for analyzing the spatial distribution of events across different quarters and event types. KDE is a fundamental tool for identifying patterns of spatial clustering and dispersion, providing a smooth surface that highlights areas of high and low event concentration. The selection of an appropriate bandwidth is crucial, as it influences the level of detail and accuracy in the density estimate. By standardizing the KDE layer format, we aim to ensure consistency and comparability throughout the analysis, particularly using the Violence against civilians event type as a reference for refining our approach.\n\nExample &lt;- \"Violence against civilians\"\nacled_2021 &lt;- acled_sf %&gt;%\n  filter(event_type == Example & year == 2021)\nyear_data &lt;- as_Spatial(acled_2021)\nregions &lt;- as_Spatial(regions_sf)\n\nyear_data_sp &lt;- as(year_data, \"SpatialPoints\")\nregions_sp &lt;- as(regions, \"SpatialPolygons\")\n\nyear_data_ppp &lt;- as.ppp(st_coordinates(acled_2021), st_bbox(acled_2021))\nyear_data_ppp\n\nPlanar point pattern: 1877 points\nwindow: rectangle = [-191409.1, 591875.9] x [1132472.1, 3042960.3] units\n\n\n\nany(duplicated(year_data_ppp))\n\n[1] TRUE\n\n\nAs there are duplicate points, we will use jittering to slightly displace the points so that overlapping points are separated on the map. The jitter parameter will slightly move each point by a small, random amount. This can help to visually separate points that are in the same space.\n\nyear_data_ppp_jit &lt;- rjitter(year_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nany(duplicated(year_data_ppp_jit))\n\n[1] FALSE\n\n\n\n\n1.5.2 Creating Owin Object\nTo confine analysis to a geographical area, convert the SpatialPolygon object to an owin object of spatstat:\n\nregions_owin &lt;- as.owin(regions_sf)\n\nyear_data_regions_ppp = year_data_ppp_jit[regions_owin]\n\n\nplot(year_data_regions_ppp)\n\n\n\n\n\n\n\n\nDue to the size of Myanmar, rescaling would need to be done:\n\nyear_data_regions_ppp.km &lt;- rescale.ppp(year_data_regions_ppp, 50000, \"km\")\n\n\n\n1.5.3 Working With Different Automatic Bandwidth Methods\nThe density() function from the spatstat package computes the kernel density estimate for a given set of spatial point events, providing insights into the spatial distribution of those events.\n\nbw.diggle(): This method selects the bandwidth (σ) by minimizing the mean-square error, as defined by Diggle (1985). The mean-square error measures the average squared difference between the estimated and actual values, aiming to reduce errors in the density estimate.\nbw.CvL(): Cronie and van Lieshout’s method selects the bandwidth by minimizing the discrepancy between the area of the observation window and the sum of reciprocal estimated intensity values at the event points. It balances the observed points and the space they occupy, capturing the underlying point process effectively.\nbw.scott(): Scott’s rule, a fast and computationally efficient method, calculates the bandwidth proportional to \\((n^{-\\frac{1}{d+4}})\\), where (n) is the number of points and (d) the spatial dimensions. It typically produces a larger bandwidth and is ideal for detecting gradual trends.\nbw.ppl(): This method selects the bandwidth through likelihood cross-validation, maximizing the point process likelihood to provide the best-fitting model for the observed data, particularly when the goal is to optimize the likelihood of the given event distribution.\n\n\nbw_CvL &lt;- bw.CvL(year_data_regions_ppp.km)\nbw_CvL\n\n   sigma \n1.350743 \n\n\n\nbw_scott &lt;- bw.scott(year_data_regions_ppp.km)\nbw_scott\n\n  sigma.x   sigma.y \n0.6961121 1.8270270 \n\n\n\nbw_ppl &lt;- bw.ppl(year_data_regions_ppp.km)\nbw_ppl\n\n    sigma \n0.1733351 \n\n\n\nbw_diggle &lt;- bw.diggle(year_data_regions_ppp.km)\nbw_diggle\n\n     sigma \n0.01829073 \n\n\n\nkde_diggle &lt;- density(year_data_regions_ppp.km, bw_diggle)\nkde_CvL &lt;- density(year_data_regions_ppp.km, bw_CvL)\nkde_scott &lt;- density(year_data_regions_ppp.km, bw_scott)\nkde_ppl &lt;- density(year_data_regions_ppp.km, bw_ppl)\n\npar(mar = c(2, 2, 2, 2),mfrow = c(2,2))\nplot(kde_diggle, main = \"kde_diggle\")\nplot(kde_CvL, main = \"kde_CvL\")\nplot(kde_scott, main = \"kde_scott\")\nplot(kde_ppl, main = \"kde_ppl\")\n\n\n\n\n\n\n\n\n\npar(mar = c(2,2,2,2),mfrow = c(2,2))\nhist(kde_diggle, main = \"kde_diggle\")\nhist(kde_CvL, main = \"kde_CvL\")\nhist(kde_scott, main = \"kde_scott\")\nhist(kde_ppl, main = \"kde_ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nBandwidth Selection Comparison for KDE:\n\nkde_diggle: The sharp peak at the beginning indicates that the Diggle method for bandwidth selection has identified a concentrated cluster of points in the initial bin. The remaining bins show little to no concentration, suggesting a significant level of spatial clustering in one specific area within the observation window. This method may highlight a localized, high-intensity clustering effect.\nkde_CvL: The left-skewed, more balanced distribution suggests that the CvL method is identifying a broader range of spatial concentrations. However, the smaller bin sizes smooth out finer details, which could mask important aspects of the point pattern. This method provides a more generalized view of the distribution but at the cost of losing granular insights.\nkde_scott: The wider range of values and the absence of a sharp peak, compared to kde_diggle, indicates that the Scott method is capturing both highly dense clusters and moderately concentrated areas. This makes it more suitable for capturing variations in spatial concentration across different regions.\nkde_ppl: Similar to the Diggle method, kde_ppl shows a sharp peak, suggesting the presence of a high concentration of points in a specific region. This points to a localized cluster, but with a similar potential risk of missing broader patterns in the dataset.\n\n\n\n\ndse_diggle &lt;- density(year_data_regions_ppp.km, bw_diggle, se=TRUE)$SE\ndse_CvL &lt;- density(year_data_regions_ppp.km, bw_CvL, se=TRUE)$SE\ndse_scott &lt;- density(year_data_regions_ppp.km, bw_scott, se=TRUE)$SE\ndse_ppl &lt;- density(year_data_regions_ppp.km, bw_ppl, se=TRUE)$SE\n\n\npar(mar = c(2,2,2,2),mfrow = c(2,2))\nplot(dse_diggle,main = \"standard error_diggle\")\nplot(dse_CvL,main = \"standard error_CvL\")\nplot(dse_scott,main = \"standard error_scott\")\nplot(dse_ppl,main = \"standard error_ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nConsideration of Standard Error:\nWhile the standard error (SE) of the density estimate provides valuable insight into the uncertainty associated with each density estimate, it is not the primary focus of this analysis. The shape of the density estimate, rather than its absolute value, is more critical when analyzing spatial patterns. Consequently, the SE was not used as a key criterion for bandwidth selection in this analysis.\nConsideration of Standard Error: While the standard error (SE) of the density estimate provides valuable insight into the uncertainty associated with each density estimate, it is not the primary focus of this analysis. The shape of the density estimate, rather than its absolute value, is more critical when analyzing spatial patterns. Consequently, the SE was not used as a key criterion for bandwidth selection in this analysis.\n\n\n\n\n1.5.4 Final Bandwidth Selection\nUpon the exploration of various fixed bandwidth selection methods for computing KDE vales, and subsequent plotting of the respective KDE estimates, their distributions and associated standard errors, we will now select the KDE bandwidth to be used in our analysis.\nWe landed on the bw_scott method for further analysis. This is because:\n\nbw_scott method provides a pair of bandwidth values for each coordinate axis. This allows it to capture the different levels of spatial clustering in each direction more accurately.\nbw_scott method capture the balance between bias and variance the best among all methods. If the bandwidth is too small, the estimate may be too skewed (high variance). The distribution histograms of KDE layers using bw_diggle and bw_ppl tend to indicate such nature. On the other hand, if the bandwidth is too large, the estimate may be over smoothed, missing crucial elements of the point pattern (high bias). This is what we observed in the distribution histogram of KDE layer using bw_CvL.\n\nSince we have chosen to use bw_scott method, now we will plot the KDE layer using this method for further analysis.\n\n1.5.4.1 Working With Different Kernel Methods\nBeyond the Gaussian kernel, three other kernels can be used to compute KDE: - Epanechnikov - Quartic - Disc\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nUpon comparing the outputs of different kernel functions (Gaussian, Epanechnikov, Quartic, Disc), we observed that the resulting density estimates were very similar across all kernels. Given the minimal variation, the choice of kernel is not critical for this particular analysis.\nWe opted for the Gaussian kernel as it is widely used in kernel density estimation and tends to produce smooth, continuous estimates. Its flexibility in capturing both sharp peaks and gradual trends makes it a reasonable default choice, especially when the differences between kernels are negligible, as seen here.\n\n\n\nkde_fixed_scott &lt;- density(year_data_regions_ppp.km, bw_scott)\nplot(kde_fixed_scott,main = \"Fixed bandwidth KDE (Using bw_scott)\")\ncontour(kde_fixed_scott, add=TRUE)\n\n\n\n\n\n\n\n\nHowever, upon visual inspection, there are signs of a certain degree of over-smoothing when directly applying the bandwidth provided by the bw_scott method. While automatic bandwidth selection methods offer a useful starting point, further fine-tuning is often necessary to ensure the accuracy of the KDE plot.\nTo address the over-smoothing, we will apply a “rule of thumb” adjustment by dividing the bandwidth value by 2. This reduction in bandwidth size will help minimize the over-smoothing effect and enhance the precision of the spatial point pattern analysis.\n\nkde_year_data_regions_fixed_scott &lt;- density(year_data_regions_ppp.km, bw_scott/2)\nkde_year_data_regions_adaptive &lt;- adaptive.density(year_data_regions_ppp.km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_year_data_regions_fixed_scott, main = \"Fixed Bandwidth (bw_scott)\")\nplot(kde_year_data_regions_adaptive, main = \"Adaptive Bandwidth\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nAfter comparing the two approaches for kernel density estimation, Fixed Bandwidth using bw_scott/2 and Adaptive Bandwidth, we observed that the fixed bandwidth method provides a more stable and interpretable result across the observation window. While adaptive bandwidth is designed to adjust to local point densities and capture finer details, it can sometimes introduce unnecessary complexity and overfit the density estimate, especially in areas with sparse data.\nGiven the goals of our analysis, which emphasize consistency and smoothness over high local sensitivity, the Fixed Bandwidth approach strikes a better balance between capturing spatial trends and avoiding over-complication.\n\n\n\n\n\nYear 2021\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_SD_quarter_data_regions_ppp , 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2022\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2023\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2024\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Violence against civilians\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04.html",
    "title": "In Class exercise 4",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#overview",
    "href": "In-class_Ex/In-class_Ex04.html#overview",
    "title": "In Class exercise 4",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex04.html#learning-outcome",
    "title": "In Class exercise 4",
    "section": "4.1 Learning Outcome",
    "text": "4.1 Learning Outcome\n\n4.1.1 The research questions\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\n4.1.2 The data\nFor the purpose of this exercise, two data sets are used, they are:\n\nforestfires, a csv file provides locations of forest fire detected from the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor data. The data are downloaded from Fire Information for Resource Management System. For the purpose of this exercise, only forest fires within Kepulauan Bangka Belitung will be used.\nKepulauan_Bangka_Belitung, an ESRI shapefile showing the sub-district (i.e. kelurahan) boundary of Kepulauan Bangka Belitung. The data set was downloaded from Indonesia Geospatial portal. The original data covers the whole Indonesia. For the purpose of this exercise, only sub-districts within Kepulauan Bangka Belitung are extracted."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex04.html#installing-and-loading-the-r-packages",
    "title": "In Class exercise 4",
    "section": "4.2 Installing and Loading the R packages",
    "text": "4.2 Installing and Loading the R packages\nFor the purpose of this study, five R packages will be used. They are:\n\nrgdal for importing geospatial data in GIS file format such as shapefile into R and save them as Spatial*DataFrame,\nmaptools for converting Spatial* object into ppp object,\nraster for handling raster data in R,\nsparr provides functions to estimate fixed and adaptive kernel-smooth spatial relative risk surfaces via the density-ratio method and perform subsequent inferences,\nspatstat for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc., and\ntmap for producing cartographic quality thematic maps.\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#importing-data-into-r",
    "href": "In-class_Ex/In-class_Ex04.html#importing-data-into-r",
    "title": "In Class exercise 4",
    "section": "4.3 Importing data into R",
    "text": "4.3 Importing data into R\n\n4.3.1 Importing and Preparing Forest Fire shapeful\n\nkbb_sf &lt;- st_read(dsn = \"data/In-class_Ex04\", \n                  layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;% # dropping the Z-value\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\In-class_Ex04' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsummary(kbb_sf)\n\n MULTIPOLYGON    epsg:32748 +proj=utm ... \n            1             0             0 \n\n\nFurthermore we create an owin object from the sf data type\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nTo ensure that the output is an owin object\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n4.3.2 Importing and Preparing Forest Fire data\nNext we will import the forest data set into R:\n\nfire_sf &lt;- read_csv(\"data/In-class_Ex04/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), \n           crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nBecause ppp object only accept numerical or character as mark. The code below is used to transform acq_date data type to numeric.\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(\"DayofYear\" = yday(acq_date)) %&gt;%\n  mutate(\"Month_num\" = month(acq_date)) %&gt;%\n  mutate(\"Month_fac\" = month(acq_date, label = TRUE, abbr = FALSE))\n\nsummary(fire_sf)\n\n   brightness         scan           track          acq_date         \n Min.   :300.3   Min.   :1.000   Min.   :1.000   Min.   :2023-01-10  \n 1st Qu.:314.3   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2023-08-01  \n Median :318.7   Median :1.100   Median :1.100   Median :2023-09-15  \n Mean   :320.9   Mean   :1.315   Mean   :1.119   Mean   :2023-09-02  \n 3rd Qu.:324.7   3rd Qu.:1.400   3rd Qu.:1.200   3rd Qu.:2023-10-14  \n Max.   :396.2   Max.   :4.200   Max.   :1.900   Max.   :2023-12-18  \n                                                                     \n    acq_time     satellite          instrument          confidence   \n Min.   : 248   Length:741         Length:741         Min.   :  0.0  \n 1st Qu.: 633   Class :character   Class :character   1st Qu.: 57.0  \n Median : 649   Mode  :character   Mode  :character   Median : 68.0  \n Mean   : 731                                         Mean   : 65.6  \n 3rd Qu.: 659                                         3rd Qu.: 77.0  \n Max.   :1915                                         Max.   :100.0  \n                                                                     \n    version        bright_t31         frp          daynight              type  \n Min.   :61.03   Min.   :274.9   Min.   :  3.0   Length:741         Min.   :0  \n 1st Qu.:61.03   1st Qu.:293.6   1st Qu.:  8.4   Class :character   1st Qu.:0  \n Median :61.03   Median :296.6   Median : 13.2   Mode  :character   Median :0  \n Mean   :61.03   Mean   :296.1   Mean   : 20.1                      Mean   :0  \n 3rd Qu.:61.03   3rd Qu.:299.2   3rd Qu.: 21.8                      3rd Qu.:0  \n Max.   :61.03   Max.   :311.2   Max.   :220.2                      Max.   :0  \n                                                                               \n          geometry     DayofYear       Month_num          Month_fac  \n POINT        :741   Min.   : 10.0   Min.   : 1.000   October  :185  \n epsg:32748   :  0   1st Qu.:213.0   1st Qu.: 8.000   September:146  \n +proj=utm ...:  0   Median :258.0   Median : 9.000   August   :143  \n                     Mean   :245.9   Mean   : 8.579   November : 88  \n                     3rd Qu.:287.0   3rd Qu.:10.000   July     : 79  \n                     Max.   :352.0   Max.   :12.000   June     : 34  \n                                                      (Other)  : 66"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#visualising-the-fire-points",
    "href": "In-class_Ex/In-class_Ex04.html#visualising-the-fire-points",
    "title": "In Class exercise 4",
    "section": "4.4 Visualising the Fire Points",
    "text": "4.4 Visualising the Fire Points\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nWe will then prepare a point symbol map showing the monthly geographic distribution of forest fires in 2023. The map should look similar to the figure below.\n\ntm_shape(kbb_sf)+\n  tm_polygons()+\n  tm_shape(fire_sf)+\n  tm_dots(size = 0.1)+\n  tm_facets(by=\"Month_fac\", free.coords = FALSE, drop.units = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#extracting-forest-fire-by-month",
    "href": "In-class_Ex/In-class_Ex04.html#extracting-forest-fire-by-month",
    "title": "In Class exercise 4",
    "section": "4.5 Extracting forest fire by month",
    "text": "4.5 Extracting forest fire by month\nThe code chunk below is used to remove the unwanted fields from the fire_sf sf data frame. This is because as.ppp() only need the mark field and geometry field from the input sf data frame.\n\nfire_month &lt;- fire_sf %&gt;%\n  select(Month_num)\n\n\n4.5.1 Creating ppp\nThe code chunk below is used to derive a ppp object called fire_month from fire_month sf data frame\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\n\n4.5.2 Creating Owin object\nThe code chunk below is used to combine origin_am_ppp and am_owin_objects into one.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nComputing Spatio-Temporal KDE Next, spattemp.density() of sparr package is used to compute the STKDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\nIn the code chunk below, plot() of R base is used to get the KDE for between July 2023 - December 2023\n\ntims &lt;- c(7, 8, 9, 10, 11, 12)\npar(mfcol=c(2, 3))\nfor(i in tims){\n  plot(st_kde, i, \n       override.par=FALSE,\n       fix.range=TRUE,\n       main=paste(\"KDE at month\", i))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02.html",
    "title": "In Class exercise 2",
    "section": "",
    "text": "For this in-class exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02.html#getting-started",
    "title": "In Class exercise 2",
    "section": "",
    "text": "For this in-class exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "title": "In Class exercise 2",
    "section": "2.1 Working with Master Plan 2014 Subzone Boundary Data",
    "text": "2.1 Working with Master Plan 2014 Subzone Boundary Data\n\nmpsz14_shp &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below demonstrates data conversion from SHP file format to KML file format:\n\nmpsz14_kml &lt;- st_write(mpsz14_shp, \n  \"data/MasterPlan2014SubzoneBoundaryWebKML.kml\",\n  delete_dsn = TRUE)\n\nThe delete_dsn argument relates to the dsn (Data Source Name) to delete original source before writing the new file"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In Class exercise 2",
    "section": "2.2 Working with Master Plan 2019 Subzone Boundary Data",
    "text": "2.2 Working with Master Plan 2019 Subzone Boundary Data\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/MasterPlan2019SubzoneBoundaryWebSHP\", \n                      layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-population-data",
    "title": "In Class exercise 2",
    "section": "2.3 Working with population data",
    "text": "2.3 Working with population data\n\npopdata &lt;- read_csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\n\n2.3.1 Data Preparation\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\nAs seen above, unlike other programming languages, R indexes from ‘1’ instead of ‘0’. The rows begin from [1],[6],[11], etc.\n\n\n2.3.2 Data Wrangling\n\npopdata2023 &lt;- popdata2023 %&gt;%\nmutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\nmutate_at(.vars = vars(PA, SZ),\n          .funs = list(toupper))\n\n\n\n2.3.3 Joining the attribute data and geospatial data\n\nmpsz_2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                       by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp,\n                       by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "In-class_Ex/data/MasterPlan2019SubzoneBoundaryWebSHP/MPSZ-2019.html",
    "href": "In-class_Ex/data/MasterPlan2019SubzoneBoundaryWebSHP/MPSZ-2019.html",
    "title": "Brian’s IS415 Experience",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.html",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, I learn how to to analyze spatial point patterns in R. On top of that I learn to apply first- and second-order analyses to assess the randomness of point distributions, and how to visualize and interpret the spatial concentration of facilities using Kernel Density Estimation (KDE)\nSpatial Point Pattern Analysis involves evaluating the distribution of a set of points on a surface. These points can represent the locations of various events or facilities, such as:\n\nEvents: Crime occurrences, traffic accidents, or disease outbreaks.\nFacilities: Business services like coffee shops, fast food outlets, or essential facilities such as childcare and eldercare centers.\n\nIn this hands-on exercise, we aim to explore the spatial distribution of childcare centers in Singapore using functions from the spatstat package. Specifically, we will address the following questions:\n\nRandomness of Distribution: Are childcare centers in Singapore randomly distributed across the country?\nClusters and Concentrations: If the distribution is not random, where are the areas with higher concentrations of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#exercise-overview",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, I learn how to to analyze spatial point patterns in R. On top of that I learn to apply first- and second-order analyses to assess the randomness of point distributions, and how to visualize and interpret the spatial concentration of facilities using Kernel Density Estimation (KDE)\nSpatial Point Pattern Analysis involves evaluating the distribution of a set of points on a surface. These points can represent the locations of various events or facilities, such as:\n\nEvents: Crime occurrences, traffic accidents, or disease outbreaks.\nFacilities: Business services like coffee shops, fast food outlets, or essential facilities such as childcare and eldercare centers.\n\nIn this hands-on exercise, we aim to explore the spatial distribution of childcare centers in Singapore using functions from the spatstat package. Specifically, we will address the following questions:\n\nRandomness of Distribution: Are childcare centers in Singapore randomly distributed across the country?\nClusters and Concentrations: If the distribution is not random, where are the areas with higher concentrations of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#data-acquisition",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.2 Data Acquisition",
    "text": "3.2 Data Acquisition\nThree data set will be used to answer these question. They are:\n\nCHILDCARE: A point feature dataset containing the location and attribute information of childcare centers in Singapore. This dataset was downloaded from Data.gov.sg and is in GeoJSON format.\nMP14_SUBZONE_WEB_PL: A polygon feature dataset providing information on URA’s 2014 Master Plan Planning Subzone boundaries. This data is in ESRI Shapefile format and was also downloaded from Data.gov.sg.\nCostalOutline: A polygon feature dataset showing the national boundary of Singapore. This dataset is provided by the Singapore Land Authority (SLA) and is in ESRI Shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.3 Getting Started",
    "text": "3.3 Getting Started\nFor this exercise, we will use the following 5 R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nraster, a package for reading, writing, manipulating, and modeling gridded spatial data (rasters). We will use it to convert image outputs generated by spatstat into raster format.\nmaptools, a set of tools for manipulating geographic data, mainly used here to convert spatial objects into the ppp format required by spatstat.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#importing-data-into-r",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.4 Importing Data into R",
    "text": "3.4 Importing Data into R\n\n3.4.1 Importing the spatial data\nIn this section, we’ll use the st_read() function from the sf package to import three geospatial datasets into R:\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe following code chunk changes the referencing system of the newly created simple feature data frames to Singapore national projected coordinate system.\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs = 3414)\n\n\n\n3.4.2 Mapping the geospatial data sets\nAfter verifying that all datasets share the same CRS, it’s useful to visualize them to confirm their spatial alignment.\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons() + \n  tm_shape(childcare_sf) + \n  tm_dots() \n\nIn this code chunk:\n\ntm_shape(mpsz_sf): Sets the base layer to the Singapore subzones.\ntm_polygons(): Plots the subzones with a light blue fill and a dark blue border.\ntm_shape(childcare_sf): Adds an overlay layer for the childcare centers.\ntm_dots(): Plots the childcare centers as red dots with a black border.\n\n\ntmap_mode('view')\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\ntmap_mode('plot')\n\nBy ensuring that all geospatial layers align correctly within the same map extent, we confirm that their CRS and coordinate values are consistent—a critical aspect of any geospatial analysis.\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.5 Geospatial Data wrangling",
    "text": "3.5 Geospatial Data wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n3.5.1 Converting sf data frames to sp’s Spatial* class\nTo work with certain geospatial analysis packages that require data in sp’s Spatial* class, you can convert simple feature (sf) data frames to these classes using the as_Spatial() function from the sf package. Below is the code to convert the sf objects to sp’s Spatial* classes:\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nAfter conversion, you can display the information of these three Spatial* classes as follows:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n3.5.2 Converting the Spatial* class into generic sp format\nTo prepare data for use in the spatstat package, you first need to convert the Spatial* classes into a generic sp format:\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nThen, you can display the properties of these sp objects:\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\n\n3.5.3 Converting the generic sp format into spatstat’s ppp format\nTo analyze spatial point patterns, you need to convert the sp objects into ppp objects, which are used by the spatstat package:\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n3.5.4 Handling duplicated points\nTo determine the existence of duplicate points, we can check for duplicates in your Point Pattern (PPP) object object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of points at each location, we can use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nTo check for the number of locations that have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output show 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\ntmap_mode('plot')\ntmap_mode('view')\n\nThere are three ways to overcome this problem.\n\nThe first and easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. If duplicates are hard to spot, you can apply a slight jitter to the points’ coordinates. Jittering will slightly displace the points so that overlapping points are separated on the map.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\nThe jitter parameter will slightly move each point by a small, random amount. This can help to visually separate points that are in the same space.\n\ntm_shape(childcare) +\n  tm_dots(jitter=0.1, alpha=0.4, size=0.05)\n\n\n\n\n\n\n\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nAfter jittering we can check if there are any duplicate point in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n3.5.5 Creating owin object\nTo confine analysis to a geographical area, convert the SpatialPolygon object to an owin object of spatstat:\n\nsg_owin &lt;- as.owin(sg_sf)\n  \nplot(sg_owin)\n\n\n\n\n\n\n\n\nFurther analysis can be done through the summary() function of Base R:\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n3.5.6 Combining point events object and owin object\nFinally, you can combine the point events with the polygon feature to create a ppp object confined to the Singapore region\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp )\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.6 First-order Spatial Point Patterns Analysis",
    "text": "3.6 First-order Spatial Point Patterns Analysis\nIn this section, we will learn how to perform first-order Spatial Point Pattern Analysis (SPPA) using the spatstat package. The focus will be on:\n\nDeriving Kernel Density Estimation (KDE) layers for visualizing and exploring the intensity of point processes.\nPerforming Confirmatory Spatial Point Patterns Analysis using Nearest Neighbour statistics.\n\n\n3.6.1 Kernel Density Estimation\nKernel Density Estimation (KDE) is a non-parametric way to estimate the intensity (density) of spatial point patterns. It helps in visualizing the spatial distribution of points by smoothing the point pattern to create a continuous surface.\n\n3.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nTo compute the KDE for the spatial point pattern of childcare services in Singapore, we’ll use the density() function from the spatstat package. This function allows for various configurations:\n\nAutomatic Bandwidth Selection: We’ll use  bw.diggle() , a method that selects an optimal bandwidth based on the data. Other methods like  bw.CvL() ,  bw.scott(), or  bw.ppl() can also be used depending on the specific needs of the analysis.\nSmoothing Kernel: The default kernel used is Gaussian. Other options include “Epanechnikov”, “Quartic”, or “Disc”.\nEdge Correction: The intensity estimate is corrected for edge effects to reduce bias, following methods described by Jones (1993) and Diggle (2010).\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nIn this example, the density values range from 0 to 0.000035, which are quite small. This is because the unit of measurement is in meters, making the density values “number of points per square meter”.\nTo check the bandwidth used:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n3.6.1.2 Rescalling KDE values\nThe small density values are due to the measurement unit being in meters. To make the results more interpretable, we can rescale the spatial point pattern from meters to kilometers.\nThe code chunk below rescale the point pattern to kilometers, recompute the KDE with the rescaled data, and plots the rescaled KDE\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp.km, \n                              sigma=bw.diggle, \n                              edge=TRUE, \n                              kernel=\"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe KDE output will look identical to the original, but the density values will now be more comprehensible, reflecting “number of points per square kilometer.”\n\n\n\n3.6.2 Working with different automatic badwidth methods\nDifferent bandwidth selection methods can produce different smoothing results:\n\nbw.CvL(): Cross-validation based on the likelihood.\nbw.scott(): Scott’s rule of thumb.\nbw.ppl(): Likelihood cross-validation proposed by Diggle.\n\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nRecommendation:\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because from their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters.\nBut they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, \n                              sigma=bw.diggle, \n                              edge=TRUE, \n                              kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n3.6.3 Working with different kernel methods\nBeyond the Gaussian kernel, three other kernels can be used to compute KDE:\n\nEpanechnikov\nQuartic\nDisc\n\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.7 Fixed and Adaptive KDE",
    "text": "3.7 Fixed and Adaptive KDE\n\n3.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\nTo compute a KDE layer using a fixed bandwidth of 0.6 km, use the following code:\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\nThis will generate a KDE layer with a consistent bandwidth across the entire study area, useful for uniform spatial point patterns.\n\n\n3.7.2 Computing KDE by using adaptive bandwidth\nAdaptive bandwidth methods are more suitable for spatial point patterns with high variability, such as urban versus rural areas. The adaptive.density() function of spatstat can be used to create a KDE layer that adjusts the bandwidth based on point density:\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nTo compare the outputs of fixed and adaptive bandwidth KDE:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed Bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive Bandwidth\")\n\n\n\n\n\n\n\n\n\n\n3.7.3 Converting KDE output into grid object.\nFor mapping purposes, KDE outputs can be converted into grid and raster formats 1. Converting to Grid Object:\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nConverting to Raster Object:\n\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nAssigning Projection System: Ensure the CRS (Coordinate Reference System) is assigned correctly:\n\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nVisualizing the Raster: Finally, use the tmap package to visualize the raster in a cartographic map:\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n3.7.4 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning regions.\n\n3.7.4.1 Extracting study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas 1. Ponggol\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\n\n\n\n\n\n\n\n\nTampines\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nChoa Chu Kang\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nJurong West\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\nThe owin objects represent the study areas as window objects, which are necessary for spatial point pattern analysis in spatstat. These are created by converting the sf objects (pg, tm, ck, and jw) representing different regions into owin format:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n3.7.4.3 Combining childcare points and the study area\nwe are then able to extract childcare that is within the specific region to perform analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nThe childcare centers within each specific region are extracted using the owin objects.\nThese point patterns (ppp objects) are then rescaled from meters to kilometers:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nFinally, the four study areas and the locations of the childcare centers are plotted:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.4 Computing KDE\nThe Kernel Density Estimate (KDE) for each area is computed using the density() function, with the bw.diggle method to derive the bandwidth:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcare_pg_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.5 Computing Fixed Bandwidth KDE\nFor comparison, a fixed bandwidth of 250 meters is used to compute KDE for the same areas:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcare_pg_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.8 Nearest Neighbour Analysis",
    "text": "3.8 Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\n\n3.8.1 Testing Spatial Point Patterns using Clark and Evans Test\nThe Clark-Evans test is performed to assess the spatial distribution of the childcare centers. The hypotheses are:\n\nH0: The distribution of childcare centers is random.\nH1: The distribution of childcare centers is clustered.\n\nThe test is conducted as follows:\n\nclarkevans.test(childcareSG_ppp, correction=\"none\", clipregion=\"sg_owin\", alternative=\"clustered\", nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nResult Interpretation:\n\nR = 0.55631: The R-value is less than 1, indicating a tendency towards clustering.\np-value &lt; 2.2e-16: The p-value is extremely small, suggesting that the clustering pattern is statistically significant. The null hypothesis of CSR (Complete Spatial Randomness) is rejected in favor of the alternative hypothesis, indicating that the childcare centers in Singapore are clustered.\n\n\n\n3.8.2 Clark and Evans Test: Punggol planning area\nIn the code chunk below,  clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Punggol planning area.\n\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=\"two.sided\",\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.92075, p-value = 0.2364\nalternative hypothesis: two-sided\n\n\nInterpretation:\n\nR = 0.91163: The R-value is close to 1, indicating a spatial distribution that is close to random.\n\n\np-value = 0.1867: The p-value is greater than 0.05, meaning there is no statistically significant evidence to reject the null hypothesis of CSR. This suggests that the childcare centers in the Punggol area are randomly distributed and do not exhibit significant clustering or regularity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.9 Second-order Spatial Point Patterns Analysis",
    "text": "3.9 Second-order Spatial Point Patterns Analysis\nThis section introduces second-order analyses of spatial point patterns, focusing on measuring interaction between points."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.10 Analysing Spatial Point Process Using G-Function",
    "text": "3.10 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.10.1 Choa Chu Kang planning area\n\n3.10.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n3.10.1.2 Performing Complete Spatial Randomness Test\nTo perform a Complete Spatial Randomness (CSR) test using a Monte Carlo simulation with the G-function in R, you are correctly using the envelope() function from the spatstat package. Here’s how you can carry out the test and interpret the results:\n\nHypothesis Definition:\n\nNull Hypothesis (Ho): The distribution of childcare services at Choa Chu Kang is randomly distributed (i.e., follows CSR).\nAlternative Hypothesis (H1): The distribution of childcare services at Choa Chu Kang is not randomly distributed.\n\nSet Up the Test:\n\nYou will perform a Monte Carlo test using the G-function, which measures the distribution of nearest-neighbor distances.\n\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n3.10.2 Tampines planning area\n\n3.10.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n3.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we perform the Complete Spatial Randomness (CSR) test for the distribution of childcare services in Tampines using the G-function in R, you can follow the steps and code chunk below:\n\nHypothesis:\n\nNull Hypothesis (Ho): The distribution of childcare services at Tampines is randomly distributed (CSR).\nAlternative Hypothesis (H1): The distribution of childcare services at Tampines is not randomly distributed\n\n\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.11 Analysing Spatial Point Process Using F-Function",
    "text": "3.11 Analysing Spatial Point Process Using F-Function\nThe F-function estimates the empty space function F(r) from a point pattern within a defined window. It provides insights into the spatial distribution by measuring the distribution of distances from a randomly chosen location in the study area to the nearest event (e.g., childcare centers). We will compute the F-function for the Choa Chu Kang and Tampines planning areas and perform a Complete Spatial Randomness (CSR) test using Monte Carlo simulations.\nWe will learn how to compute F-function estimation by using Fest() of spatstat package, and how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.11.1 Choa Chu Kang planning area\n\n3.11.1.1 Computing F-fucntion estimate\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n3.11.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns at Choa Chu Kang, a hypothesis test using the F-function will be conducted. The hypotheses are:\n\nHo (Null Hypothesis): The distribution of childcare services at Choa Chu Kang is randomly distributed.\nH1 (Alternative Hypothesis): The distribution of childcare services at Choa Chu Kang is not randomly distributed.\n\nThe null hypothesis will be rejected if the p-value is smaller than the alpha value of 0.001.\nMonte Carlo Test Using F-function:\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n3.11.2 Tampines planning area\n\n3.11.2.1 Computing F-fucntion estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n3.11.2.2 Computing F-fucntion estimation\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.12 Analysing Spatial Point Process Using K-Function",
    "text": "3.12 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.12.1 Choa Chu Kang planning area\n\n3.12.1.1 Computing K-fucntion estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n3.12.1.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n3.12.2 Tampines planning area\n\n3.12.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n3.12.2.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.13 Analysing Spatial Point Process Using L-Function",
    "text": "3.13 Analysing Spatial Point Process Using L-Function\nThe L-function is a method used to analyze spatial point patterns by transforming the K-function to be more interpretable, particularly by normalizing the function against a theoretical CSR model. This section covers how to compute the L-function estimation and perform a Monte Carlo simulation test using the  Lest() and envelope() of spatstat package.\n\n3.13.1 Choa Chu Kang planning area\n\n3.13.1.1 Computing L-fucntion estimation\nTo compute the L-function estimation for Choa Chu Kang, use the Lest() function with the “Ripley” correction. Then, plot the results.\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n3.13.1.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n3.13.2 Tampines planning area\n\n3.13.2.1 Computing L-fucntion estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n3.13.2.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01.html",
    "title": "Geospatial Data Science with R",
    "section": "",
    "text": "In this hands-on exercise, I learnt of how to perform geospatial data science tasks in R by using the sf package.\nUse pacman::p_load to install and load sf and tidyverse"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#exercise-overview",
    "title": "Geospatial Data Science with R",
    "section": "",
    "text": "In this hands-on exercise, I learnt of how to perform geospatial data science tasks in R by using the sf package.\nUse pacman::p_load to install and load sf and tidyverse"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#data-acquisition",
    "title": "Geospatial Data Science with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. These data sources publicly available.\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#getting-started",
    "title": "Geospatial Data Science with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nFor this exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data\nreadxl for importing Excel worksheet\ntidyr for manipulating data\ndplyr for transforming data\nggplot2 for visualising data\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)\n\nThe p_load function conveniently installs (if necessary) and loads the sf and tidyverse packages, making them readily available for use in our analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "title": "Geospatial Data Science with R",
    "section": "1.4 Importing Geospatial Data into R",
    "text": "1.4 Importing Geospatial Data into R\nIn this section, you will learn how to import various geospatial data formats into R using the st_read() of sf package. The following datasets will be imported:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Importing polygon feature data (shapefile format)\nThe code below demonstrates how to import the MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame using the st_read() function. When dealing with shapefiles, you need to specify two arguments: dsn (the data source path) and layer (the shapefile name). Note that you do not need to include file extensions like .shp, .dbf, .prj, or .shx.\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis message indicates that the mpsz object is a simple feature data frame containing 323 multipolygon features and 15 fields, with the SVY21 projected coordinate system. The bounding box provides the data’s spatial extent.\n\n\n1.4.2 Importing polyline feature data (Shapefile Format)\nThe following code demonstrates how to import the CyclingPath shapefile into R as a line feature data frame:\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThis output reveals that the cyclingpath object is a simple feature data frame containing 3138 line features and 2 fields, with the same SVY21 projected coordinate system.\n\n\n1.4.3 Importing GIS data in (KML format)\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThis message indicates that preschool is a point feature data frame with 2290 features and 2 fields, using the WGS 84 geodetic coordinate system, different from the previous datasets."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Geospatial Data Science with R",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, we will use different ways to retrieve information related to the content of a simple feature data frame.\n\n1.5.1 Working with st_geometry()\nThe geometry column in an sf data frame is a list of class sfc. To access the geometry list-column, we use a more general approach, the st_geometry() function, as shown below:\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis function will display basic information about the feature class, such as the geometry type, geographic extent, and coordinate system.\n\n\n1.5.2 glimpse()\nThe glimpse() function reveals the data type of each field, providing insight into the structure and contents of the data frame.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n1.5.3 head()\nIf you need to examine the complete information of a feature object, the head() function in base R is helpful. It displays the first few records of the data frame:\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThe head() function is particularly useful for quickly inspecting a subset of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Geospatial Data Science with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial data science, visualizing geospatial features is crucial. The plot() function from base R allows you to quickly visualize these features:\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nBy default, this function creates a multi-plot of all attributes. You can also plot only the geometry using:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nOr plot the sf object based on a specific attribute:\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#working-with-projection",
    "title": "Geospatial Data Science with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nMap projection is a key aspect of geospatial data. To perform geoprocessing on two datasets, they must share the same coordinate system.\nIn this section, we will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nWhen importing geospatial data into R, the coordinate system might be missing or incorrectly assigned. You can check the coordinate system of a simple feature data frame using st_crs():\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Geospatial Data Science with R",
    "section": "1.8 Importing and Converting An Aspatial Data",
    "text": "1.8 Importing and Converting An Aspatial Data\nAn example of aspatial data would be listing of inside Airbnb. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, we will be importing an aspatial data into R environment and save it as a tibble data frame. Next, we will convert it into a simple feature data frame.\n\n1.8.1 Importing the aspatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing, it’s important to check that the data was imported correctly using list():\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Geospatial Data Science with R",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\nIn this section, we will perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission Accomplished!\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculating Density of Preschool by planning subzone\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Geospatial Data Science with R",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count:\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome! I’m Brian Lim ZhengLong, an undergraduate at Singapore Management University (SMU). This website is dedicated to documenting my learning journey in IS415: Geospatial Analytics and Applications under the guidance of Professor Kam Tin Seong. Join me as I explore the fascinating realms of big data, geospatial analysis, and urban planning.\nLet’s connect and learn together!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02.html",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to create effective and accurate thematic/choropleth maps and other geospatial visualization techniques using the tmap package in R.\nThematic mapping is a technique that uses map symbols to visualize certain characteristics of geographic features that are not naturally visible, such as population, temperature, crime rates, and property values, among others.\nGeovisualization, on the other hand, involves creating graphical representations to make a place, phenomenon, or process visible. This approach leverages the human brain’s powerful spatial cognition abilities, linked to our eye-brain vision system, to better process and understand spatial information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#exercise-overview",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to create effective and accurate thematic/choropleth maps and other geospatial visualization techniques using the tmap package in R.\nThematic mapping is a technique that uses map symbols to visualize certain characteristics of geographic features that are not naturally visible, such as population, temperature, crime rates, and property values, among others.\nGeovisualization, on the other hand, involves creating graphical representations to make a place, phenomenon, or process visible. This approach leverages the human brain’s powerful spatial cognition abilities, linked to our eye-brain vision system, to better process and understand spatial information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#data-acquisition",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e.respopagesexfa2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.3 Getting Started",
    "text": "2.3 Getting Started\nFor this exercise, the following R packages will be used:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, tmap, tidyverse)\n\nThe p_load function conveniently installs (if necessary) and loads the sf and tidyverse packages, making them readily available for use in our analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#importing-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.4 Importing Data into R",
    "text": "2.4 Importing Data into R\n\n2.4.1 Importing Geospatial Data into R\nThe following code demonstrates how to use the st_read() function from the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame named mpsz:\n\nmpsz &lt;- st_read(dsn = \"data/geospatial/\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the content of mpsz by using the code chunk below\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThe reason only the first 10 records are displayed by mpsz is due to its default behaviour. Using head() would allow for the number of display records to change according to the n value.\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n2.4.2 Importing Attribute Data into R\nNext, we will import the respopagesexfa2011to2020.csv file into the R environment and save it into an R dataframe called popdata. The task can be performed using the read_csv() function from the readr package, as shown below:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\n\n\n2.4.3 Data Preparation\nBefore creating a thematic map, it’s necessary to prepare a data table with values from the year 2020. This table should include the following variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: Includes age groups from 0-4 up to 20-24.\nECONOMY ACTIVE: Includes age groups from 25-29 up to 60-64.\nAGED: Includes age groups 65 and above.\nTOTAL: Includes all age groups.\nDEPENDENCY: The ratio between the young and aged populations against the economy active group.\n\n\n2.4.3.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() from the tidyr package.\nmutate(), filter(), group_by(), and select() from the dplyr package.\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP)%&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n2.4.3.2 Joining the attribute data and geospatial data\nBefore performing a georelational join, it’s necessary to convert the values in the PA and SZ fields to uppercase. This is because these fields contain both uppercase and lowercase letters, while the corresponding fields SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, the left_join() function from the dplyr package is used to join the geospatial data and attribute table using SUBZONE_N and SZ as the common identifiers:\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nTake note: The left_join() function from the dplyr package is used with the mpsz simple feature data frame as the left data table to ensure that the output remains a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.5 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.5 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.5.1 Plotting a choropleth map quickly by using qtm()\nThe quickest way to draw a choropleth map is using the qtm() function, which provides a good default visualization with minimal coding. Here’s how you can use it:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n2.5.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() is useful for quickly drawing a choropleth map, it offers limited control over the aesthetics of individual layers. To create a high-quality cartographic choropleth map, you should use tmap elements like tm_shape(), tm_fill(), and tm_borders().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n2.5.2.1 Drawing a base map\nThe foundation of a tmap visualization is tm_shape(), which is followed by layer elements like tm_fill() and tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.5.2.2 Drawing a choropleth map using tm_polygons()\nTo create a choropleth map that shows the geographical distribution of a variable (e.g., DEPENDENCY) by planning subzone, assign the target variable to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to note with tm_polygons():\n\nThe default interval binning method is “pretty.”\nThe default color scheme is “YlOrRd” from ColorBrewer.\nMissing values are shaded in grey.\n\n\n\n2.5.2.3 Drawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is essentially a wrapper for tm_fill() and tm_border(). tm_fill() colors the polygons, while tm_borders() adds the borders. Examine the difference in output between the 2 following code chunks:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map with tm_border().\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.5.3 Data classification methods of tmap\nChoropleth maps often involve data classification to group observations into ranges or classes. tmap offers ten classification methods, including “fixed,” “sd,” “equal,” “pretty” (default), “quantile,” “kmeans,” “hclust,” “bclust,” “fisher,” and “jenks.”\n\n2.5.3.1 Plotting choropleth maps with built-in classification methods\nThe following code demonstrates a quantile classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe equal classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe fisher classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe sd classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe hclust classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe jenks classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAdditionally, we can try preparing choropleth maps by using similar classification methods (i.e. kmeans) but with differing number of classes. The following code chunks use kmeans clustering with different class sizes (2, 6, 10, 20)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.5.3.2 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90 using the breaks argument. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.5.4 Colour Scheme\ntmap supports color ramps defined by the user or from the RColorBrewer package.\n\n2.5.4.1 Using ColourBrewer palette\nTo change the color scheme, assign the desired palette to the palette argument of tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the color scheme, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.5.5 Map Layouts\nMap layout involves combining all map elements into a cohesive visualization, including the title, scale bar, compass, margins, and aspect ratios.\n\n2.5.5.1 Map Legend\ntmap provides several options for customizing the legend’s placement, format, and appearance.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.5.5.2 Map style\ntmap allows you to change the map’s layout settings using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n2.5.5.3 Cartographic Furniture\ntmap also provides functions to add other map elements, such as a compass, scale bar, and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n2.5.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, or facet maps, allow the visualization of how spatial relationships change with another variable, such as time. These maps are composed of several maps arranged side by side or stacked vertically. In tmap, small multiple maps can be plotted in three different ways:\n\nBy assigning multiple values to at least one of the aesthetic arguments.\nBy defining a group-by variable in tm_facets().\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n2.5.6.1 By assigning multiple values to at least one of the aesthetic arguments\nOne way to create small multiple choropleth maps is by defining multiple values for an aesthetic argument such as fill. This method is straightforward and allows for visual comparison across variables.\nThe following code chunk uses tm_fill() with multiple variables\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example:\n\nThe c(\"YOUNG\", \"AGED\") argument creates two maps side by side, one for the young population and one for the aged population.\nThe style argument is set to \"equal\" to ensure consistent class breaks across the maps.\n\nThe following code chunk uses tm_polygons() with multiple styles\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn this example:\n\nThe 2 variables, “DEPENDENCY” and “AGED”, are mapped with different classification styles (“equal” and “quantile”) and color palettes (“Blues” and “Greens”)\n\n\n\n2.5.6.2 By defining a group-by variable in tm_facets()\nAnother approach to creating small multiple maps is by using the tm_facets() function, which allows you to create separate maps based on a grouping variable.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example:\n\nThe by = \"REGION_N\" argument in tm_facets() creates separate maps for each region.\nfree.coords = TRUE allows each facet to have its own coordinate system, and drop.shapes = TRUE drops shapes not belonging to any of the regions.\n\n\n\n2.5.6.3 By creating multiple stand-alone maps with tmap_arrange()\nYou can also create individual maps and then arrange them side by side using tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nIn this example:\n\nTwo maps, youngmap and agedmap, are created individually.\ntmap_arrange() is then used to display these maps side by side with ncol = 2.\n\n\n\n\n2.5.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can also map spatial objects that meet a specific selection criterion using selection functions.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example:\n\nThe data is filtered to only include regions within the “CENTRAL REGION”.\nThe resulting map shows the dependency ratio specifically for this region, with additional customization for the legend and layout.\n\nThese methods allow for versatile and detailed visual representations of spatial data, enabling deeper insights into geographical patterns and trends."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#references",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.6. References",
    "text": "2.6. References\nTutorial provided by Professor Kam Tin Seong©, Singapore Management University\nReference: https://r4gdsa.netlify.app/chap02.html\n\n2.6.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n2.6.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n2.6.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "In-class_Ex/data/In-class_Ex04/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/data/In-class_Ex04/Kepulauan_Bangka_Belitung.html",
    "title": "Brian’s IS415 Experience",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03.html",
    "title": "In Class exercise 3",
    "section": "",
    "text": "Conduct a Monte Carlo simulation to test for Complete Spatial Randomness (CSR)\nMonte Carlo simulation test of CSR:\n\nTo determine the simulation envelope, use the 95th percentile (maximum) and 5th percentile (minimum) values of G(r) from the simulations.\nWhen randomising data it is important to set seed to have it be repeatable\n\nNearest Neighbour Index:\n\nBefore hypothesis, one should determine confidence interval (confidence level) to justify conclusion reached\nDue to the unpredictability of real life data, uncertainty would need to be considered via the confidence level\n\n99 - 99.9 confidence level should be avoided due to the perceived notion that it is almost fully accurate, which cannot happen due to real world uncertainty\n\nReject P-value, if P-value&lt; Alpha value\n\nL Functions Interpretation:\n\nSigns of clustering can be determined from how much higher the L value is above the envelope\n\nRipley’s K function:\n\nBoth G function and K function are distance based, but G function is for any particular zone (isolated), but K function is cumulative in nature (inclusive)\nUsage lies in zoning based on the various interval ranges"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#notes",
    "href": "In-class_Ex/In-class_Ex03.html#notes",
    "title": "In Class exercise 3",
    "section": "",
    "text": "Conduct a Monte Carlo simulation to test for Complete Spatial Randomness (CSR)\nMonte Carlo simulation test of CSR:\n\nTo determine the simulation envelope, use the 95th percentile (maximum) and 5th percentile (minimum) values of G(r) from the simulations.\nWhen randomising data it is important to set seed to have it be repeatable\n\nNearest Neighbour Index:\n\nBefore hypothesis, one should determine confidence interval (confidence level) to justify conclusion reached\nDue to the unpredictability of real life data, uncertainty would need to be considered via the confidence level\n\n99 - 99.9 confidence level should be avoided due to the perceived notion that it is almost fully accurate, which cannot happen due to real world uncertainty\n\nReject P-value, if P-value&lt; Alpha value\n\nL Functions Interpretation:\n\nSigns of clustering can be determined from how much higher the L value is above the envelope\n\nRipley’s K function:\n\nBoth G function and K function are distance based, but G function is for any particular zone (isolated), but K function is cumulative in nature (inclusive)\nUsage lies in zoning based on the various interval ranges"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#getting-started",
    "href": "In-class_Ex/In-class_Ex03.html#getting-started",
    "title": "In Class exercise 3",
    "section": "3.1 Getting Started",
    "text": "3.1 Getting Started\nMaptools is retired and binary is removed from CRAN. However, we can download froom Posit Public Package Manager\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\n3.1.1 Working with st_union()\nThe code chunk below is used to derive the coastal outline in tibble data frame sg_sf &lt;- mpsz_sf %&gt;% st_union()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#viewing-data-for-take-home-exercise-1",
    "href": "In-class_Ex/In-class_Ex03.html#viewing-data-for-take-home-exercise-1",
    "title": "In Class exercise 3",
    "section": "3.2 Viewing data for Take Home exercise 1",
    "text": "3.2 Viewing data for Take Home exercise 1\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;% \n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs= 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\ntmap_mode('view')\nacled_sf %&gt;%\n  filter(year == 2023 |\n           event_type == \"Political violence\") %&gt;%\n  tm_shape()+\n  tm_dots()\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to my IS415 Geospatial Analytics and Applications. In this website, you will find my coursework prepared for this course.\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial Data Science with R\n\n\n\n\n\n\nBrian Lim\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nThematic Mapping and GeoVisualisation with R\n\n\n\n\n\n\nBrian Lim\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1st & 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nBrian Lim\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_ex/Take-home_ex01.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.6 2nd-Order Spatial Point Patterns Analysis",
    "text": "1.6 2nd-Order Spatial Point Patterns Analysis\n\n1.6.1 Overview\nTo perform a Second-order Spatial Point Patterns Analysis, we utilize the G, F, K, and L functions of the spatstat package in R. Each of these functions analyzes different aspects of spatial point patterns. Given the nature of the dataset, it is crucial to choose an analysis that best captures the complexity of spatial distributions for conflict events. Each of the spatial functions (G, F, K, and L) has its strengths, but here’s how they align with conflict data analysis, with a particular focus on the G-function:\n\nG-Function (Nearest Neighbor Distribution):\n\nDetecting local clustering: The G-function focuses on the distribution of nearest neighbors, making it particularly useful for detecting local clustering of events. In the civil war context, where conflict events often cluster in specific regions or around key areas of interest (e.g., cities, roads, military bases), the G-function can quickly and efficiently help identify hotspots of violence. Its simplicity and computational efficiency make it an excellent choice for analyzing localized patterns of violence, especially when time and resources are limited.\n\nF-Function (Empty Space Function):\n\nDetecting global regularity: The F-function measures the distance from random locations to the nearest event. While it can offer insights into the global spread of events, this function is less relevant for conflict analysis because it emphasizes regularity over clustering, which is not typical in conflict zones. Conflict events are rarely evenly spaced, making the F-function less suited for this kind of data.\n\nK-Function (Ripley’s K-Function):\n\nMulti-scale clustering: The K-function is valuable for analyzing clustering at different spatial scales, especially in hierarchical conflict scenarios where regional and local clusters coexist. However, the K-function’s multi-scale nature comes with a higher computational cost, making it less practical for when large datasets are involved. While informative, its complexity and runtime can be a drawback.\n\nL-Function (Transformed K-Function):\n\nSimplifying K-function results: The L-function is a linearized version of the K-function and offers more intuitive interpretations of clustering versus dispersion. However, like the K-function, it involves significant computation time, and its added complexity may not always justify its use, especially when the G-function already provides key insights into local clustering.\n\n\nGiven the nature of the civil war event data, where localized patterns and hotspots of violence are of primary concern, the G-function emerges as the most suitable tool for analysis. Its ability to efficiently detect local clustering while being computationally lightweight makes it a clear choice. While both K-function and L-functions offer multi-scale insights, they come at the cost of significant computation time, which may not be necessary for this analysis.\nThe G-function provides a focused and practical approach to understanding the spatial distribution of conflict events, making it the preferred choice in this context.\n\n\nExplosions/Remote violence overview\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_ER_quarter_data_regions_ppp,\n  my_2021_Q2_ER_quarter_data_regions_ppp,\n  my_2021_Q3_ER_quarter_data_regions_ppp,\n  my_2021_Q4_ER_quarter_data_regions_ppp,\n  my_2022_Q1_ER_quarter_data_regions_ppp,\n  my_2022_Q2_ER_quarter_data_regions_ppp,\n  my_2022_Q3_ER_quarter_data_regions_ppp,\n  my_2022_Q4_ER_quarter_data_regions_ppp,\n  my_2023_Q1_ER_quarter_data_regions_ppp,\n  my_2023_Q2_ER_quarter_data_regions_ppp,\n  my_2023_Q3_ER_quarter_data_regions_ppp,\n  my_2023_Q4_ER_quarter_data_regions_ppp,\n  my_2024_Q1_ER_quarter_data_regions_ppp,\n  my_2024_Q2_ER_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,0,2,0))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n  invisible(\n    G_CK.csr &lt;- suppressMessages(\n      envelope(er_datasets[[i]], Gest, nsim = 10, correction=\"all\", parallel = parallel::detectCores())\n    )\n  )\n  plot(G_CK.csr, xlim=c(0,10000), main= paste0(er_labels[[i]]))\n}\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nStrategic developments overview\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_SD_quarter_data_regions_ppp,\n  my_2021_Q2_SD_quarter_data_regions_ppp,\n  my_2021_Q3_SD_quarter_data_regions_ppp,\n  my_2021_Q4_SD_quarter_data_regions_ppp,\n  my_2022_Q1_SD_quarter_data_regions_ppp,\n  my_2022_Q2_SD_quarter_data_regions_ppp,\n  my_2022_Q3_SD_quarter_data_regions_ppp,\n  my_2022_Q4_SD_quarter_data_regions_ppp,\n  my_2023_Q1_SD_quarter_data_regions_ppp,\n  my_2023_Q2_SD_quarter_data_regions_ppp,\n  my_2023_Q3_SD_quarter_data_regions_ppp,\n  my_2023_Q4_SD_quarter_data_regions_ppp,\n  my_2024_Q1_SD_quarter_data_regions_ppp,\n  my_2024_Q2_SD_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n  invisible(\n    G_CK.csr &lt;- suppressMessages(\n      envelope(er_datasets[[i]], Gest, nsim = 10, parallel = parallel::detectCores())\n    )\n  )\n  plot(G_CK.csr, xlim=c(0,10000), main= paste0(er_labels[[i]]))\n}\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nBattles overview\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_B_quarter_data_regions_ppp,\n  my_2021_Q2_B_quarter_data_regions_ppp,\n  my_2021_Q3_B_quarter_data_regions_ppp,\n  my_2021_Q4_B_quarter_data_regions_ppp,\n  my_2022_Q1_B_quarter_data_regions_ppp,\n  my_2022_Q2_B_quarter_data_regions_ppp,\n  my_2022_Q3_B_quarter_data_regions_ppp,\n  my_2022_Q4_B_quarter_data_regions_ppp,\n  my_2023_Q1_B_quarter_data_regions_ppp,\n  my_2023_Q2_B_quarter_data_regions_ppp,\n  my_2023_Q3_B_quarter_data_regions_ppp,\n  my_2023_Q4_B_quarter_data_regions_ppp,\n  my_2024_Q1_B_quarter_data_regions_ppp,\n  my_2024_Q2_B_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n  invisible(\n    G_CK.csr &lt;- suppressMessages(\n      envelope(er_datasets[[i]], Gest, nsim = 10, parallel = parallel::detectCores())\n    )\n  )\n  plot(G_CK.csr, xlim=c(0,10000), main= paste0(er_labels[[i]]))\n}\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nViolence against civilians overview\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_VAC_quarter_data_regions_ppp,\n  my_2021_Q2_VAC_quarter_data_regions_ppp,\n  my_2021_Q3_VAC_quarter_data_regions_ppp,\n  my_2021_Q4_VAC_quarter_data_regions_ppp,\n  my_2022_Q1_VAC_quarter_data_regions_ppp,\n  my_2022_Q2_VAC_quarter_data_regions_ppp,\n  my_2022_Q3_VAC_quarter_data_regions_ppp,\n  my_2022_Q4_VAC_quarter_data_regions_ppp,\n  my_2023_Q1_VAC_quarter_data_regions_ppp,\n  my_2023_Q2_VAC_quarter_data_regions_ppp,\n  my_2023_Q3_VAC_quarter_data_regions_ppp,\n  my_2023_Q4_VAC_quarter_data_regions_ppp,\n  my_2024_Q1_VAC_quarter_data_regions_ppp,\n  my_2024_Q2_VAC_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n  invisible(\n    G_CK.csr &lt;- suppressMessages(\n      envelope(er_datasets[[i]], Gest, nsim = 10, parallel = parallel::detectCores())\n    )\n  )\n  plot(G_CK.csr, xlim=c(0,10000), main= paste0(er_labels[[i]]))\n}\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\nGenerating 10 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, \n10.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\n1.6.2 Conclusion"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#determining-spatio-temporal-kde-layer",
    "href": "Take-home_ex/Take-home_ex01.html#determining-spatio-temporal-kde-layer",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.7 Determining Spatio-Temporal KDE Layer",
    "text": "1.7 Determining Spatio-Temporal KDE Layer\n\n1.7.1 Choosing sample Dataset\n\ntemporal_acled_sf &lt;- acled_sf %&gt;%\n  mutate(event_date = dmy(event_date)) %&gt;%\n  mutate(quarter = paste0(year, \" Q\", quarter(event_date))) %&gt;%\n  mutate(DayofYear = yday(event_date)) %&gt;%\n  mutate(Month_num = month(event_date)) %&gt;%\n  mutate(Month_fac = month(event_date, \n                           label = TRUE, \n                           abbr = FALSE))\n\n\ntm_shape(regions_sf)+\n  tm_polygons() +\ntm_shape(temporal_acled_sf) +\n  tm_dots()"
  }
]