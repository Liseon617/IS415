[
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "",
    "text": "In this take-home exercise, I will focus on prototyping a Geographically Weighted Predictive Model for my group’s Shiny App. This model allows users to input specific values for key variables and obtain rental price predictions for HDB flats in Singapore. The model considers variables such as flat type, proximity to kindergartens and MRT stations, the number of childcare centers within 500 meters, and distance to amenities like hawker centers, shopping malls, primary schools, and the CBD. By capturing these localized effects, the predictive model provides a user-friendly, data-driven tool for estimating monthly rent based on a flat’s characteristics and surrounding environment. The data preparation and Exploratory Data Analysis were handled by my groupmate, so for this exercise, I will load the data directly from an RDS file. For this exercise, I will load the prepared dataset directly from an RDS file for efficient model testing."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#overview",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#overview",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "",
    "text": "In this take-home exercise, I will focus on prototyping a Geographically Weighted Predictive Model for my group’s Shiny App. This model allows users to input specific values for key variables and obtain rental price predictions for HDB flats in Singapore. The model considers variables such as flat type, proximity to kindergartens and MRT stations, the number of childcare centers within 500 meters, and distance to amenities like hawker centers, shopping malls, primary schools, and the CBD. By capturing these localized effects, the predictive model provides a user-friendly, data-driven tool for estimating monthly rent based on a flat’s characteristics and surrounding environment. The data preparation and Exploratory Data Analysis were handled by my groupmate, so for this exercise, I will load the data directly from an RDS file. For this exercise, I will load the prepared dataset directly from an RDS file for efficient model testing."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#getting-started",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#getting-started",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.2 Getting Started",
    "text": "3.2 Getting Started\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\nspdep for spatial dependence analysis, including computing spatial weights and conducting spatial autocorrelation tests such as Moran’s I and Geary’s C\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nGWmodel provides techniques from a particular branch of spatial statistics,termed geographically-weighted (GW) models. GW models suit situations when data are not described well by some global model, but where there are spatial regions where a suitably localised calibration provides a better description.\nSpatialML for a geographically weighted random forest regression including a function to find the optical bandwidth.\nrsample to create and summarize different types of resampling objects.\nMetrics implements metrics for regression, time series, binary classification, classification, and information retrieval problems.\nolsrr provides tools for building OLS regression models using R\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, spdep, tmap, tidyverse, GWmodel, SpatialML, rsample, Metrics, olsrr)"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#importing-data-into-r",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#importing-data-into-r",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.3 Importing Data into R",
    "text": "3.3 Importing Data into R\nWe will first import the rental dataset prepared by one of my teammates. Please refer to here for the details of the data wrangling.\n\nrental.sf =&gt; contains the rental data from Jan 2020 to Sept 2024, as well as other fields like:\n\nDependent:\n\nMonthly Rental fee: monthly_rent\n\nContinuous:\n\nProximity measure: kindergarten, childcare, hawker, bus stops, shopping mall, mrt, primary schools, cbd\nCount of amenities within specific distance: kindergarten, childcare, hawker, bus stops, shopping mall,\n\nCategorical:\n\nFlat Type: flat_type\nTown: town\nRegion: region\n\n\n\n\nrental_sf &lt;- read_rds(\"data/rds/rental_sf.rds\")\n\nPrimarily, we will be working with numerical values to determine the variable correlations they have with monthly_rent. Based on the summary results below, we will first focus on the following columns:\n1. no_of_kindergarten_500m\n2. prox_kindergarten\n3. no_of_childcare_500m\n4. prox_childcare\n5. no_of_hawker_500m\n6. prox_hawker\n7. no_of_busstop_500m\n8. prox_busstop\n9. no_of_shoppingmall_1km\n10. prox_shoppingmall\n11. prox_mrt\n12. prox_prisch\n13. prox_cbd\n\nsummary(rental_sf)\n\n rent_approval_date       town            flat_type          monthly_rent \n Min.   :2024-01-01   Length:25713       Length:25713       Min.   : 500  \n 1st Qu.:2024-03-01   Class :character   Class :character   1st Qu.:2700  \n Median :2024-05-01   Mode  :character   Mode  :character   Median :3100  \n Mean   :2024-04-29                                         Mean   :3102  \n 3rd Qu.:2024-07-01                                         3rd Qu.:3500  \n Max.   :2024-09-01                                         Max.   :6500  \n          geometry        region          no_of_kindergarten_500m\n POINT        :25713   Length:25713       Min.   : 0.000         \n epsg:3414    :    0   Class :character   1st Qu.: 1.000         \n +proj=tmer...:    0   Mode  :character   Median : 2.000         \n                                          Mean   : 1.912         \n                                          3rd Qu.: 3.000         \n                                          Max.   :11.000         \n prox_kindergarten no_of_childcare_500m prox_childcare    no_of_hawker_500m\n Min.   :   0.0    Min.   : 0.000       Min.   :   0.00   Min.   :0.0000   \n 1st Qu.: 171.7    1st Qu.: 6.000       1st Qu.:  71.08   1st Qu.:0.0000   \n Median : 272.0    Median : 8.000       Median : 117.53   Median :0.0000   \n Mean   : 296.6    Mean   : 8.495       Mean   : 126.71   Mean   :0.6711   \n 3rd Qu.: 390.5    3rd Qu.:10.000       3rd Qu.: 170.96   3rd Qu.:1.0000   \n Max.   :3196.7    Max.   :28.000       Max.   :2952.48   Max.   :5.0000   \n  prox_hawker       no_of_busstop_500m  prox_busstop    no_of_shoppingmall_1km\n Min.   :   6.981   Min.   : 3.00      Min.   : 15.43   Min.   : 0.00         \n 1st Qu.: 301.816   1st Qu.:12.00      1st Qu.: 73.62   1st Qu.: 1.00         \n Median : 530.754   Median :15.00      Median :107.18   Median : 2.00         \n Mean   : 672.403   Mean   :15.28      Mean   :114.66   Mean   : 1.78         \n 3rd Qu.: 907.293   3rd Qu.:18.00      3rd Qu.:145.81   3rd Qu.: 3.00         \n Max.   :2867.630   Max.   :32.00      Max.   :391.47   Max.   :16.00         \n prox_shoppingmall    prox_mrt         prox_prisch        prox_cbd    \n Min.   :   0.0    Min.   :   9.112   Min.   :   0.0   Min.   :  722  \n 1st Qu.: 388.7    1st Qu.: 250.080   1st Qu.: 249.3   1st Qu.: 7412  \n Median : 617.7    Median : 423.233   Median : 385.4   Median :11340  \n Mean   : 689.8    Mean   : 495.644   Mean   : 443.9   Mean   :10956  \n 3rd Qu.: 920.1    3rd Qu.: 666.385   3rd Qu.: 557.4   3rd Qu.:14314  \n Max.   :3222.7    Max.   :3446.893   Max.   :3293.3   Max.   :19758  \n\n\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package.\n\nset.seed(1234)\nrental_split &lt;- initial_split(rental_sf, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(rental_split)\ntest_data &lt;- testing(rental_split)\n\n\nwrite_rds(train_data, \"data/rds/model/train_data.rds\")\nwrite_rds(test_data, \"data/rds/model/test_data.rds\")\n\n\ntrain_data &lt;- read_rds(\"data/rds/model/train_data.rds\")\ntest_data &lt;- read_rds(\"data/rds/model/test_data.rds\")\n\n\nrental_nogeo &lt;- rental_sf %&gt;%\n  select(7:19) %&gt;%\n  st_drop_geometry()\n\nAs we are more interested in predicting rental prices of property based on different locations across Singpaore, we will start by examining the only numeric independent values of the rental.sf data frame\n\nnames(rental_nogeo)\n\n [1] \"no_of_kindergarten_500m\" \"prox_kindergarten\"      \n [3] \"no_of_childcare_500m\"    \"prox_childcare\"         \n [5] \"no_of_hawker_500m\"       \"prox_hawker\"            \n [7] \"no_of_busstop_500m\"      \"prox_busstop\"           \n [9] \"no_of_shoppingmall_1km\"  \"prox_shoppingmall\"      \n[11] \"prox_mrt\"                \"prox_prisch\"            \n[13] \"prox_cbd\""
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#computing-correlation-matrix",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#computing-correlation-matrix",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.4 Computing Correlation Matrix",
    "text": "3.4 Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in rental.sf data.frame.\n\ncorrplot::corrplot(cor(rental_nogeo), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\nAfter viewing the various correlation matrices above, all the correlation values are below 0.8. Hence, there is no sign of multicolinearity."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.5 Building a non-spatial multiple linear regression",
    "text": "3.5 Building a non-spatial multiple linear regression\nWe will now go about building a non-spatial multi-linear regression. Given that flat_type is categorical and has been shown to significantly impact rental prices, it’s appropriate to retain it. Variables like flat_type have proven theoretical and empirical justification for their inclusion based on their substantial effect on monthly rental price.\n\ntrain_data &lt;- read_rds(\"data/rds/model/train_data.rds\")\ntest_data &lt;- read_rds(\"data/rds/model/test_data.rds\")\n\n\n\nShow the code\nrental_price_mlr &lt;- lm(monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + prox_kindergarten +\n                  no_of_childcare_500m + no_of_hawker_500m + prox_childcare +\n                  prox_hawker + no_of_busstop_500m + prox_busstop + \n                  no_of_shoppingmall_1km + prox_shoppingmall +\n                  prox_mrt + prox_prisch +\n                  prox_cbd,\n                data=train_data)\n\nsummary(rental_price_mlr)\n\n\n\nCall:\nlm(formula = monthly_rent ~ flat_type + no_of_kindergarten_500m + \n    prox_kindergarten + no_of_childcare_500m + no_of_hawker_500m + \n    prox_childcare + prox_hawker + no_of_busstop_500m + prox_busstop + \n    no_of_shoppingmall_1km + prox_shoppingmall + prox_mrt + prox_prisch + \n    prox_cbd, data = train_data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3062.83  -286.72    65.87   348.22  2720.83 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              3.229e+03  3.497e+01  92.323  &lt; 2e-16 ***\nflat_type4-ROOM          6.540e+02  1.026e+01  63.763  &lt; 2e-16 ***\nflat_type5-ROOM          9.203e+02  1.195e+01  77.030  &lt; 2e-16 ***\nno_of_kindergarten_500m  8.559e+00  3.788e+00   2.260  0.02385 *  \nprox_kindergarten       -8.094e-02  2.959e-02  -2.735  0.00624 ** \nno_of_childcare_500m    -7.138e+00  1.541e+00  -4.633 3.64e-06 ***\nno_of_hawker_500m       -8.987e-01  6.881e+00  -0.131  0.89609    \nprox_childcare          -2.000e-02  5.015e-02  -0.399  0.69011    \nprox_hawker             -6.219e-02  1.140e-02  -5.457 4.92e-08 ***\nno_of_busstop_500m       9.605e-01  1.110e+00   0.866  0.38677    \nprox_busstop             7.130e-02  7.997e-02   0.892  0.37263    \nno_of_shoppingmall_1km  -2.101e+00  3.687e+00  -0.570  0.56886    \nprox_shoppingmall       -8.636e-02  1.476e-02  -5.849 5.03e-09 ***\nprox_mrt                -1.063e-01  1.391e-02  -7.642 2.25e-14 ***\nprox_prisch              4.032e-02  1.674e-02   2.408  0.01606 *  \nprox_cbd                -3.886e-02  1.179e-03 -32.962  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 547.7 on 16697 degrees of freedom\nMultiple R-squared:  0.3144,    Adjusted R-squared:  0.3137 \nF-statistic: 510.3 on 15 and 16697 DF,  p-value: &lt; 2.2e-16\n\n\nBased on the coefficient section, we can see that not all the independent variables are statistically significant, and some variables can be removed from our model based on their p-value field (Pr &gt; 0.05).\nThe following variables should be removed from the model due to their high p-values, indicating they are not statisitically significant predictors of monthly rent:\n1. no_of_hawker_500m (p = 0.89609)\n2. prox_childcare (p = 0.69011)\n3. no_of_busstop_500m (p = 0.38677)\n4. prox_busstop (p = 0.37263)\n5. no_of_shoppingmall_1km (p = 0.56886)\nNow we will update the model by removing the 5 variables\n\n\nShow the code\nrental_price_mlr &lt;- lm(formula = monthly_rent ~ flat_type + no_of_kindergarten_500m + prox_kindergarten +\n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_prisch + prox_cbd, \n                 data = train_data)\n\n# Display the publication-quality table\nols_regress(rental_price_mlr)\n\n\n                           Model Summary                             \n--------------------------------------------------------------------\nR                         0.561       RMSE                  547.483 \nR-Squared                 0.314       MSE                299935.128 \nAdj. R-Squared            0.314       Coef. Var              17.672 \nPred R-Squared            0.313       AIC                258215.452 \nMAE                     412.938       SBC                258308.139 \n--------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                      Sum of                                                    \n                     Squares           DF      Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    2295968877.016           10    229596887.702    765.488    0.0000 \nResidual      5009516507.263        16702       299935.128                      \nTotal         7305485384.279        16712                                       \n--------------------------------------------------------------------------------\n\n                                            Parameter Estimates                                             \n-----------------------------------------------------------------------------------------------------------\n                  model        Beta    Std. Error    Std. Beta       t        Sig        lower       upper \n-----------------------------------------------------------------------------------------------------------\n            (Intercept)    3240.088        23.849                 135.858    0.000    3193.341    3286.834 \n        flat_type4-ROOM     654.702        10.195        0.484     64.215    0.000     634.718     674.686 \n        flat_type5-ROOM     921.148        11.884        0.600     77.510    0.000     897.853     944.443 \nno_of_kindergarten_500m       8.553         3.704        0.019      2.309    0.021       1.293      15.813 \n      prox_kindergarten      -0.085         0.027       -0.023     -3.152    0.002      -0.138      -0.032 \n   no_of_childcare_500m      -6.901         1.502       -0.038     -4.594    0.000      -9.845      -3.956 \n            prox_hawker      -0.062         0.010       -0.047     -6.449    0.000      -0.081      -0.043 \n      prox_shoppingmall      -0.084         0.012       -0.051     -7.117    0.000      -0.107      -0.061 \n               prox_mrt      -0.106         0.014       -0.054     -7.699    0.000      -0.133      -0.079 \n            prox_prisch       0.038         0.017        0.016      2.297    0.022       0.006       0.070 \n               prox_cbd      -0.039         0.001       -0.269    -35.002    0.000      -0.041      -0.036 \n-----------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nInterpretation\n\n\n\n\nModel Performance:\n\nThe R-squared value is 0.314, indicating that about 31.4% of the variability in monthly rent is explained by the model. While it shows some predictive capability, other factors might still influence rental prices.\n\nKey Predictors:\n\nSignificant Variables: The predictors with low p-values (e.g., flat type, number of kindergartens, proximity to hawker centers, shopping malls, MRT stations, primary schools, and CBD) significantly influence monthly rent.\nNoteworthy Coefficients:\n\nflat_type: Larger room types (4-ROOM, 5-ROOM) show substantial positive impacts on monthly rent.\nprox_cbd: Rent decreases as distance from the CBD increases, with each unit increase in distance reducing the monthly rent by about 0.039.\n\n\nModel Error and Diagnostics:\n\nRMSE: 547.5, suggesting a reasonable prediction accuracy\nMAE: 412.9, reflecting an average prediction error of about $413"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#constructing-the-adaptive-bandwidth-gwr-model",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#constructing-the-adaptive-bandwidth-gwr-model",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.6 Constructing the adaptive bandwidth gwr model",
    "text": "3.6 Constructing the adaptive bandwidth gwr model\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel. First we use bw.gwr() of GWmodel package to determine the optimal bandwidth to be used\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 16713 \nextent      : 11597.31, 45192.3, 28097.64, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 18\nnames       : rent_approval_date,       town, flat_type, monthly_rent,         region, no_of_kindergarten_500m,    prox_kindergarten, no_of_childcare_500m,       prox_childcare, no_of_hawker_500m,      prox_hawker, no_of_busstop_500m,     prox_busstop, no_of_shoppingmall_1km, prox_shoppingmall, ... \nmin values  :              19723, ANG MO KIO,    3-ROOM,          500, CENTRAL REGION,                       0, 6.59828462646688e-05,                    0, 6.26024982260832e-06,                 0,  6.9808810867684,                  3, 15.4274594853233,                      0,                 0, ... \nmax values  :              19967,     YISHUN,    5-ROOM,         6500,    WEST REGION,                      11,      3196.6660398211,                   28,     2952.47979062617,                 5, 2867.63031236184,                 32, 391.470766976464,                     16,  3222.67183763499, ... \n\n\n\n\nShow the code\nbw_adaptive &lt;- bw.gwr(monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + prox_kindergarten +\n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_prisch + prox_cbd,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\n\nwrite_rds(bw_adaptive, \"data/rds/model/bw_adaptive.rds\")\n\n\nbw_adaptive &lt;- read_rds(\"data/rds/model/bw_adaptive.rds\")\nbw_adaptive\n\n[1] 184\n\n\n\n\n\n\n\n\nInisghts\n\n\n\n\nOptimal Bandwidth:\n\n\nHere, the optimal adaptive bandwidth is found to be 184 (based on the lowest CV score of 4484696643).\nThis bandwidth indicates that for each local regression in the GWR model, the 184 nearest neighbors are included, providing a balance between capturing spatial variation and maintaining model stability.\n\n\n\nAfter identifying the optimal adaptive bandwidth (bw_adaptive) for running a Geographically Weighted Regression (GWR) with cross-validation, we use this bw_adaptive value in the next step with gwr.basic will allow you to fit the GWR model itself.\nIn short, this step allows you to create a spatially-varying model, which helps identify how different factors contribute to monthly_rent differently across locations.\nNow we can to calibrate the gwr-based hedonic pricing model using adaptive bandwidth and gaussian kernel.\n\n\nShow the code\ngwr_adaptive &lt;- gwr.basic(formula = monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + prox_kindergarten +\n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_prisch + prox_cbd,\n                  data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\n\n\nwrite_rds(gwr_adaptive, \"data/rds/model/gwr_adaptive.rds\")\n\n\ngwr_adaptive &lt;- read_rds(\"data/rds/model/gwr_adaptive.rds\")\n\nThis code produces the GWR model using the adaptive bandwidth previously calculated. Running this step is essential for performing the actual localized regression analysis and obtaining spatially varying coefficients, which will reveal how the influence of each predictor on rental prices varies across the area. This model will give you insights into spatial patterns in rental prices, helping you to understand which factors are most significant in different locations.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-11-03 00:38:14.363774 \n   Call:\n   gwr.basic(formula = monthly_rent ~ flat_type + no_of_kindergarten_500m + \n    prox_kindergarten + no_of_childcare_500m + prox_hawker + \n    prox_shoppingmall + prox_mrt + prox_prisch + prox_cbd, data = train_data_sp, \n    bw = bw_adaptive, kernel = \"gaussian\", adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  monthly_rent\n   Independent variables:  flat_type no_of_kindergarten_500m prox_kindergarten no_of_childcare_500m prox_hawker prox_shoppingmall prox_mrt prox_prisch prox_cbd\n   Number of data points: 16713\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n     Min       1Q   Median       3Q      Max \n-3060.57  -286.94    66.18   348.38  2725.20 \n\n   Coefficients:\n                             Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              3.240e+03  2.385e+01 135.858  &lt; 2e-16 ***\n   flat_type4-ROOM          6.547e+02  1.020e+01  64.215  &lt; 2e-16 ***\n   flat_type5-ROOM          9.211e+02  1.188e+01  77.510  &lt; 2e-16 ***\n   no_of_kindergarten_500m  8.553e+00  3.704e+00   2.309  0.02095 *  \n   prox_kindergarten       -8.478e-02  2.690e-02  -3.152  0.00162 ** \n   no_of_childcare_500m    -6.901e+00  1.502e+00  -4.594 4.38e-06 ***\n   prox_hawker             -6.226e-02  9.654e-03  -6.449 1.16e-10 ***\n   prox_shoppingmall       -8.396e-02  1.180e-02  -7.117 1.15e-12 ***\n   prox_mrt                -1.062e-01  1.379e-02  -7.699 1.45e-14 ***\n   prox_prisch              3.800e-02  1.655e-02   2.297  0.02165 *  \n   prox_cbd                -3.863e-02  1.104e-03 -35.002  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 547.7 on 16702 degrees of freedom\n   Multiple R-squared: 0.3143\n   Adjusted R-squared: 0.3139 \n   F-statistic: 765.5 on 10 and 16702 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 5009516507\n   Sigma(hat): 547.5158\n   AIC:  258215.5\n   AICc:  258215.5\n   BIC:  241711.8\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 184 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                  Min.     1st Qu.      Median     3rd Qu.\n   Intercept               -4.1239e+03  2.2785e+03  2.9224e+03  3.3464e+03\n   flat_type4.ROOM          1.5958e+02  4.7323e+02  5.8078e+02  7.1121e+02\n   flat_type5.ROOM          3.3315e+02  7.3309e+02  8.7484e+02  1.0579e+03\n   no_of_kindergarten_500m -4.4557e+02 -3.1163e+01 -3.5370e+00  1.3943e+01\n   prox_kindergarten       -2.7091e+00 -1.9117e-01  2.9232e-02  2.1290e-01\n   no_of_childcare_500m    -7.8560e+01 -6.0831e+00  2.5467e+00  1.1740e+01\n   prox_hawker             -6.8246e-01 -1.0095e-01  3.7093e-02  2.0007e-01\n   prox_shoppingmall       -1.3366e+00 -1.4787e-01 -5.2000e-02  5.9172e-02\n   prox_mrt                -2.4673e+00 -3.2010e-01 -1.8481e-01 -6.2536e-02\n   prox_prisch             -1.1783e+00 -1.1478e-01  1.6581e-02  1.1858e-01\n   prox_cbd                -1.0204e+00 -6.5047e-02 -1.0502e-02  3.4669e-02\n                                 Max.\n   Intercept               10751.4755\n   flat_type4.ROOM          1196.1883\n   flat_type5.ROOM          1495.6959\n   no_of_kindergarten_500m   112.0738\n   prox_kindergarten           0.6535\n   no_of_childcare_500m      107.6404\n   prox_hawker                 1.5006\n   prox_shoppingmall           1.4020\n   prox_mrt                    0.7157\n   prox_prisch                 1.2324\n   prox_cbd                    0.9232\n   ************************Diagnostic information*************************\n   Number of data points: 16713 \n   Effective number of parameters (2trace(S) - trace(S'S)): 585.6495 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 16127.35 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 256327.1 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 255849.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 243063.8 \n   Residual sum of squares: 4238886846 \n   R-square value:  0.4197666 \n   Adjusted R-square value:  0.3986946 \n\n   ***********************************************************************\n   Program stops at: 2024-11-03 00:39:34.720698 \n\n\n\n\n\n\n\n\nInsights\n\n\n\nThis analysis captures how each variable’s impact on rental prices varies across different spatial locations. Here’s a breakdown of the key results:\n\n1. Global Regression Results\nSignificant variables (based on p-values &lt; 0.05) include: - flat_type: Different flat types significantly impact rental prices. - Proximity to various facilities (e.g., prox_kindergarten, prox_hawker, prox_shoppingmall, prox_mrt, prox_cbd) also shows significant impact, with proximity to the Central Business District (prox_cbd) having a strong negative effect.\n\n\n2. GWR Results\n\nAdaptive Bandwidth: The optimal bandwidth is 184, determined via cross-validation. This bandwidth allows the model to capture spatially varying relationships, adjusting the number of nearest neighbors for each location.\nprox_cbd has a median negative effect but varies across locations, indicating that distance to the CBD does not uniformly affect rental prices.\nInsignificant Features: All of the features listed have p-values less than 0.05, indicating that they are statistically significant. However, if you’re looking for features that are less impactful:\n\n\nprox_kindergarten: p = 0.00162\nprox_prisch: p = 0.02165\n\n\nR-squared: 0.4198, indicating that the GWR model explains around 41.98% of the variance in rental prices—an improvement over the global model.\nAICc: 256327.1, which is lower than the global model’s AIC, suggesting a better fit when accounting for spatial variation.\n\n\n\n3. Diagnostics\n\nResidual Sum of Squares (RSS): Lower in GWR (4238886846 vs. 5009516507 in the global model), indicating better fit.\nAdjusted R-squared: 0.3987 for GWR, higher than the global model’s, suggesting improved explanatory power.\n\nThe GWR model thus captures complex spatial heterogeneity in rental price determinants, which would be missed by a non-spatial global regression model."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#preparing-coordinates-data",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#preparing-coordinates-data",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.7 Preparing coordinates data",
    "text": "3.7 Preparing coordinates data\n\n3.7.1 Extracting coordinates data\nWe will then retrieve x and y coordinates for all datasets (full, training, and test) using st_coordinates(), essential for spatial analysis and spatial modeling.\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(rental_sf)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\n\ncoords_train &lt;- write_rds(coords_train, \"data/rds/model/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/rds/model/coords_test.rds\" )\n\n\ncoords_train &lt;- read_rds(\"data/rds/model/coords_train.rds\" )\ncoords_test &lt;- read_rds(\"data/rds/model/coords_test.rds\" )\n\n\n\n3.7.2 Data Preparation\nFirst, we convert the categorical data related columns to factors within both the train_data and test_data. This informs R that these are nominal categories, and they can be handled correctly in the model\n\ntrain_data$flat_type &lt;- as.factor(train_data$flat_type)\ntrain_data$town &lt;- as.factor(train_data$town)\ntrain_data$region &lt;- as.factor(train_data$region)\n\ntest_data$flat_type &lt;- as.factor(test_data$flat_type)\ntest_data$town &lt;- as.factor(test_data$town)\ntest_data$region &lt;- as.factor(test_data$region)\n\nWe will then drop geometry column of the sf data.frame by using st_drop_geometry() of sf package. This prepares the data for modeling while keeping the spatial information separate.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#calibrating-models",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#calibrating-models",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.8 Calibrating Models",
    "text": "3.8 Calibrating Models\nIn this section, we will calibrate a model to predict HDB rental price by using grf() of SpatialML package.\n\n3.8.1 Calibrating using training data\nBased on the output of the initial GWR model (gwr_adaptive), all of the features listed have p-values less than 0.05, indicating that they are statistically significant. However, if you’re looking for features that are less impactful, you can consider examining the magnitude of the coefficients alongside their p-values:\n\nprox_kindergarten: Coefficient = -0.08478 (indicating a negative relationship, but relatively low impact)\nprox_prisch: Coefficient = 0.03800 (also showing a weak relationship)\n\n\n\n3.8.2 Calibrating Random Forest (RF) Model\nIn this section, we will calibrate a model to predict HDB rental price by using random forest function of ranger package.\n\nset.seed(1234)\nrf_cal &lt;- ranger(monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + \n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_cbd,\n             data=train_data)\nrf_cal\n\n\nwrite_rds(rf_cal, \"data/rds/model/rf_cal.rds\")\n\nThe code chunk below can be used to retrieve the save model in future.\n\nrf_cal &lt;- read_rds(\"data/rds/model/rf_cal.rds\")\n\n\n\n3.8.3 Calibrating Random Forest (RF) Model with Tuned Hyperparameters\nIn this section, we will calibrate a model to predict HDB rental price by using random forest function and utilizing the most important predictors to focus on those that have the strongest relationships with rental price. By recalibrating based on variable importance, this approach seeks to improve both prediction accuracy and model interpretability.\n\nset.seed(1234)\nrf_tuned &lt;- ranger(monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + \n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_cbd,\n             data=train_data,\n             importance = \"permutation\",\n             mtry = 3,\n             min.node.size=10)\nrf_tuned\n\n\nwrite_rds(rf_tuned, \"data/rds/model/rf_tuned.rds\")\n\nThe code chunk below can be used to retrieve the save model in future.\n\nrf_tuned &lt;- read_rds(\"data/rds/model/rf_tuned.rds\")\n\n\n\n3.8.4 Calibrating Geographical Random Forest (GRF) Model\nThe code chunk below calibrate a geographic random forest model by using grf() of SpatialML package.\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = monthly_rent ~ \n                  flat_type + no_of_kindergarten_500m + \n                  no_of_childcare_500m + prox_hawker + prox_shoppingmall +\n                  prox_mrt + prox_cbd,\n                  dframe=train_data, \n                  bw=70,                   # Broader bandwidth\n                  kernel=\"adaptive\",\n                  ntree=350,\n                  coords=coords_train,\n                  min.node.size=10)  \n\nLet’s save the model output by using the code chunk below.\n\nwrite_rds(gwRF_adaptive, \"data/rds/model/gwRF_adaptive.rds\")\n\nThe code chunk below can be used to retrieve the save model in future.\n\ngwRF_adaptive &lt;- read_rds(\"data/rds/model/gwRF_adaptive.rds\")\n\n\ngwRF_adaptive\n\n\n\n\n\n\n\nNotes\n\n\n\nCalibrating 3 random forest models would give the user more options in determining how their HDB rental prices are predicted\n\n\n\nwrite_rds(train_data, \"data/rds/model/train_data_mod.rds\")\nwrite_rds(test_data, \"data/rds/model/test_data_mod.rds\")\n\n\ntrain_data &lt;- read_rds(\"data/rds/model/train_data_mod.rds\")\ntest_data &lt;- read_rds(\"data/rds/model/test_data_mod.rds\")"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#predicting-by-using-test-data",
    "href": "Take-home_ex/Take-home_ex03/Take-home_ex03.html#predicting-by-using-test-data",
    "title": "Take-home Exercise 3: Geographically Weighted Predictive Models: Rental price prediction based on location based data",
    "section": "3.9 Predicting by using test data",
    "text": "3.9 Predicting by using test data\n\n3.9.1 Preparing the test data\nTo prepare the test data for prediction, the test data is combined with the coordinates, and unnecessary geometry information is removed to streamline the dataset for the model.\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\n# Combine test data with coordinates and drop geometry\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\nNext, we verify that the test data contains all required variables:\n\n# Define the required variables\nrequired_vars &lt;- c(\"flat_type\", \"no_of_kindergarten_500m\", \n                   \"no_of_childcare_500m\", \"prox_hawker\", \n                   \"prox_shoppingmall\", \"prox_mrt\", \"prox_cbd\", \"X\", \"Y\")\n\n# Check which required variables are missing\nmissing_vars &lt;- setdiff(required_vars, names(test_data))\nif (length(missing_vars) &gt; 0) {\n  print(paste(\"Missing variables:\", paste(missing_vars, collapse = \", \")))\n} else {\n  print(\"All required variables are present.\")\n}\n\n[1] \"All required variables are present.\"\n\ntest_data_subset &lt;- test_data[, required_vars, drop = FALSE]\n\n\n\n3.9.2 Predicting with test data\nUsing the trained Random Forest models, rf_cal and rf_tuned, we proceed with rental value predictions on the test data.\n\nrf_pred_cal &lt;- predict(rf_cal, data = test_data_subset)\nrf_pred_tuned &lt;- predict(rf_tuned, data = test_data_subset)\n\nNext, predict.grf() of spatialML package will be used to predict the rental value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data_subset, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\nBefore moving on, let us save the output into rds files for future use.\n\nwrite_rds(rf_pred_cal, \"data/rds/model/rf_pred_cal.rds\")\nwrite_rds(rf_pred_tuned, \"data/rds/model/rf_pred_tuned.rds\")\nwrite_rds(gwRF_pred, \"data/rds/model/GRF_pred.rds\")\n\n\n\n3.9.3 Formatting Prediction Outputs\nThe output of the predict() and predict.grf() is a vector of predicted values. We will convert it into a data frame for further visualisation and analysis.\n\nrf_pred_cal &lt;- read_rds(\"data/rds/model/rf_pred_cal.rds\")\nrf_pred_tuned &lt;- read_rds(\"data/rds/model/rf_pred_tuned.rds\")\ngwRF_pred &lt;- read_rds(\"data/rds/model/GRF_pred.rds\")\n\n\nrf_pred_cal &lt;- as.data.frame(rf_pred_cal)\nrf_pred_tuned &lt;- as.data.frame(rf_pred_tuned)\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_data.\n\ntest_data_rpc &lt;- cbind(test_data, rf_pred_cal)\ntest_data_rpt &lt;- cbind(test_data, rf_pred_tuned)\ntest_data_gp &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_rpc, \"data/rds/model/test_data_rpc.rds\")\nwrite_rds(test_data_rpt, \"data/rds/model/test_data_rpt.rds\")\nwrite_rds(test_data_gp, \"data/rds/model/test_data_gp.rds\")\n\n\ntest_data_rpc &lt;- read_rds(\"data/rds/model/test_data_rpc.rds\")\ntest_data_rpt &lt;- read_rds(\"data/rds/model/test_data_rpt.rds\")\ntest_data_gp &lt;- read_rds(\"data/rds/model/test_data_gp.rds\")\n\n\n\n3.9.4 Evaluating Model Accuracy with RMSE and MAE\nThe Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) are used to assess the accuracy of the predictions by comparing the predicted values with the actual monthly rent.\n\n3.9.4.1 Accuracy of Random Forest (RF) Model\n\nrmse(test_data_rpc$monthly_rent, \n     test_data_rpc$prediction)\n\n[1] 543.6913\n\n\n\nmae(test_data_rpc$monthly_rent, \n     test_data_rpc$prediction)\n\n[1] 409.7593\n\n\n\n\n3.9.4.2 Accuracy of Random Forest (RF) Model with Tuned Hyperparameters\n\nrmse(test_data_rpt$monthly_rent, \n     test_data_rpt$prediction)\n\n[1] 538.4702\n\n\n\nmae(test_data_rpt$monthly_rent, \n     test_data_rpt$prediction)\n\n[1] 406.2413\n\n\n\n\n3.9.4.3 Accuracy of Geographical Random Forest (GRF) Model\n\nrmse(test_data_gp$monthly_rent, \n     test_data_gp$gwRF_pred)\n\n[1] 573.2705\n\n\n\nmae(test_data_gp$monthly_rent, \n     test_data_gp$gwRF_pred)\n\n[1] 431.0546\n\n\n\n\n\n3.9.5 Visualising the predicted values\nTo better visually assess model performance and make better comparisons between the models, scatterplots display the relationship between predicted and actual values. A well-performing model will show points clustering along the diagonal, indicating strong alignment between predictions and observations.\nPrior to creating the plots, we would first identify and remove duplicate columns (if any exist).\n\n3.9.5.1 Random Forest (RF) Model\n\n\nShow the code\nduplicate_columns &lt;- names(test_data_rpc)[duplicated(names(test_data_rpc))]\ntest_data_rpc &lt;- test_data_rpc[, !duplicated(names(test_data_rpc))]\n\n\n\nggplot(data = test_data_rpc, aes(x = prediction, y = monthly_rent)) +\n  geom_point(alpha = 0.6, color = \"blue\") +  # Adjust point transparency and color\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\", linetype = \"dashed\") +  # Best fit line\n  labs(title = \"Predicted Monthly Rent vs. Geographically Weighted RF Predictions\",\n       x = \"Geographically Weighted RF Predictions\",\n       y = \"Monthly Rent\")\n\n\n\n\n\n\n\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5),  # Center the title\n        axis.title = element_text(size = 12),  # Increase axis title size\n        axis.text = element_text(size = 10))   # Increase axis text size\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 12\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : num 10\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\n3.9.5.2 Random Forest (RF) Model with Tuned Hyperparameters\n\n\nShow the code\nduplicate_columns &lt;- names(test_data_rpt)[duplicated(names(test_data_rpt))]\ntest_data_rpt &lt;- test_data_rpt[, !duplicated(names(test_data_rpt))]\n\n\n\nggplot(data = test_data_rpt, aes(x = prediction, y = monthly_rent)) +\n  geom_point(alpha = 0.6, color = \"blue\") +  # Adjust point transparency and color\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\", linetype = \"dashed\") +  # Best fit line\n  labs(title = \"Predicted Monthly Rent vs. Geographically Weighted RF Predictions\",\n       x = \"Geographically Weighted RF Predictions\",\n       y = \"Monthly Rent\")\n\n\n\n\n\n\n\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5),  # Center the title\n        axis.title = element_text(size = 12),  # Increase axis title size\n        axis.text = element_text(size = 10))   # Increase axis text size\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 12\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : num 10\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\n3.9.5.3 Geographical Random Forest (GRF) Model\n\n\nShow the code\nduplicate_columns &lt;- names(test_data_gp)[duplicated(names(test_data_gp))]\ntest_data_gp &lt;- test_data_gp[, !duplicated(names(test_data_gp))]\n\n\n\nggplot(data = test_data_gp, aes(x = gwRF_pred, y = monthly_rent)) +\n  geom_point(alpha = 0.6, color = \"blue\") +  # Adjust point transparency and color\n  geom_smooth(method = \"lm\", se = TRUE, color = \"red\", linetype = \"dashed\") +  # Best fit line\n  labs(title = \"Predicted Monthly Rent vs. Geographically Weighted RF Predictions\",\n       x = \"Geographically Weighted RF Predictions\",\n       y = \"Monthly Rent\")\n\n\n\n\n\n\n\n  theme_minimal() + \n  theme(plot.title = element_text(hjust = 0.5),  # Center the title\n        axis.title = element_text(size = 12),  # Increase axis title size\n        axis.text = element_text(size = 10))   # Increase axis text size\n\nList of 136\n $ line                            :List of 6\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ lineend      : chr \"butt\"\n  ..$ arrow        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_line\" \"element\"\n $ rect                            :List of 5\n  ..$ fill         : chr \"white\"\n  ..$ colour       : chr \"black\"\n  ..$ linewidth    : num 0.5\n  ..$ linetype     : num 1\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_rect\" \"element\"\n $ text                            :List of 11\n  ..$ family       : chr \"\"\n  ..$ face         : chr \"plain\"\n  ..$ colour       : chr \"black\"\n  ..$ size         : num 11\n  ..$ hjust        : num 0.5\n  ..$ vjust        : num 0.5\n  ..$ angle        : num 0\n  ..$ lineheight   : num 0.9\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : logi FALSE\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ title                           : NULL\n $ aspect.ratio                    : NULL\n $ axis.title                      :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : num 12\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.75points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.top                :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.75points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.x.bottom             : NULL\n $ axis.title.y                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num 90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.75points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.title.y.left               : NULL\n $ axis.title.y.right              :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : num -90\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.75points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text                       :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : chr \"grey30\"\n  ..$ size         : num 10\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi FALSE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 1\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 2.2points 0points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.top                 :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : NULL\n  ..$ vjust        : num 0\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 2.2points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.x.bottom              : NULL\n $ axis.text.y                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 1\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 0points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.y.left                : NULL\n $ axis.text.y.right               :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 0points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.text.theta                 : NULL\n $ axis.text.r                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0.5\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : 'margin' num [1:4] 0points 2.2points 0points 2.2points\n  .. ..- attr(*, \"unit\")= int 8\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ axis.ticks                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.ticks.x                    : NULL\n $ axis.ticks.x.top                : NULL\n $ axis.ticks.x.bottom             : NULL\n $ axis.ticks.y                    : NULL\n $ axis.ticks.y.left               : NULL\n $ axis.ticks.y.right              : NULL\n $ axis.ticks.theta                : NULL\n $ axis.ticks.r                    : NULL\n $ axis.minor.ticks.x.top          : NULL\n $ axis.minor.ticks.x.bottom       : NULL\n $ axis.minor.ticks.y.left         : NULL\n $ axis.minor.ticks.y.right        : NULL\n $ axis.minor.ticks.theta          : NULL\n $ axis.minor.ticks.r              : NULL\n $ axis.ticks.length               : 'simpleUnit' num 2.75points\n  ..- attr(*, \"unit\")= int 8\n $ axis.ticks.length.x             : NULL\n $ axis.ticks.length.x.top         : NULL\n $ axis.ticks.length.x.bottom      : NULL\n $ axis.ticks.length.y             : NULL\n $ axis.ticks.length.y.left        : NULL\n $ axis.ticks.length.y.right       : NULL\n $ axis.ticks.length.theta         : NULL\n $ axis.ticks.length.r             : NULL\n $ axis.minor.ticks.length         : 'rel' num 0.75\n $ axis.minor.ticks.length.x       : NULL\n $ axis.minor.ticks.length.x.top   : NULL\n $ axis.minor.ticks.length.x.bottom: NULL\n $ axis.minor.ticks.length.y       : NULL\n $ axis.minor.ticks.length.y.left  : NULL\n $ axis.minor.ticks.length.y.right : NULL\n $ axis.minor.ticks.length.theta   : NULL\n $ axis.minor.ticks.length.r       : NULL\n $ axis.line                       : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ axis.line.x                     : NULL\n $ axis.line.x.top                 : NULL\n $ axis.line.x.bottom              : NULL\n $ axis.line.y                     : NULL\n $ axis.line.y.left                : NULL\n $ axis.line.y.right               : NULL\n $ axis.line.theta                 : NULL\n $ axis.line.r                     : NULL\n $ legend.background               : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.margin                   : 'margin' num [1:4] 5.5points 5.5points 5.5points 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing                  : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n $ legend.spacing.x                : NULL\n $ legend.spacing.y                : NULL\n $ legend.key                      : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.key.size                 : 'simpleUnit' num 1.2lines\n  ..- attr(*, \"unit\")= int 3\n $ legend.key.height               : NULL\n $ legend.key.width                : NULL\n $ legend.key.spacing              : 'simpleUnit' num 5.5points\n  ..- attr(*, \"unit\")= int 8\n $ legend.key.spacing.x            : NULL\n $ legend.key.spacing.y            : NULL\n $ legend.frame                    : NULL\n $ legend.ticks                    : NULL\n $ legend.ticks.length             : 'rel' num 0.2\n $ legend.axis.line                : NULL\n $ legend.text                     :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : 'rel' num 0.8\n  ..$ hjust        : NULL\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.text.position            : NULL\n $ legend.title                    :List of 11\n  ..$ family       : NULL\n  ..$ face         : NULL\n  ..$ colour       : NULL\n  ..$ size         : NULL\n  ..$ hjust        : num 0\n  ..$ vjust        : NULL\n  ..$ angle        : NULL\n  ..$ lineheight   : NULL\n  ..$ margin       : NULL\n  ..$ debug        : NULL\n  ..$ inherit.blank: logi TRUE\n  ..- attr(*, \"class\")= chr [1:2] \"element_text\" \"element\"\n $ legend.title.position           : NULL\n $ legend.position                 : chr \"right\"\n $ legend.position.inside          : NULL\n $ legend.direction                : NULL\n $ legend.byrow                    : NULL\n $ legend.justification            : chr \"center\"\n $ legend.justification.top        : NULL\n $ legend.justification.bottom     : NULL\n $ legend.justification.left       : NULL\n $ legend.justification.right      : NULL\n $ legend.justification.inside     : NULL\n $ legend.location                 : NULL\n $ legend.box                      : NULL\n $ legend.box.just                 : NULL\n $ legend.box.margin               : 'margin' num [1:4] 0cm 0cm 0cm 0cm\n  ..- attr(*, \"unit\")= int 1\n $ legend.box.background           : list()\n  ..- attr(*, \"class\")= chr [1:2] \"element_blank\" \"element\"\n $ legend.box.spacing              : 'simpleUnit' num 11points\n  ..- attr(*, \"unit\")= int 8\n  [list output truncated]\n - attr(*, \"class\")= chr [1:2] \"theme\" \"gg\"\n - attr(*, \"complete\")= logi TRUE\n - attr(*, \"validate\")= logi TRUE\n\n\n\n\n\n\n\n\nNotes\n\n\n\nWith the different predictive models, users can choose the model that best fits their specific needs, depending on their requirements for accuracy, interpretability, or spatial relevance. Each model provides distinct benefits:\n\nStandard Random Forest (RF): Offers a straightforward approach, balancing interpretability and predictive power with little calibration. It’s useful for users looking for a quick and reliable model without the need for significant adjustments.\nTuned Random Forest (RF with Tuned Hyperparameters): By focusing on the most impactful predictors and fine-tuning parameters like mtry and min.node.size, this model aims to achieve higher prediction accuracy. This is ideal for users who want an optimized model for maximum performance.\nGeographic Random Forest (GRF): The geographically weighted RF model accounts for spatial differences in predictor effects, making it ideal for predictions where location plays a critical role, such as real estate or environmental modeling. Users interested in localized predictions would find this model particularly beneficial.\n\n\n\n\n\n\n3.9.6 Summary and Practical Application\nEach calibrated model provides a different lens through which HDB rental prices can be understood and predicted. For practical application:\n\nFor general insights, the Standard RF model may suffice.\nFor users seeking finer accuracy in specific feature relationships, the Tuned RF model provides a refined approach.\nFor users interested in spatial variation, the GRF model offers insights into how geographical context influences rent, making it highly applicable to real estate forecasting.\n\n\n\n3.9.7 UI Design\n\n3.9.7.1 Scatterplot Model Analysis\nUsers would be able to explore the scatterplot model analysis of the various models. This setup allows users to visualise the comparison of RF models directly within the main panel and reference selection guidance. Only one plot is shown at a time, based on their selection, so as to not overwhelm them.\n\n\n\n3.9.7.2 Predictive Models\nThe guide section provides users with step-by-step instructions on how to navigate the UI, making the interface more intuitive.\nThe side panel (and the Map section for Geospatial model types) would simulate the functions of a calculator, where users would be able to input certain aspects of the their ideal HDB rental location to determine a likely monthly rental cost. Together this would provide users with a clearer understanding of how to interact with the tool and a polished output section for viewing predictions\nThis approach aims to provide a dynamic and intuitive way to input model parameters and view rental price predictions for different HDB flats in Singapore.\n\n\nAspatial Model Type\n\n\n\nGeospatial Model Type"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html",
    "href": "Take-home_ex/Take-home_ex01.html",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nIn this study, I will apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#exercise-overview",
    "href": "Take-home_ex/Take-home_ex01.html#exercise-overview",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "",
    "text": "Millions of people have their lives shattered by armed conflict – wars – every year.\nArmed conflict has been on the rise since about 2012, after a decline in the 1990s and early 2000s. First came conflicts in Libya, Syria and Yemen, triggered by the 2011 Arab uprisings. Libya’s instability spilled south, helping set off a protracted crisis in the Sahel region. A fresh wave of major combat followed: the 2020 Azerbaijani-Armenian war over the Nagorno-Karabakh enclave, horrific fighting in Ethiopia’s northern Tigray region that began weeks later, the conflict prompted by the Myanmar army’s 2021 power grab and Russia’s 2022 assault on Ukraine. Add to those 2023’s devastation in Sudan and Gaza. Around the globe, more people are dying in fighting, being forced from their homes or in need of life-saving aid than in decades.\nIn this study, I will apply spatial point patterns analysis methods to discover the spatial and spatio-temporal distribution of armed conflict in Myanmar."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#data-acquisition",
    "href": "Take-home_ex/Take-home_ex01.html#data-acquisition",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nThe data sets that we will be using are the following: - Armed conflict data of Myanmar between 2021-2024. This data can be downloaded from Armed Conflict Location & Event Data ACLED, an independent, impartial, international non-profit organization collecting data on violent conflict and protest in all countries and territories in the world, should be used. - The shapefile of the Myanmar State and Region Boundaries with Sub-regions. This data can be downloaded from Myanmar Information Management Unit, MIMU."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#getting-started",
    "href": "Take-home_ex/Take-home_ex01.html#getting-started",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nraster, a package for reading, writing, manipulating, and modeling gridded spatial data (rasters). We will use it to convert image outputs generated by spatstat into raster format.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nRColorBrewer for creating nice looking color palettes especially for thematic maps.\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, RColorBrewer, lubridate, ggplot2, parallel, sparr, magick)"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#importing-data-into-r",
    "href": "Take-home_ex/Take-home_ex01.html#importing-data-into-r",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.4 Importing Data into R",
    "text": "1.4 Importing Data into R\nNext, we will import the ACLED-Southeast_Asia-Myanmar(1).csv file into the R environment and save it into an R dataframe called acled_sf. The task can be performed using the read_csv() function from the readr package, as shown below:\n\nacled_sf &lt;- read_csv(\"data/ACLED-Southeast_Asia-Myanmar(1).csv\") %&gt;% \n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs= 32647)%&gt;%\n  mutate(event_date = dmy(event_date)) %&gt;%\n  mutate(quarter = paste0(year, \" Q\", quarter(event_date)))\n\n\n\n\n\n\n\nNotes\n\n\n\nWe used the mutate() function to ensure that the event_data column is in the right format of dmy(), while also creating a quarter column to represent the current  that the row belongs to\n\n\nWe can check the validity of the imported dataset, ensuring that it is in the right format with the st_crs() and summary() function:\n\nst_crs(acled_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32647 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 47N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 47N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",99,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Navigation and medium accuracy spatial referencing.\"],\n        AREA[\"Between 96°E and 102°E, northern hemisphere between equator and 84°N, onshore and offshore. China. Indonesia. Laos. Malaysia - West Malaysia. Mongolia. Myanmar (Burma). Russian Federation. Thailand.\"],\n        BBOX[0,96,84,102]],\n    ID[\"EPSG\",32647]]\n\n\n\nsummary(acled_sf)\n\n event_id_cnty        event_date              year      time_precision \n Length:42608       Min.   :2021-01-01   Min.   :2021   Min.   :1.000  \n Class :character   1st Qu.:2022-01-10   1st Qu.:2022   1st Qu.:1.000  \n Mode  :character   Median :2022-10-13   Median :2022   Median :1.000  \n                    Mean   :2022-10-29   Mean   :2022   Mean   :1.053  \n                    3rd Qu.:2023-08-29   3rd Qu.:2023   3rd Qu.:1.000  \n                    Max.   :2024-06-30   Max.   :2024   Max.   :3.000  \n disorder_type       event_type        sub_event_type        actor1         \n Length:42608       Length:42608       Length:42608       Length:42608      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n assoc_actor_1          inter1         actor2          assoc_actor_2     \n Length:42608       Min.   :1.000   Length:42608       Length:42608      \n Class :character   1st Qu.:1.000   Class :character   Class :character  \n Mode  :character   Median :1.000   Mode  :character   Mode  :character  \n                    Mean   :1.947                                        \n                    3rd Qu.:3.000                                        \n                    Max.   :8.000                                        \n     inter2       interaction    civilian_targeting      iso     \n Min.   :0.000   Min.   :10.00   Length:42608       Min.   :104  \n 1st Qu.:1.000   1st Qu.:13.00   Class :character   1st Qu.:104  \n Median :3.000   Median :17.00   Mode  :character   Median :104  \n Mean   :3.597   Mean   :18.86                      Mean   :104  \n 3rd Qu.:7.000   3rd Qu.:17.00                      3rd Qu.:104  \n Max.   :8.000   Max.   :80.00                      Max.   :104  \n    region            country             admin1             admin2         \n Length:42608       Length:42608       Length:42608       Length:42608      \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n    admin3            location         geo_precision      source         \n Length:42608       Length:42608       Min.   :1.000   Length:42608      \n Class :character   Class :character   1st Qu.:1.000   Class :character  \n Mode  :character   Mode  :character   Median :1.000   Mode  :character  \n                                       Mean   :1.495                     \n                                       3rd Qu.:2.000                     \n                                       Max.   :3.000                     \n source_scale          notes             fatalities         tags          \n Length:42608       Length:42608       Min.   :  0.00   Length:42608      \n Class :character   Class :character   1st Qu.:  0.00   Class :character  \n Mode  :character   Mode  :character   Median :  0.00   Mode  :character  \n                                       Mean   :  1.27                     \n                                       3rd Qu.:  1.00                     \n                                       Max.   :201.00                     \n   timestamp                  geometry       quarter         \n Min.   :1.611e+09   POINT        :42608   Length:42608      \n 1st Qu.:1.702e+09   epsg:32647   :    0   Class :character  \n Median :1.714e+09   +proj=utm ...:    0   Mode  :character  \n Mean   :1.702e+09                                           \n 3rd Qu.:1.719e+09                                           \n Max.   :1.726e+09                                           \n\n\nWe then import the boundaries and regions of Myanmar using the st_read() function to import the mmr_polbnda2_adm1_250k_mimu_1 shapefile into R as a simple feature data frame named regions_sf:\n\nregions_sf &lt;- st_read(dsn = \"data/myanmar\", \n                layer = \"mmr_polbnda2_adm1_250k_mimu_1\")\n\nReading layer `mmr_polbnda2_adm1_250k_mimu_1' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\myanmar' \n  using driver `ESRI Shapefile'\nSimple feature collection with 18 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.1721 ymin: 9.696844 xmax: 101.17 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\nregions_sf &lt;- st_transform(regions_sf, crs = 32647)\n\n\n\n\n\n\n\nNotes\n\n\n\nThe acled_sf and regions_sf data are being transformed to EPSG 32647, which corresponds to UTM Zone 47N. This CSR is fine for Myanmar. This consistency also ensures that the UTM zone transformation makes sense for the study area, and prevents any distortion in KDE results.\n\n\nAfter importing the boundary and region data, we can check that what was imported is correct by checking the summary and plotting the views:\n\nSummaryDetailed Regional View\n\n\n\nsummary(regions_sf)\n\n    OBJECTID          ST              ST_PCODE            ST_RG          \n Min.   : 1.00   Length:18          Length:18          Length:18         \n 1st Qu.: 5.25   Class :character   Class :character   Class :character  \n Median : 9.50   Mode  :character   Mode  :character   Mode  :character  \n Mean   : 9.50                                                           \n 3rd Qu.:13.75                                                           \n Max.   :18.00                                                           \n    ST_MMR             PCode_V             geometry \n Length:18          Min.   :9.4   MULTIPOLYGON :18  \n Class :character   1st Qu.:9.4   epsg:32647   : 0  \n Mode  :character   Median :9.4   +proj=utm ...: 0  \n                    Mean   :9.4                     \n                    3rd Qu.:9.4                     \n                    Max.   :9.4                     \n\n\n\n\n\nnum_colors &lt;- length(unique(regions_sf$ST))\ncolors &lt;- brewer.pal(n = num_colors, name = \"Set1\")\n\ntm_shape(regions_sf) +\n  tm_polygons(col = \"ST\", palette = colors) +\n  tm_text(\"ST\", size = 0.9, col = \"black\", bg.color = \"white\", \n          just = c(\"center\", \"center\"), xmod = 0, ymod = 0) +\n  tm_layout(main.title = \"Region and Boundaries in Myanmar\",\n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_legend(title = \"Sub-regions\")\n\n\n\n\n\n\n\n\n\n\n\n\n1.4.1 Focused Event Types\nFor the study, we focus on the following four event types from the ACLED dataset for Myanmar:\n\nBattles\nStrategic developments\nViolence against civilians\nExplosion/Remote violence\n\nThe study period spans from January 2021 to June 2024, broken down into quarterly intervals. We aim to visualize and analyze the spatial distribution of these armed conflict events in Myanmar.\nThe following function is used to generate spatial point pattern plots for each event type within the defined region throughout the stated time span:\n\n# Function to create combined events object with owin object\nplot_event_by_quarter &lt;- function(event_data, event_name) {\n  quarter_data_ppp &lt;- as.ppp(st_coordinates(event_data), st_bbox(event_data))\n  regions_owin &lt;- as.owin(regions_sf)\n  quarter_data_regions_ppp = quarter_data_ppp[regions_owin]\n  \n  plot(quarter_data_regions_ppp,\n     main = paste(\"Events in Myanmar -\", event_name, \"(2021 - 2024)\"),\n     xlab = \"Longitude\", ylab = \"Latitude\")\n}\n\n\n# Get a list of unique quarters\nevents &lt;- unique(acled_sf$event_type)\n\n# Loop over each quarter and generate the plot\nmap(events, ~ {\n  event_data &lt;- acled_sf %&gt;% filter(event_type == .x)\n  plot_event_by_quarter(event_data, .x)\n})\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n[[1]]\nSymbol map with constant values\ncols: #00000033\n\n[[2]]\nSymbol map with constant values\ncols: #00000033\n\n[[3]]\nSymbol map with constant values\ncols: #00000033\n\n[[4]]\nSymbol map with constant values\ncols: #00000033\n\n\n\n\n1.4.2 Storing key data\nWe will store key data sets intermittently to keep track of key data.\n\nwrite_rds(acled_sf, \"data/rds/acled_sf.rds\")\nwrite_rds(regions_sf, \"data/rds/regions_sf.rds\")"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#determining-kde-layer",
    "href": "Take-home_ex/Take-home_ex01.html#determining-kde-layer",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.5 Determining KDE Layer",
    "text": "1.5 Determining KDE Layer\n\n1.5.1 Choosing Sample Dataset\nIn this section, we focus on determining the appropriate Kernel Density Estimate (KDE) layer format for analyzing the spatial distribution of events across different quarters and event types. KDE is a fundamental tool for identifying patterns of spatial clustering and dispersion, providing a smooth surface that highlights areas of high and low event concentration. The selection of an appropriate bandwidth is crucial, as it influences the level of detail and accuracy in the density estimate. By standardizing the KDE layer format, we aim to ensure consistency and comparability throughout the analysis, particularly using the Violence against civilians event type as a reference for refining our approach.\n\nExample &lt;- \"Violence against civilians\"\nacled_2021 &lt;- acled_sf %&gt;%\n  filter(event_type == Example & year == 2021)\nyear_data &lt;- as_Spatial(acled_2021)\nregions &lt;- as_Spatial(regions_sf)\n\nyear_data_sp &lt;- as(year_data, \"SpatialPoints\")\nregions_sp &lt;- as(regions, \"SpatialPolygons\")\n\nyear_data_ppp &lt;- as.ppp(st_coordinates(acled_2021), st_bbox(acled_2021))\nyear_data_ppp\n\nPlanar point pattern: 1877 points\nwindow: rectangle = [-191409.1, 591875.9] x [1132472.1, 3042960.3] units\n\n\n\nany(duplicated(year_data_ppp))\n\n[1] TRUE\n\n\nAs there are duplicate points, we will use jittering to slightly displace the points so that overlapping points are separated on the map. The jitter parameter will slightly move each point by a small, random amount. This can help to visually separate points that are in the same space.\n\nyear_data_ppp_jit &lt;- rjitter(year_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\nany(duplicated(year_data_ppp_jit))\n\n[1] FALSE\n\n\n\n\n1.5.2 Creating Owin Object\nTo confine analysis to a geographical area, convert the SpatialPolygon object to an owin object of spatstat:\n\nregions_owin &lt;- as.owin(regions_sf)\n\nyear_data_regions_ppp = year_data_ppp_jit[regions_owin]\n\n\nplot(year_data_regions_ppp)\n\n\n\n\n\n\n\n\nDue to the size of Myanmar, rescaling would need to be done:\n\nyear_data_regions_ppp.km &lt;- rescale.ppp(year_data_regions_ppp, 50000, \"km\")\n\n\n\n1.5.3 Working With Different Automatic Bandwidth Methods\nThe density() function from the spatstat package computes the kernel density estimate for a given set of spatial point events, providing insights into the spatial distribution of those events.\n\nbw.diggle(): This method selects the bandwidth (σ) by minimizing the mean-square error, as defined by Diggle (1985). The mean-square error measures the average squared difference between the estimated and actual values, aiming to reduce errors in the density estimate.\nbw.CvL(): Cronie and van Lieshout’s method selects the bandwidth by minimizing the discrepancy between the area of the observation window and the sum of reciprocal estimated intensity values at the event points. It balances the observed points and the space they occupy, capturing the underlying point process effectively.\nbw.scott(): Scott’s rule, a fast and computationally efficient method, calculates the bandwidth proportional to \\((n^{-\\frac{1}{d+4}})\\), where (n) is the number of points and (d) the spatial dimensions. It typically produces a larger bandwidth and is ideal for detecting gradual trends.\nbw.ppl(): This method selects the bandwidth through likelihood cross-validation, maximizing the point process likelihood to provide the best-fitting model for the observed data, particularly when the goal is to optimize the likelihood of the given event distribution.\n\n\nbw_CvL &lt;- bw.CvL(year_data_regions_ppp.km)\nbw_CvL\n\n   sigma \n1.326217 \n\n\n\nbw_scott &lt;- bw.scott(year_data_regions_ppp.km)\nbw_scott\n\n  sigma.x   sigma.y \n0.6923824 1.8282864 \n\n\n\nbw_ppl &lt;- bw.ppl(year_data_regions_ppp.km)\nbw_ppl\n\n    sigma \n0.1678648 \n\n\n\nbw_diggle &lt;- bw.diggle(year_data_regions_ppp.km)\nbw_diggle\n\n     sigma \n0.02286341 \n\n\n\nkde_diggle &lt;- density(year_data_regions_ppp.km, bw_diggle)\nkde_CvL &lt;- density(year_data_regions_ppp.km, bw_CvL)\nkde_scott &lt;- density(year_data_regions_ppp.km, bw_scott)\nkde_ppl &lt;- density(year_data_regions_ppp.km, bw_ppl)\n\npar(mar = c(2, 2, 2, 2),mfrow = c(2,2))\nplot(kde_diggle, main = \"kde_diggle\")\nplot(kde_CvL, main = \"kde_CvL\")\nplot(kde_scott, main = \"kde_scott\")\nplot(kde_ppl, main = \"kde_ppl\")\n\n\n\n\n\n\n\n\n\npar(mar = c(2,2,2,2),mfrow = c(2,2))\nhist(kde_diggle, main = \"kde_diggle\")\nhist(kde_CvL, main = \"kde_CvL\")\nhist(kde_scott, main = \"kde_scott\")\nhist(kde_ppl, main = \"kde_ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nBandwidth Selection Comparison for KDE:\n\nkde_diggle: The sharp peak at the beginning indicates that the Diggle method for bandwidth selection has identified a concentrated cluster of points in the initial bin. The remaining bins show little to no concentration, suggesting a significant level of spatial clustering in one specific area within the observation window. This method may highlight a localized, high-intensity clustering effect.\nkde_CvL: The left-skewed, more balanced distribution suggests that the CvL method is identifying a broader range of spatial concentrations. However, the smaller bin sizes smooth out finer details, which could mask important aspects of the point pattern. This method provides a more generalized view of the distribution but at the cost of losing granular insights.\nkde_scott: The wider range of values and the absence of a sharp peak, compared to kde_diggle, indicates that the Scott method is capturing both highly dense clusters and moderately concentrated areas. This makes it more suitable for capturing variations in spatial concentration across different regions.\nkde_ppl: Similar to the Diggle method, kde_ppl shows a sharp peak, suggesting the presence of a high concentration of points in a specific region. This points to a localized cluster, but with a similar potential risk of missing broader patterns in the dataset.\n\n\n\n\ndse_diggle &lt;- density(year_data_regions_ppp.km, bw_diggle, se=TRUE)$SE\ndse_CvL &lt;- density(year_data_regions_ppp.km, bw_CvL, se=TRUE)$SE\ndse_scott &lt;- density(year_data_regions_ppp.km, bw_scott, se=TRUE)$SE\ndse_ppl &lt;- density(year_data_regions_ppp.km, bw_ppl, se=TRUE)$SE\n\n\npar(mar = c(2,2,2,2),mfrow = c(2,2))\nplot(dse_diggle,main = \"standard error_diggle\")\nplot(dse_CvL,main = \"standard error_CvL\")\nplot(dse_scott,main = \"standard error_scott\")\nplot(dse_ppl,main = \"standard error_ppl\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nConsideration of Standard Error:\nWhile the standard error (SE) of the density estimate provides valuable insight into the uncertainty associated with each density estimate, it is not the primary focus of this analysis. The shape of the density estimate, rather than its absolute value, is more critical when analyzing spatial patterns. Consequently, the SE was not used as a key criterion for bandwidth selection in this analysis.\nConsideration of Standard Error: While the standard error (SE) of the density estimate provides valuable insight into the uncertainty associated with each density estimate, it is not the primary focus of this analysis. The shape of the density estimate, rather than its absolute value, is more critical when analyzing spatial patterns. Consequently, the SE was not used as a key criterion for bandwidth selection in this analysis.\n\n\n\n\n1.5.4 Final Bandwidth Selection\nUpon the exploration of various fixed bandwidth selection methods for computing KDE vales, and subsequent plotting of the respective KDE estimates, their distributions and associated standard errors, we will now select the KDE bandwidth to be used in our analysis.\nWe landed on the bw_scott method for further analysis. This is because:\n\nbw_scott method provides a pair of bandwidth values for each coordinate axis. This allows it to capture the different levels of spatial clustering in each direction more accurately.\nbw_scott method capture the balance between bias and variance the best among all methods. If the bandwidth is too small, the estimate may be too skewed (high variance). The distribution histograms of KDE layers using bw_diggle and bw_ppl tend to indicate such nature. On the other hand, if the bandwidth is too large, the estimate may be over smoothed, missing crucial elements of the point pattern (high bias). This is what we observed in the distribution histogram of KDE layer using bw_CvL.\n\nSince we have chosen to use bw_scott method, now we will plot the KDE layer using this method for further analysis.\n\n1.5.4.1 Working With Different Kernel Methods\nBeyond the Gaussian kernel, three other kernels can be used to compute KDE: - Epanechnikov - Quartic - Disc\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(year_data_regions_ppp.km, \n             sigma=bw_scott, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nUpon comparing the outputs of different kernel functions (Gaussian, Epanechnikov, Quartic, Disc), we observed that the resulting density estimates were very similar across all kernels. Given the minimal variation, the choice of kernel is not critical for this particular analysis.\nWe opted for the Gaussian kernel as it is widely used in kernel density estimation and tends to produce smooth, continuous estimates. Its flexibility in capturing both sharp peaks and gradual trends makes it a reasonable default choice, especially when the differences between kernels are negligible, as seen here.\n\n\n\nkde_fixed_scott &lt;- density(year_data_regions_ppp.km, bw_scott)\nplot(kde_fixed_scott,main = \"Fixed bandwidth KDE (Using bw_scott)\")\ncontour(kde_fixed_scott, add=TRUE)\n\n\n\n\n\n\n\n\nHowever, upon visual inspection, there are signs of a certain degree of over-smoothing when directly applying the bandwidth provided by the bw_scott method. While automatic bandwidth selection methods offer a useful starting point, further fine-tuning is often necessary to ensure the accuracy of the KDE plot.\nTo address the over-smoothing, we will apply a “rule of thumb” adjustment by dividing the bandwidth value by 2. This reduction in bandwidth size will help minimize the over-smoothing effect and enhance the precision of the spatial point pattern analysis.\n\nkde_year_data_regions_fixed_scott &lt;- density(year_data_regions_ppp.km, bw_scott/2)\nkde_year_data_regions_adaptive &lt;- adaptive.density(year_data_regions_ppp.km, method=\"kernel\")\n\npar(mfrow=c(1,2))\nplot(kde_year_data_regions_fixed_scott, main = \"Fixed Bandwidth (bw_scott)\")\nplot(kde_year_data_regions_adaptive, main = \"Adaptive Bandwidth\")\n\n\n\n\n\n\n\n\n\n\n1.5.4.2 Plotting Interactive KDE Maps\n\nraster_kde_fixed_scott &lt;- raster(kde_year_data_regions_fixed_scott)\nraster_kde_adaptive_kernel &lt;- raster(kde_year_data_regions_adaptive)\n\n# Set the correct CRS for the raster (EPSG:32647)\nprojection(raster_kde_fixed_scott) &lt;- CRS(\"+init=EPSG:32647 +units=km\")\nprojection(raster_kde_adaptive_kernel) &lt;- CRS(\"+init=EPSG:32647 +units=km\")\n\n\ntmap_mode('view')\n\nkde_fixed_scott &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_fixed_scott) +\n  tm_raster(\"layer\",\n            n = 10,\n            title = \"KDE_Fixed_scott\",\n            alpha = 0.6,\n            palette = c(\"#fafac3\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(regions_sf) +  # Transform only for visualization\n  tm_polygons(alpha=0.1, id=\"ST_PCODE\") +\n  tmap_options(check.and.fix = TRUE)\n\nkde_adaptive_kernel &lt;- tm_basemap(server = \"OpenStreetMap\") +\n  tm_basemap(server = \"Esri.WorldImagery\") +\n  tm_shape(raster_kde_adaptive_kernel) +\n  tm_raster(\"layer\",\n            n = 7,\n            title = \"KDE_Adaptive_Kernel\",\n            style = \"pretty\",\n            alpha = 0.6,\n            palette = c(\"#fafac3\",\"#fd953b\",\"#f02a75\",\"#b62385\",\"#021c9e\")) +\n  tm_shape(regions_sf) +  # Transform only for visualization\n  tm_polygons(alpha=0.1, id=\"ST_PCODE\") +\n  tmap_options(check.and.fix = TRUE)\n\ntmap_arrange(kde_fixed_scott, kde_adaptive_kernel, ncol=1, nrow=2, sync = TRUE)\n\n\n\n\n\n\n\nReflection\n\n\n\nAfter comparing the two approaches for kernel density estimation, Fixed Bandwidth using bw_scott/2 and Adaptive Bandwidth, we observed that the fixed bandwidth method provides a more stable and interpretable result across the observation window. While adaptive bandwidth is designed to adjust to local point densities and capture finer details, it can sometimes introduce unnecessary complexity and overfit the density estimate, especially in areas with sparse data.\nGiven the goals of our analysis, which emphasize consistency and smoothness over high local sensitivity, the Fixed Bandwidth approach strikes a better balance between capturing spatial trends and avoiding over-complication.\n\n\n\n\n1.5.4.3 Viewing Quarterly KDE Maps\n\n\n\nYear 2021\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\n\nwrite_rds(my_2021_Q1, \"data/rds/my_2021_Q1_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\n\nwrite_rds(my_2021_Q1, \"data/rds/my_2021_Q1_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_SD_quarter_data_regions_ppp , 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\n\nwrite_rds(my_2021_Q1, \"data/rds/my_2021_Q1_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q1\")\n\nwrite_rds(my_2021_Q1, \"data/rds/my_2021_Q1_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q1), st_bbox(my_2021_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\n\nwrite_rds(my_2021_Q2, \"data/rds/my_2021_Q2_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\n\nwrite_rds(my_2021_Q2, \"data/rds/my_2021_Q2_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\n\nwrite_rds(my_2021_Q2, \"data/rds/my_2021_Q2_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q2\")\n\nwrite_rds(my_2021_Q2, \"data/rds/my_2021_Q2_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q2), st_bbox(my_2021_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\n\nwrite_rds(my_2021_Q3, \"data/rds/my_2021_Q3_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\n\nwrite_rds(my_2021_Q3, \"data/rds/my_2021_Q3_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\n\nwrite_rds(my_2021_Q3, \"data/rds/my_2021_Q3_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q3\")\n\nwrite_rds(my_2021_Q3, \"data/rds/my_2021_Q3_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q3), st_bbox(my_2021_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\n\nwrite_rds(my_2021_Q4, \"data/rds/my_2021_Q4_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\n\nwrite_rds(my_2021_Q4, \"data/rds/my_2021_Q4_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\n\nwrite_rds(my_2021_Q4, \"data/rds/my_2021_Q4_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2021_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2021 Q4\")\n\nwrite_rds(my_2021_Q4, \"data/rds/my_2021_Q4_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2021_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2021_Q4), st_bbox(my_2021_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2021_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2021_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2021 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2022\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\n\nwrite_rds(my_2022_Q1, \"data/rds/my_2022_Q1_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\n\nwrite_rds(my_2022_Q1, \"data/rds/my_2022_Q1_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\n\nwrite_rds(my_2022_Q1, \"data/rds/my_2022_Q1_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q1\")\n\nwrite_rds(my_2022_Q1, \"data/rds/my_2022_Q1_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q1), st_bbox(my_2022_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\n\nwrite_rds(my_2022_Q2, \"data/rds/my_2022_Q2_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\n\nwrite_rds(my_2022_Q2, \"data/rds/my_2022_Q2_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\n\nwrite_rds(my_2022_Q2, \"data/rds/my_2022_Q2_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q2\")\n\nwrite_rds(my_2022_Q2, \"data/rds/my_2022_Q2_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q2), st_bbox(my_2022_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\n\nwrite_rds(my_2022_Q3, \"data/rds/my_2022_Q3_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\n\nwrite_rds(my_2022_Q3, \"data/rds/my_2022_Q3_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\n\nwrite_rds(my_2022_Q3, \"data/rds/my_2022_Q3_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q3\")\n\nwrite_rds(my_2022_Q3, \"data/rds/my_2022_Q3_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q3), st_bbox(my_2022_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\n\nwrite_rds(my_2022_Q4, \"data/rds/my_2022_Q4_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\n\nwrite_rds(my_2022_Q4, \"data/rds/my_2022_Q4_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\n\nwrite_rds(my_2022_Q4, \"data/rds/my_2022_Q4_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2022_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2022 Q4\")\n\nwrite_rds(my_2022_Q4, \"data/rds/my_2022_Q4_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2022_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2022_Q4), st_bbox(my_2022_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2022_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2022_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2022 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2023\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\n\nwrite_rds(my_2023_Q1, \"data/rds/my_2023_Q1_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\n\nwrite_rds(my_2023_Q1, \"data/rds/my_2023_Q1_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\n\nwrite_rds(my_2023_Q1, \"data/rds/my_2023_Q1_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q1\")\n\nwrite_rds(my_2023_Q1, \"data/rds/my_2023_Q1_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q1), st_bbox(my_2023_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\n\nwrite_rds(my_2023_Q2, \"data/rds/my_2023_Q2_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\n\nwrite_rds(my_2023_Q2, \"data/rds/my_2023_Q2_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\n\nwrite_rds(my_2023_Q2, \"data/rds/my_2023_Q2_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q2\")\n\nwrite_rds(my_2023_Q2, \"data/rds/my_2023_Q2_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q2), st_bbox(my_2023_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q2 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 3\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\n\nwrite_rds(my_2023_Q3, \"data/rds/my_2023_Q3_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\n\nwrite_rds(my_2023_Q3, \"data/rds/my_2023_Q3_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\n\nwrite_rds(my_2023_Q3, \"data/rds/my_2023_Q3_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q3 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q3\")\n\nwrite_rds(my_2023_Q3, \"data/rds/my_2023_Q3_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q3)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q3), st_bbox(my_2023_Q3))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q3_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q3_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q3 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 4\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\n\nwrite_rds(my_2023_Q4, \"data/rds/my_2023_Q4_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\n\nwrite_rds(my_2023_Q4, \"data/rds/my_2023_Q4_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\n\nwrite_rds(my_2023_Q4, \"data/rds/my_2023_Q4_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2023_Q4 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2023 Q4\")\n\nwrite_rds(my_2023_Q4, \"data/rds/my_2023_Q4_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2023_Q4)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2023_Q4), st_bbox(my_2023_Q4))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2023_Q4_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2023_Q4_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2023 Q4 - Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYear 2024\n\nQuarter 1\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\n\nwrite_rds(my_2024_Q1, \"data/rds/my_2024_Q1_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\n\nwrite_rds(my_2024_Q1, \"data/rds/my_2024_Q1_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\n\nwrite_rds(my_2024_Q1, \"data/rds/my_2024_Q1_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2024_Q1 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q1\")\n\nwrite_rds(my_2024_Q1, \"data/rds/my_2024_Q1_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q1)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q1), st_bbox(my_2024_Q1))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q1_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q1_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q1 -Violence against civilians\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nQuarter 2\n\nExplosions/Remote violenceStrategic developmentsBattlesViolence against civilians\n\n\n\nExample &lt;- \"Explosions/Remote violence\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\n\nwrite_rds(my_2024_Q2, \"data/rds/my_2024_Q2_ER_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_ER_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_ER_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Explosion/Remote violence\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Strategic developments\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\n\nwrite_rds(my_2024_Q2, \"data/rds/my_2024_Q2_SD_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_SD_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_SD_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Strategic developments\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Battles\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\n\nwrite_rds(my_2024_Q2, \"data/rds/my_2024_Q2_B_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_B_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_B_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Battles\")\n\n\n\n\n\n\n\n\n\n\n\nExample &lt;- \"Violence against civilians\"\nmy_2024_Q2 &lt;- acled_sf  %&gt;%\n  filter(event_type == Example & quarter == \"2024 Q2\")\n\nwrite_rds(my_2024_Q2, \"data/rds/my_2024_Q2_VAC_quarter_data_regions_sf.rds\")\n\nquarter_data &lt;- as_Spatial(my_2024_Q2)\nquarter_data_sp &lt;- as(quarter_data, \"SpatialPoints\")\nquarter_data_ppp &lt;- as.ppp(st_coordinates(my_2024_Q2), st_bbox(my_2024_Q2))\n\nquarter_data_ppp_jit &lt;- rjitter(quarter_data_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\n\nmy_2024_Q2_VAC_quarter_data_regions_ppp = quarter_data_ppp_jit[regions_owin]\nquarter_data_regions_ppp.km &lt;- rescale.ppp(my_2024_Q2_VAC_quarter_data_regions_ppp, 50000, \"km\")\n\nbw_scott &lt;- bw.scott(quarter_data_regions_ppp.km)\n\nplot(density(quarter_data_regions_ppp.km, \n             sigma=bw_scott/2, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main = \"2024 Q2 - Violence against civilians\")"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#nd-order-spatial-point-patterns-analysis",
    "href": "Take-home_ex/Take-home_ex01.html#nd-order-spatial-point-patterns-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.6 2nd-Order Spatial Point Patterns Analysis",
    "text": "1.6 2nd-Order Spatial Point Patterns Analysis\n\n1.6.1 Overview\nTo perform a Second-order Spatial Point Patterns Analysis, we utilize the G, F, K, and L functions of the spatstat package in R. Each of these functions analyzes different aspects of spatial point patterns. Given the nature of the dataset, it is crucial to choose an analysis that best captures the complexity of spatial distributions for conflict events. Each of the spatial functions (G, F, K, and L) has its strengths, but here’s how they align with conflict data analysis, with a particular focus on the G-function:\n\nG-Function (Nearest Neighbor Distribution):\n\nDetecting local clustering: The G-function focuses on the distribution of nearest neighbors, making it particularly useful for detecting local clustering of events. In the civil war context, where conflict events often cluster in specific regions or around key areas of interest (e.g., cities, roads, military bases), the G-function can quickly and efficiently help identify hotspots of violence. Its simplicity and computational efficiency make it an excellent choice for analyzing localized patterns of violence, especially when time and resources are limited.\n\nF-Function (Empty Space Function):\n\nDetecting global regularity: The F-function measures the distance from random locations to the nearest event. While it can offer insights into the global spread of events, this function is less relevant for conflict analysis because it emphasizes regularity over clustering, which is not typical in conflict zones. Conflict events are rarely evenly spaced, making the F-function less suited for this kind of data.\n\nK-Function (Ripley’s K-Function):\n\nMulti-scale clustering: The K-function is valuable for analyzing clustering at different spatial scales, especially in hierarchical conflict scenarios where regional and local clusters coexist. However, the K-function’s multi-scale nature comes with a higher computational cost, making it less practical for when large datasets are involved. While informative, its complexity and runtime can be a drawback.\n\nL-Function (Transformed K-Function):\n\nSimplifying K-function results: The L-function is a linearized version of the K-function and offers more intuitive interpretations of clustering versus dispersion. However, like the K-function, it involves significant computation time, and its added complexity may not always justify its use, especially when the G-function already provides key insights into local clustering.\n\n\nGiven the nature of the civil war event data, where localized patterns and hotspots of violence are of primary concern, the G-function emerges as the most suitable tool for analysis. Its ability to efficiently detect local clustering while being computationally lightweight makes it a clear choice. While both K-function and L-functions offer multi-scale insights, they come at the cost of significant computation time, which may not be necessary for this analysis.\nThe G-function provides a focused and practical approach to understanding the spatial distribution of conflict events, making it the preferred choice in this context.\n\n\n\n\n\n\nNote\n\n\n\nDue to the non-deterministic nature of running each simulation, the set.seed() function is employed to ensure the reproducibility of the simulation results. This is especially important for lower values of nsim, as it helps mitigate the random variability inherent in smaller sample sizes. By using a fixed seed, the analysis produces consistent outcomes across repeated runs, allowing for reliable comparisons and interpretations.\nThis approach enables us to assess whether the observed spatial point patterns significantly deviate from randomness. By simulating random point processes and comparing them to the observed data, we can identify potential clustering or dispersion patterns. These insights are critical in understanding the underlying structure of armed conflict events over time, helping to reveal whether the events are influenced by specific geographic or temporal factors or if they occur more randomly.\nThe results of this analysis contribute to a deeper understanding of the spatial-temporal dynamics of armed conflict, such as hotspots of violence, escalation patterns, and event diffusion across regions. This information is invaluable for conflict analysis, policy-making, and intervention planning.\n\n\n\n\nExplosions/Remote violence overview\n\nset.seed(123)\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_ER_quarter_data_regions_ppp,\n  my_2021_Q2_ER_quarter_data_regions_ppp,\n  my_2021_Q3_ER_quarter_data_regions_ppp,\n  my_2021_Q4_ER_quarter_data_regions_ppp,\n  my_2022_Q1_ER_quarter_data_regions_ppp,\n  my_2022_Q2_ER_quarter_data_regions_ppp,\n  my_2022_Q3_ER_quarter_data_regions_ppp,\n  my_2022_Q4_ER_quarter_data_regions_ppp,\n  my_2023_Q1_ER_quarter_data_regions_ppp,\n  my_2023_Q2_ER_quarter_data_regions_ppp,\n  my_2023_Q3_ER_quarter_data_regions_ppp,\n  my_2023_Q4_ER_quarter_data_regions_ppp,\n  my_2024_Q1_ER_quarter_data_regions_ppp,\n  my_2024_Q2_ER_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,0,2,0))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n    G_CK.csr &lt;- envelope(er_datasets[[i]], Gest, nsim = 50, correction=\"all\", parallel = parallel::detectCores()\n    )\n  plot(G_CK.csr, xlim=c(0,10000), main= er_labels[[i]])\n}\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nStrategic developments overview\n\nset.seed(124)\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_SD_quarter_data_regions_ppp,\n  my_2021_Q2_SD_quarter_data_regions_ppp,\n  my_2021_Q3_SD_quarter_data_regions_ppp,\n  my_2021_Q4_SD_quarter_data_regions_ppp,\n  my_2022_Q1_SD_quarter_data_regions_ppp,\n  my_2022_Q2_SD_quarter_data_regions_ppp,\n  my_2022_Q3_SD_quarter_data_regions_ppp,\n  my_2022_Q4_SD_quarter_data_regions_ppp,\n  my_2023_Q1_SD_quarter_data_regions_ppp,\n  my_2023_Q2_SD_quarter_data_regions_ppp,\n  my_2023_Q3_SD_quarter_data_regions_ppp,\n  my_2023_Q4_SD_quarter_data_regions_ppp,\n  my_2024_Q1_SD_quarter_data_regions_ppp,\n  my_2024_Q2_SD_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n    G_CK.csr &lt;- envelope(er_datasets[[i]], Gest, nsim = 50, parallel = parallel::detectCores())\n  plot(G_CK.csr, xlim=c(0,10000), main= er_labels[[i]])\n}\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nBattles overview\n\nset.seed(125)\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_B_quarter_data_regions_ppp,\n  my_2021_Q2_B_quarter_data_regions_ppp,\n  my_2021_Q3_B_quarter_data_regions_ppp,\n  my_2021_Q4_B_quarter_data_regions_ppp,\n  my_2022_Q1_B_quarter_data_regions_ppp,\n  my_2022_Q2_B_quarter_data_regions_ppp,\n  my_2022_Q3_B_quarter_data_regions_ppp,\n  my_2022_Q4_B_quarter_data_regions_ppp,\n  my_2023_Q1_B_quarter_data_regions_ppp,\n  my_2023_Q2_B_quarter_data_regions_ppp,\n  my_2023_Q3_B_quarter_data_regions_ppp,\n  my_2023_Q4_B_quarter_data_regions_ppp,\n  my_2024_Q1_B_quarter_data_regions_ppp,\n  my_2024_Q2_B_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n    G_CK.csr &lt;- envelope(er_datasets[[i]], Gest, nsim = 50, parallel = parallel::detectCores())\n  plot(G_CK.csr, xlim=c(0,10000), main= er_labels[[i]])\n}\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\nViolence against civilians overview\n\nset.seed(126)\n\n# Create a list of all the ER quarter datasets\ner_datasets &lt;- list(\n  my_2021_Q1_VAC_quarter_data_regions_ppp,\n  my_2021_Q2_VAC_quarter_data_regions_ppp,\n  my_2021_Q3_VAC_quarter_data_regions_ppp,\n  my_2021_Q4_VAC_quarter_data_regions_ppp,\n  my_2022_Q1_VAC_quarter_data_regions_ppp,\n  my_2022_Q2_VAC_quarter_data_regions_ppp,\n  my_2022_Q3_VAC_quarter_data_regions_ppp,\n  my_2022_Q4_VAC_quarter_data_regions_ppp,\n  my_2023_Q1_VAC_quarter_data_regions_ppp,\n  my_2023_Q2_VAC_quarter_data_regions_ppp,\n  my_2023_Q3_VAC_quarter_data_regions_ppp,\n  my_2023_Q4_VAC_quarter_data_regions_ppp,\n  my_2024_Q1_VAC_quarter_data_regions_ppp,\n  my_2024_Q2_VAC_quarter_data_regions_ppp\n)\n\n# Corresponding year and quarter labels for the plots\ner_labels &lt;- c(\n  \"2021 Q1\", \"2021 Q2\", \"2021 Q3\", \"2021 Q4\",\n  \"2022 Q1\", \"2022 Q2\", \"2022 Q3\", \"2022 Q4\",\n  \"2023 Q1\", \"2023 Q2\", \"2023 Q3\", \"2023 Q4\",\n  \"2024 Q1\", \"2024 Q2\"\n)\n\n# Set up the plotting area\npar(mar = c(2,1,2,1))\npar(mfrow=c(4,4))\n\n# Loop through each dataset and create the KDE plots\nfor (i in seq_along(er_datasets)) {\n    G_CK.csr &lt;- envelope(er_datasets[[i]], Gest, nsim = 50, parallel = parallel::detectCores())\n  plot(G_CK.csr, xlim=c(0,10000), main= er_labels[[i]])\n}\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nQuarter-wise analysis for all event types:\n\n2021 Q1: There is a strong deviation from the CSR, where the empirical G-function lies well above the envelope. This suggests clustering, particularly over the distances considered.\n2021 Q2 to 2024 Q2: Most quarters show a more stable pattern with the empirical G-function generally falling within the simulation envelope or only slightly above it at different distances. This suggests that there is no significant deviation from CSR, implying randomness in the spatial arrangement of points during most of these quarters. In some cases, the curve slightly rises above the envelope, which could indicate mild clustering.\n\nGeneral Trend: Across the quarters, the empirical G-function mostly lies within the CSR envelope, indicating a spatial point pattern that does not strongly deviate from randomness. The early quarters show more clustering, but later quarters become more consistent with random spatial distribution."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#determining-spatio-temporal-kde-layer",
    "href": "Take-home_ex/Take-home_ex01.html#determining-spatio-temporal-kde-layer",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.7 Determining Spatio-Temporal KDE Layer",
    "text": "1.7 Determining Spatio-Temporal KDE Layer\n\n1.7.1 Visualising geographic distribution of events by month\nWe would first prepare the acled_sf object. The q column is derived from the event_date field using the quarter() function, which extracts the quarter (Q1, Q2, Q3, or Q4) from each date. This new column helps in grouping events by the quarter of the year, which is crucial for spatio-temporal analysis.\n\ntemporal_acled_sf &lt;- acled_sf %&gt;%\n  mutate(q = quarter(event_date))\n\nwrite_rds(temporal_acled_sf, \"data/rds/temporal_acled_sf.rds\")\n\n\ntm_shape(regions_sf)+\n  tm_polygons() +\ntm_shape(temporal_acled_sf) +\n  tm_dots() +\ntm_facets(by=\"quarter\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\n\n\n\n\n\n\n1.7.2 Deriving Quarterly Spatio-Temporal KDE Layers\nIn this section, we will be generating Quarterly Spatio-Temporal KDE (Kernel Density Estimation) layers for conflict events. KDE is a powerful technique for estimating the probability density function of a random variable—in this case, spatial point events such as conflicts.\nThe goal of spatio-temporal KDE is to analyze how the intensity of conflict events evolves both spatially and temporally. Instead of simply plotting the points, KDE smooths the data to show areas of higher and lower event intensity, giving a more nuanced view of conflict pattern\n::: Key Steps in this Section: 1. Quarter-Based Data Aggregation: The conflict data will be divided into quarters (e.g., Q1 to Q4), allowing us to analyze conflict intensity in each three-month period.\n\nSpatial Density Calculation: The KDE method will be applied to the spatial points in each quarter, resulting in a density surface that highlights areas of high conflict concentration. This is more informative than a simple point map, as it reveals underlying patterns that might not be obvious from the raw data.\nTemporal Change Analysis: By deriving KDE layers for each quarter, you will visualize how conflict intensity shifts over time. This allows you to examine whether certain regions experience persistent conflict or if the hotspots move across the country as the year progresses.\nVisualizing KDE Layers: Each KDE layer will be visualized on a map, either as a standalone plot or as part of a sequence (e.g., an animated GIF), showing how the density changes quarterly. This provides a dynamic view of the conflict landscape.\n\n:::\n\n1.7.2.1 Explosions/Remote violence\n\nExample &lt;- \"Explosions/Remote violence\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\nYear 2021Year 2022Year 2023Year 2024\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/ER/kde_2021_ER\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/ER/kde_2022_ER\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/ER/kde_2023_ER\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 2)\npar(mfrow=c(1,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/ER/kde_2024_ER\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n  dev.off()\n}\n\n\n\n\n\nkde_images &lt;- list.files(\"data/rds/kde_plots/ER/\", full.names = TRUE, pattern = \".png\")\nimage_read(kde_images) %&gt;%\n  image_animate(fps = 2)\n\n\n\n\n\n\n\n\n\n\n1.7.2.2 Strategic developments\n\nExample &lt;- \"Strategic developments\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\nYear 2021Year 2022Year 2023Year 2024\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/SD/kde_2021_SD\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/SD/kde_2022_SD\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/SD/kde_2023_SD\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 2)\npar(mfrow=c(1,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/SD/kde_2024_SD\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n  dev.off()\n}\n\n\n\n\n\nkde_images &lt;- list.files(\"data/rds/kde_plots/SD/\", full.names = TRUE, pattern = \".png\")\nimage_read(kde_images) %&gt;%\n  image_animate(fps = 2)\n\n\n\n\n\n\n\n\n\n\n1.7.2.3 Battles\n\nExample &lt;- \"Battles\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\nYear 2021Year 2022Year 2023Year 2024\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/B/kde_2021_B\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/B/kde_2022_B\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/B/kde_2023_B\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 2)\npar(mfrow=c(1,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/B/kde_2024_B\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n  dev.off()\n}\n\n\n\n\n\nkde_images &lt;- list.files(\"data/rds/kde_plots/B/\", full.names = TRUE, pattern = \".png\")\nimage_read(kde_images) %&gt;%\n  image_animate(fps = 2)\n\n\n\n\n\n\n\n\n\n\n1.7.2.4 Violence against civilians\n\nExample &lt;- \"Violence against civilians\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\nYear 2021Year 2022Year 2023Year 2024\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/VAC/kde_2021_VAC\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2021 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/VAC/kde_2022_VAC\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2022 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 3, 2, 4)\npar(mfcol=c(2,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/VAC/kde_2023_VAC\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2023 Q\",i))\n  dev.off()\n}\n\n\n\n\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nst_kde &lt;- spattemp.density(acled_spatio_ppp_owin)\n\ntims &lt;- c(1, 2)\npar(mfrow=c(1,2))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n}\n\n\n\n\n\n\n\n\n\nfor(i in tims){\n  png(filename = paste0(\"data/rds/kde_plots/VAC/kde_2024_VAC\", i, \".png\"), width = 800, height = 600)\n  \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at 2024 Q\",i))\n  dev.off()\n}\n\n\n\n\n\nkde_images &lt;- list.files(\"data/rds/kde_plots/VAC/\", full.names = TRUE, pattern = \".png\")\nimage_read(kde_images) %&gt;%\n  image_animate(fps = 2)"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#nd-order-spatio-temporal-point-patterns-analysis",
    "href": "Take-home_ex/Take-home_ex01.html#nd-order-spatio-temporal-point-patterns-analysis",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.8 2nd-Order Spatio-Temporal Point Patterns Analysis",
    "text": "1.8 2nd-Order Spatio-Temporal Point Patterns Analysis\nGiven that we are analyzing armed conflict data across different quarters (from 2021 to 2024) and likely observing variation in event density over space and time, inhomogeneous point patterns are the more appropriate model.\nAs such we have opted to use the Kinhom function for 2nd-order analysis.\n\n\n\n\n\n\nNote\n\n\n\nIt can be noted that set.seed() is not utilised for the following set of simulations. This is due to to nsim is set to a sufficiently large value, and that provides a large enough sample of randomized patterns to accurately assess the distribution of the test statistic under the null hypothesis.\nWhen the number of simulations is high, the variability in the results caused by random differences between simulations is reduced, making the outcome more stable and less sensitive to randomness. This minimizes the risk of random fluctuations significantly influencing the final result.\n\n\n\n1.8.1 Explosions/Remote violence\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [6:18 remaining] 3,\n [6:12 remaining] 4,  [6:04 remaining] 5,  [6:00 remaining] 6,\n [5:50 remaining] 7,  [5:44 remaining] 8,  [5:39 remaining] 9,\n [5:33 remaining] 10,  [5:29 remaining] 11,  [5:27 remaining] 12,\n [5:22 remaining] 13,  [5:16 remaining] 14,  [5:12 remaining] 15,\n [5:11 remaining] 16,  [5:08 remaining] 17,  [5:04 remaining] 18,\n [5:00 remaining] 19,  [4:56 remaining] 20,  [4:52 remaining] 21,\n [4:50 remaining] 22,  [4:48 remaining] 23,  [4:45 remaining] 24,\n [4:42 remaining] 25,  [4:38 remaining] 26,  [4:34 remaining] 27,\n [4:30 remaining] 28,  [4:26 remaining] 29,  [4:22 remaining] 30,\n [4:18 remaining] 31,  [4:14 remaining] 32,  [4:10 remaining] 33,\n [4:06 remaining] 34,  [4:02 remaining] 35,  [3:58 remaining] 36,\n [3:54 remaining] 37,  [3:50 remaining] 38,  [3:46 remaining] 39,\n [3:43 remaining] 40,  [3:39 remaining] 41,  [3:35 remaining] 42,\n [3:32 remaining] 43,  [3:28 remaining] 44,  [3:23 remaining] 45,\n [3:19 remaining] 46,  [3:14 remaining] 47,  [3:10 remaining] 48,\n [3:06 remaining] 49,  [3:02 remaining] 50,  [2:58 remaining] 51,\n [2:54 remaining] 52,  [2:50 remaining] 53,  [2:46 remaining] 54,\n [2:42 remaining] 55,  [2:38 remaining] 56,  [2:35 remaining] 57,\n [2:31 remaining] 58,  [2:27 remaining] 59,  [2:23 remaining] 60,\n [2:19 remaining] 61,  [2:15 remaining] 62,  [2:12 remaining] 63,\n [2:08 remaining] 64,  [2:04 remaining] 65,  [2:01 remaining] 66,\n [1:57 remaining] 67,  [1:53 remaining] 68,  [1:49 remaining] 69,\n [1:46 remaining] 70,  [1:42 remaining] 71,  [1:39 remaining] 72,\n [1:35 remaining] 73,  [1:31 remaining] 74,  [1:28 remaining] 75,\n [1:24 remaining] 76,  [1:20 remaining] 77,  [1:17 remaining] 78,\n [1:13 remaining] 79,  [1:10 remaining] 80,  [1:06 remaining] 81,\n [1:03 remaining] 82,  [59 sec remaining] 83,  [56 sec remaining] 84,\n [52 sec remaining] 85,  [49 sec remaining] 86,  [45 sec remaining] 87,\n [42 sec remaining] 88,  [38 sec remaining] 89,  [35 sec remaining] 90,\n [31 sec remaining] 91,  [28 sec remaining] 92,  [24 sec remaining] 93,\n [21 sec remaining] 94,  [17 sec remaining] 95,  [14 sec remaining] 96,\n [10 sec remaining] 97,  [7 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [6:28 remaining] 3,\n [6:24 remaining] 4,  [6:20 remaining] 5,  [6:18 remaining] 6,\n [6:16 remaining] 7,  [6:12 remaining] 8,  [6:10 remaining] 9,\n [6:07 remaining] 10,  [6:02 remaining] 11,  [5:59 remaining] 12,\n [5:54 remaining] 13,  [5:50 remaining] 14,  [5:47 remaining] 15,\n [5:42 remaining] 16,  [5:38 remaining] 17,  [5:35 remaining] 18,\n [5:31 remaining] 19,  [5:26 remaining] 20,  [5:22 remaining] 21,\n [5:17 remaining] 22,  [5:14 remaining] 23,  [5:09 remaining] 24,\n [5:05 remaining] 25,  [5:02 remaining] 26,  [4:57 remaining] 27,\n [4:53 remaining] 28,  [4:49 remaining] 29,  [4:45 remaining] 30,\n [4:41 remaining] 31,  [4:37 remaining] 32,  [4:33 remaining] 33,\n [4:29 remaining] 34,  [4:25 remaining] 35,  [4:21 remaining] 36,\n [4:17 remaining] 37,  [4:13 remaining] 38,  [4:09 remaining] 39,\n [4:05 remaining] 40,  [4:01 remaining] 41,  [3:57 remaining] 42,\n [3:53 remaining] 43,  [3:49 remaining] 44,  [3:45 remaining] 45,\n [3:41 remaining] 46,  [3:37 remaining] 47,  [3:32 remaining] 48,\n [3:28 remaining] 49,  [3:24 remaining] 50,  [3:21 remaining] 51,\n [3:16 remaining] 52,  [3:12 remaining] 53,  [3:08 remaining] 54,\n [3:04 remaining] 55,  [3:00 remaining] 56,  [2:56 remaining] 57,\n [2:52 remaining] 58,  [2:48 remaining] 59,  [2:44 remaining] 60,\n [2:40 remaining] 61,  [2:35 remaining] 62,  [2:31 remaining] 63,\n [2:27 remaining] 64,  [2:23 remaining] 65,  [2:19 remaining] 66,\n [2:15 remaining] 67,  [2:11 remaining] 68,  [2:07 remaining] 69,\n [2:03 remaining] 70,  [1:58 remaining] 71,  [1:54 remaining] 72,\n [1:50 remaining] 73,  [1:46 remaining] 74,  [1:42 remaining] 75,\n [1:38 remaining] 76,  [1:34 remaining] 77,  [1:30 remaining] 78,\n [1:26 remaining] 79,  [1:22 remaining] 80,  [1:18 remaining] 81,\n [1:14 remaining] 82,  [1:10 remaining] 83,  [1:05 remaining] 84,\n [1:01 remaining] 85,  [57 sec remaining] 86,  [53 sec remaining] 87,\n [49 sec remaining] 88,  [45 sec remaining] 89,  [41 sec remaining] 90,\n [37 sec remaining] 91,  [33 sec remaining] 92,  [29 sec remaining] 93,\n [25 sec remaining] 94,  [20 sec remaining] 95,  [16 sec remaining] 96,\n [12 sec remaining] 97,  [8 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [6:29 remaining] 3,\n [6:28 remaining] 4,  [6:21 remaining] 5,  [6:22 remaining] 6,\n [6:18 remaining] 7,  [6:18 remaining] 8,  [6:13 remaining] 9,\n [6:08 remaining] 10,  [6:06 remaining] 11,  [6:02 remaining] 12,\n [5:57 remaining] 13,  [5:52 remaining] 14,  [5:47 remaining] 15,\n [5:42 remaining] 16,  [5:40 remaining] 17,  [5:35 remaining] 18,\n [5:31 remaining] 19,  [5:26 remaining] 20,  [5:22 remaining] 21,\n [5:17 remaining] 22,  [5:13 remaining] 23,  [5:09 remaining] 24,\n [5:06 remaining] 25,  [5:02 remaining] 26,  [4:58 remaining] 27,\n [4:54 remaining] 28,  [4:50 remaining] 29,  [4:45 remaining] 30,\n [4:41 remaining] 31,  [4:37 remaining] 32,  [4:33 remaining] 33,\n [4:30 remaining] 34,  [4:26 remaining] 35,  [4:21 remaining] 36,\n [4:17 remaining] 37,  [4:13 remaining] 38,  [4:09 remaining] 39,\n [4:05 remaining] 40,  [4:01 remaining] 41,  [3:57 remaining] 42,\n [3:53 remaining] 43,  [3:49 remaining] 44,  [3:45 remaining] 45,\n [3:41 remaining] 46,  [3:37 remaining] 47,  [3:33 remaining] 48,\n [3:29 remaining] 49,  [3:25 remaining] 50,  [3:21 remaining] 51,\n [3:17 remaining] 52,  [3:13 remaining] 53,  [3:09 remaining] 54,\n [3:05 remaining] 55,  [3:01 remaining] 56,  [2:56 remaining] 57,\n [2:52 remaining] 58,  [2:48 remaining] 59,  [2:44 remaining] 60,\n [2:40 remaining] 61,  [2:36 remaining] 62,  [2:32 remaining] 63,\n [2:28 remaining] 64,  [2:23 remaining] 65,  [2:19 remaining] 66,\n [2:15 remaining] 67,  [2:11 remaining] 68,  [2:07 remaining] 69,\n [2:03 remaining] 70,  [1:59 remaining] 71,  [1:55 remaining] 72,\n [1:51 remaining] 73,  [1:47 remaining] 74,  [1:42 remaining] 75,\n [1:38 remaining] 76,  [1:34 remaining] 77,  [1:30 remaining] 78,\n [1:26 remaining] 79,  [1:22 remaining] 80,  [1:18 remaining] 81,\n [1:14 remaining] 82,  [1:10 remaining] 83,  [1:06 remaining] 84,\n [1:02 remaining] 85,  [57 sec remaining] 86,  [53 sec remaining] 87,\n [49 sec remaining] 88,  [45 sec remaining] 89,  [41 sec remaining] 90,\n [37 sec remaining] 91,  [33 sec remaining] 92,  [29 sec remaining] 93,\n [25 sec remaining] 94,  [21 sec remaining] 95,  [16 sec remaining] 96,\n [12 sec remaining] 97,  [8 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [4:19 remaining] 3,\n [4:12 remaining] 4,  [4:10 remaining] 5,  [4:09 remaining] 6,\n [4:06 remaining] 7,  [4:03 remaining] 8,  [4:01 remaining] 9,\n [3:58 remaining] 10,  [3:58 remaining] 11,  [3:54 remaining] 12,\n [3:52 remaining] 13,  [3:49 remaining] 14,  [3:46 remaining] 15,\n [3:43 remaining] 16,  [3:41 remaining] 17,  [3:38 remaining] 18,\n [3:35 remaining] 19,  [3:32 remaining] 20,  [3:30 remaining] 21,\n [3:28 remaining] 22,  [3:25 remaining] 23,  [3:23 remaining] 24,\n [3:20 remaining] 25,  [3:17 remaining] 26,  [3:14 remaining] 27,\n [3:12 remaining] 28,  [3:09 remaining] 29,  [3:06 remaining] 30,\n [3:04 remaining] 31,  [3:01 remaining] 32,  [2:58 remaining] 33,\n [2:58 remaining] 34,  [2:56 remaining] 35,  [2:53 remaining] 36,\n [2:51 remaining] 37,  [2:48 remaining] 38,  [2:45 remaining] 39,\n [2:42 remaining] 40,  [2:40 remaining] 41,  [2:37 remaining] 42,\n [2:34 remaining] 43,  [2:31 remaining] 44,  [2:29 remaining] 45,\n [2:26 remaining] 46,  [2:23 remaining] 47,  [2:20 remaining] 48,\n [2:18 remaining] 49,  [2:15 remaining] 50,  [2:12 remaining] 51,\n [2:09 remaining] 52,  [2:07 remaining] 53,  [2:04 remaining] 54,\n [2:02 remaining] 55,  [1:59 remaining] 56,  [1:56 remaining] 57,\n [1:53 remaining] 58,  [1:50 remaining] 59,  [1:48 remaining] 60,\n [1:45 remaining] 61,  [1:42 remaining] 62,  [1:40 remaining] 63,\n [1:37 remaining] 64,  [1:34 remaining] 65,  [1:32 remaining] 66,\n [1:29 remaining] 67,  [1:26 remaining] 68,  [1:23 remaining] 69,\n [1:21 remaining] 70,  [1:18 remaining] 71,  [1:15 remaining] 72,\n [1:13 remaining] 73,  [1:10 remaining] 74,  [1:07 remaining] 75,\n [1:05 remaining] 76,  [1:02 remaining] 77,  [59 sec remaining] 78,\n [57 sec remaining] 79,  [54 sec remaining] 80,  [51 sec remaining] 81,\n [48 sec remaining] 82,  [46 sec remaining] 83,  [43 sec remaining] 84,\n [40 sec remaining] 85,  [38 sec remaining] 86,  [35 sec remaining] 87,\n [32 sec remaining] 88,  [30 sec remaining] 89,  [27 sec remaining] 90,\n [24 sec remaining] 91,  [22 sec remaining] 92,  [19 sec remaining] 93,\n [16 sec remaining] 94,  [13 sec remaining] 95,  [11 sec remaining] 96,\n [8 sec remaining] 97,  [5 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\n\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.2 Strategic developments\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [6:32 remaining] 3,\n [6:15 remaining] 4,  [6:07 remaining] 5,  [6:08 remaining] 6,\n [6:02 remaining] 7,  [5:55 remaining] 8,  [5:51 remaining] 9,\n [5:47 remaining] 10,  [5:42 remaining] 11,  [5:38 remaining] 12,\n [5:33 remaining] 13,  [5:29 remaining] 14,  [5:28 remaining] 15,\n [5:23 remaining] 16,  [5:20 remaining] 17,  [5:16 remaining] 18,\n [5:11 remaining] 19,  [5:07 remaining] 20,  [5:03 remaining] 21,\n [4:58 remaining] 22,  [4:54 remaining] 23,  [4:51 remaining] 24,\n [4:47 remaining] 25,  [4:43 remaining] 26,  [4:39 remaining] 27,\n [4:35 remaining] 28,  [4:32 remaining] 29,  [4:28 remaining] 30,\n [4:24 remaining] 31,  [4:20 remaining] 32,  [4:16 remaining] 33,\n [4:12 remaining] 34,  [4:08 remaining] 35,  [4:04 remaining] 36,\n [4:01 remaining] 37,  [3:57 remaining] 38,  [3:53 remaining] 39,\n [3:50 remaining] 40,  [3:46 remaining] 41,  [3:42 remaining] 42,\n [3:38 remaining] 43,  [3:34 remaining] 44,  [3:30 remaining] 45,\n [3:26 remaining] 46,  [3:23 remaining] 47,  [3:19 remaining] 48,\n [3:15 remaining] 49,  [3:11 remaining] 50,  [3:07 remaining] 51,\n [3:03 remaining] 52,  [2:59 remaining] 53,  [2:56 remaining] 54,\n [2:52 remaining] 55,  [2:48 remaining] 56,  [2:44 remaining] 57,\n [2:41 remaining] 58,  [2:37 remaining] 59,  [2:33 remaining] 60,\n [2:29 remaining] 61,  [2:25 remaining] 62,  [2:21 remaining] 63,\n [2:17 remaining] 64,  [2:14 remaining] 65,  [2:10 remaining] 66,\n [2:06 remaining] 67,  [2:02 remaining] 68,  [1:58 remaining] 69,\n [1:54 remaining] 70,  [1:51 remaining] 71,  [1:47 remaining] 72,\n [1:43 remaining] 73,  [1:39 remaining] 74,  [1:35 remaining] 75,\n [1:32 remaining] 76,  [1:28 remaining] 77,  [1:24 remaining] 78,\n [1:20 remaining] 79,  [1:16 remaining] 80,  [1:13 remaining] 81,\n [1:09 remaining] 82,  [1:05 remaining] 83,  [1:01 remaining] 84,\n [57 sec remaining] 85,  [53 sec remaining] 86,  [50 sec remaining] 87,\n [46 sec remaining] 88,  [42 sec remaining] 89,  [38 sec remaining] 90,\n [34 sec remaining] 91,  [31 sec remaining] 92,  [27 sec remaining] 93,\n [23 sec remaining] 94,  [19 sec remaining] 95,  [15 sec remaining] 96,\n [11 sec remaining] 97,  [8 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [8:17 remaining] 3,\n [8:00 remaining] 4,  [7:52 remaining] 5,  [7:40 remaining] 6,\n [7:31 remaining] 7,  [7:29 remaining] 8,  [7:22 remaining] 9,\n [7:15 remaining] 10,  [7:10 remaining] 11,  [7:05 remaining] 12,\n [7:01 remaining] 13,  [6:55 remaining] 14,  [6:51 remaining] 15,\n [6:48 remaining] 16,  [6:42 remaining] 17,  [6:37 remaining] 18,\n [6:32 remaining] 19,  [6:27 remaining] 20,  [6:21 remaining] 21,\n [6:16 remaining] 22,  [6:11 remaining] 23,  [6:07 remaining] 24,\n [6:01 remaining] 25,  [5:56 remaining] 26,  [5:51 remaining] 27,\n [5:46 remaining] 28,  [5:42 remaining] 29,  [5:37 remaining] 30,\n [5:33 remaining] 31,  [5:28 remaining] 32,  [5:23 remaining] 33,\n [5:18 remaining] 34,  [5:13 remaining] 35,  [5:09 remaining] 36,\n [5:04 remaining] 37,  [4:59 remaining] 38,  [4:54 remaining] 39,\n [4:49 remaining] 40,  [4:44 remaining] 41,  [4:39 remaining] 42,\n [4:35 remaining] 43,  [4:30 remaining] 44,  [4:25 remaining] 45,\n [4:20 remaining] 46,  [4:15 remaining] 47,  [4:10 remaining] 48,\n [4:05 remaining] 49,  [4:01 remaining] 50,  [3:56 remaining] 51,\n [3:51 remaining] 52,  [3:46 remaining] 53,  [3:41 remaining] 54,\n [3:37 remaining] 55,  [3:32 remaining] 56,  [3:27 remaining] 57,\n [3:22 remaining] 58,  [3:17 remaining] 59,  [3:12 remaining] 60,\n [3:08 remaining] 61,  [3:03 remaining] 62,  [2:58 remaining] 63,\n [2:53 remaining] 64,  [2:48 remaining] 65,  [2:43 remaining] 66,\n [2:39 remaining] 67,  [2:34 remaining] 68,  [2:29 remaining] 69,\n [2:24 remaining] 70,  [2:19 remaining] 71,  [2:15 remaining] 72,\n [2:10 remaining] 73,  [2:05 remaining] 74,  [2:00 remaining] 75,\n [1:55 remaining] 76,  [1:51 remaining] 77,  [1:46 remaining] 78,\n [1:41 remaining] 79,  [1:36 remaining] 80,  [1:31 remaining] 81,\n [1:27 remaining] 82,  [1:22 remaining] 83,  [1:17 remaining] 84,\n [1:12 remaining] 85,  [1:07 remaining] 86,  [1:02 remaining] 87,\n [58 sec remaining] 88,  [53 sec remaining] 89,  [48 sec remaining] 90,\n [43 sec remaining] 91,  [38 sec remaining] 92,  [34 sec remaining] 93,\n [29 sec remaining] 94,  [24 sec remaining] 95,  [19 sec remaining] 96,\n [14 sec remaining] 97,  [10 sec remaining] 98,  [5 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [5:53 remaining] 3,\n [5:43 remaining] 4,  [5:38 remaining] 5,  [5:34 remaining] 6,\n [5:39 remaining] 7,  [5:32 remaining] 8,  [5:27 remaining] 9,\n [5:23 remaining] 10,  [5:19 remaining] 11,  [5:15 remaining] 12,\n [5:11 remaining] 13,  [5:08 remaining] 14,  [5:04 remaining] 15,\n [5:02 remaining] 16,  [4:59 remaining] 17,  [4:55 remaining] 18,\n [4:51 remaining] 19,  [4:47 remaining] 20,  [4:44 remaining] 21,\n [4:40 remaining] 22,  [4:36 remaining] 23,  [4:32 remaining] 24,\n [4:29 remaining] 25,  [4:26 remaining] 26,  [4:22 remaining] 27,\n [4:18 remaining] 28,  [4:14 remaining] 29,  [4:10 remaining] 30,\n [4:07 remaining] 31,  [4:03 remaining] 32,  [3:59 remaining] 33,\n [3:56 remaining] 34,  [3:52 remaining] 35,  [3:49 remaining] 36,\n [3:45 remaining] 37,  [3:41 remaining] 38,  [3:38 remaining] 39,\n [3:34 remaining] 40,  [3:30 remaining] 41,  [3:27 remaining] 42,\n [3:23 remaining] 43,  [3:20 remaining] 44,  [3:16 remaining] 45,\n [3:13 remaining] 46,  [3:09 remaining] 47,  [3:06 remaining] 48,\n [3:02 remaining] 49,  [2:58 remaining] 50,  [2:55 remaining] 51,\n [2:51 remaining] 52,  [2:48 remaining] 53,  [2:44 remaining] 54,\n [2:41 remaining] 55,  [2:37 remaining] 56,  [2:33 remaining] 57,\n [2:30 remaining] 58,  [2:26 remaining] 59,  [2:23 remaining] 60,\n [2:19 remaining] 61,  [2:16 remaining] 62,  [2:12 remaining] 63,\n [2:09 remaining] 64,  [2:05 remaining] 65,  [2:02 remaining] 66,\n [1:58 remaining] 67,  [1:54 remaining] 68,  [1:51 remaining] 69,\n [1:47 remaining] 70,  [1:44 remaining] 71,  [1:40 remaining] 72,\n [1:37 remaining] 73,  [1:33 remaining] 74,  [1:29 remaining] 75,\n [1:26 remaining] 76,  [1:22 remaining] 77,  [1:19 remaining] 78,\n [1:15 remaining] 79,  [1:12 remaining] 80,  [1:08 remaining] 81,\n [1:04 remaining] 82,  [1:01 remaining] 83,  [57 sec remaining] 84,\n [54 sec remaining] 85,  [50 sec remaining] 86,  [47 sec remaining] 87,\n [43 sec remaining] 88,  [39 sec remaining] 89,  [36 sec remaining] 90,\n [32 sec remaining] 91,  [29 sec remaining] 92,  [25 sec remaining] 93,\n [21 sec remaining] 94,  [18 sec remaining] 95,  [14 sec remaining] 96,\n [11 sec remaining] 97,  [7 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [3:01 remaining] 3,\n [3:02 remaining] 4,  [3:00 remaining] 5,  [2:55 remaining] 6,\n [2:53 remaining] 7,  [2:50 remaining] 8,  [2:48 remaining] 9,\n [2:47 remaining] 10,  [2:44 remaining] 11,  [2:44 remaining] 12,\n [2:42 remaining] 13,  [2:40 remaining] 14,  [2:37 remaining] 15,\n [2:35 remaining] 16,  [2:33 remaining] 17,  [2:31 remaining] 18,\n [2:29 remaining] 19,  [2:27 remaining] 20,  [2:25 remaining] 21,\n [2:23 remaining] 22,  [2:21 remaining] 23,  [2:20 remaining] 24,\n [2:19 remaining] 25,  [2:17 remaining] 26,  [2:15 remaining] 27,\n [2:13 remaining] 28,  [2:11 remaining] 29,  [2:09 remaining] 30,\n [2:07 remaining] 31,  [2:05 remaining] 32,  [2:04 remaining] 33,\n [2:02 remaining] 34,  [2:00 remaining] 35,  [1:58 remaining] 36,\n [1:56 remaining] 37,  [1:54 remaining] 38,  [1:53 remaining] 39,\n [1:51 remaining] 40,  [1:50 remaining] 41,  [1:48 remaining] 42,\n [1:46 remaining] 43,  [1:44 remaining] 44,  [1:42 remaining] 45,\n [1:40 remaining] 46,  [1:38 remaining] 47,  [1:36 remaining] 48,\n [1:34 remaining] 49,  [1:33 remaining] 50,  [1:31 remaining] 51,\n [1:29 remaining] 52,  [1:27 remaining] 53,  [1:25 remaining] 54,\n [1:23 remaining] 55,  [1:22 remaining] 56,  [1:20 remaining] 57,\n [1:18 remaining] 58,  [1:16 remaining] 59,  [1:14 remaining] 60,\n [1:12 remaining] 61,  [1:10 remaining] 62,  [1:08 remaining] 63,\n [1:07 remaining] 64,  [1:05 remaining] 65,  [1:03 remaining] 66,\n [1:01 remaining] 67,  [59 sec remaining] 68,  [57 sec remaining] 69,\n [55 sec remaining] 70,  [54 sec remaining] 71,  [52 sec remaining] 72,\n [50 sec remaining] 73,  [48 sec remaining] 74,  [46 sec remaining] 75,\n [44 sec remaining] 76,  [43 sec remaining] 77,  [41 sec remaining] 78,\n [39 sec remaining] 79,  [37 sec remaining] 80,  [35 sec remaining] 81,\n [33 sec remaining] 82,  [31 sec remaining] 83,  [30 sec remaining] 84,\n [28 sec remaining] 85,  [26 sec remaining] 86,  [24 sec remaining] 87,\n [22 sec remaining] 88,  [20 sec remaining] 89,  [18 sec remaining] 90,\n [17 sec remaining] 91,  [15 sec remaining] 92,  [13 sec remaining] 93,\n [11 sec remaining] 94,  [9 sec remaining] 95,  [7 sec remaining] 96,\n [6 sec remaining] 97,  [4 sec remaining] 98,  [2 sec remaining] \n99.\n\nDone.\n\n\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.3 Battles\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [4:38 remaining] 3,\n [4:30 remaining] 4,  [4:27 remaining] 5,  [4:28 remaining] 6,\n [4:22 remaining] 7,  [4:17 remaining] 8,  [4:12 remaining] 9,\n [4:08 remaining] 10,  [4:05 remaining] 11,  [4:03 remaining] 12,\n [3:59 remaining] 13,  [3:56 remaining] 14,  [3:57 remaining] 15,\n [3:57 remaining] 16,  [3:57 remaining] 17,  [3:57 remaining] 18,\n [3:53 remaining] 19,  [3:50 remaining] 20,  [3:46 remaining] 21,\n [3:44 remaining] 22,  [3:40 remaining] 23,  [3:37 remaining] 24,\n [3:34 remaining] 25,  [3:31 remaining] 26,  [3:28 remaining] 27,\n [3:24 remaining] 28,  [3:22 remaining] 29,  [3:19 remaining] 30,\n [3:16 remaining] 31,  [3:13 remaining] 32,  [3:10 remaining] 33,\n [3:07 remaining] 34,  [3:04 remaining] 35,  [3:01 remaining] 36,\n [2:58 remaining] 37,  [2:55 remaining] 38,  [2:53 remaining] 39,\n [2:50 remaining] 40,  [2:47 remaining] 41,  [2:44 remaining] 42,\n [2:41 remaining] 43,  [2:38 remaining] 44,  [2:35 remaining] 45,\n [2:32 remaining] 46,  [2:29 remaining] 47,  [2:26 remaining] 48,\n [2:24 remaining] 49,  [2:21 remaining] 50,  [2:18 remaining] 51,\n [2:15 remaining] 52,  [2:12 remaining] 53,  [2:09 remaining] 54,\n [2:06 remaining] 55,  [2:04 remaining] 56,  [2:01 remaining] 57,\n [1:58 remaining] 58,  [1:55 remaining] 59,  [1:52 remaining] 60,\n [1:49 remaining] 61,  [1:47 remaining] 62,  [1:44 remaining] 63,\n [1:41 remaining] 64,  [1:38 remaining] 65,  [1:35 remaining] 66,\n [1:33 remaining] 67,  [1:30 remaining] 68,  [1:27 remaining] 69,\n [1:24 remaining] 70,  [1:21 remaining] 71,  [1:19 remaining] 72,\n [1:16 remaining] 73,  [1:13 remaining] 74,  [1:10 remaining] 75,\n [1:07 remaining] 76,  [1:04 remaining] 77,  [1:02 remaining] 78,\n [59 sec remaining] 79,  [56 sec remaining] 80,  [53 sec remaining] 81,\n [50 sec remaining] 82,  [48 sec remaining] 83,  [45 sec remaining] 84,\n [42 sec remaining] 85,  [39 sec remaining] 86,  [36 sec remaining] 87,\n [34 sec remaining] 88,  [31 sec remaining] 89,  [28 sec remaining] 90,\n [25 sec remaining] 91,  [22 sec remaining] 92,  [20 sec remaining] 93,\n [17 sec remaining] 94,  [14 sec remaining] 95,  [11 sec remaining] 96,\n [8 sec remaining] 97,  [6 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [6:54 remaining] 3,\n [7:37 remaining] 4,  [7:24 remaining] 5,  [7:09 remaining] 6,\n [7:00 remaining] 7,  [6:54 remaining] 8,  [6:47 remaining] 9,\n [6:44 remaining] 10,  [6:45 remaining] 11,  [6:43 remaining] 12,\n [6:37 remaining] 13,  [6:30 remaining] 14,  [6:25 remaining] 15,\n [6:18 remaining] 16,  [6:12 remaining] 17,  [6:06 remaining] 18,\n [6:02 remaining] 19,  [5:56 remaining] 20,  [5:51 remaining] 21,\n [5:46 remaining] 22,  [5:41 remaining] 23,  [5:35 remaining] 24,\n [5:31 remaining] 25,  [5:27 remaining] 26,  [5:23 remaining] 27,\n [5:18 remaining] 28,  [5:13 remaining] 29,  [5:08 remaining] 30,\n [5:04 remaining] 31,  [4:59 remaining] 32,  [4:54 remaining] 33,\n [4:49 remaining] 34,  [4:45 remaining] 35,  [4:40 remaining] 36,\n [4:36 remaining] 37,  [4:31 remaining] 38,  [4:26 remaining] 39,\n [4:22 remaining] 40,  [4:17 remaining] 41,  [4:14 remaining] 42,\n [4:09 remaining] 43,  [4:05 remaining] 44,  [4:00 remaining] 45,\n [3:56 remaining] 46,  [3:51 remaining] 47,  [3:47 remaining] 48,\n [3:43 remaining] 49,  [3:39 remaining] 50,  [3:35 remaining] 51,\n [3:31 remaining] 52,  [3:26 remaining] 53,  [3:22 remaining] 54,\n [3:18 remaining] 55,  [3:14 remaining] 56,  [3:10 remaining] 57,\n [3:06 remaining] 58,  [3:01 remaining] 59,  [2:57 remaining] 60,\n [2:53 remaining] 61,  [2:48 remaining] 62,  [2:43 remaining] 63,\n [2:39 remaining] 64,  [2:34 remaining] 65,  [2:30 remaining] 66,\n [2:26 remaining] 67,  [2:21 remaining] 68,  [2:17 remaining] 69,\n [2:12 remaining] 70,  [2:08 remaining] 71,  [2:03 remaining] 72,\n [1:59 remaining] 73,  [1:54 remaining] 74,  [1:50 remaining] 75,\n [1:46 remaining] 76,  [1:41 remaining] 77,  [1:37 remaining] 78,\n [1:33 remaining] 79,  [1:28 remaining] 80,  [1:24 remaining] 81,\n [1:20 remaining] 82,  [1:15 remaining] 83,  [1:11 remaining] 84,\n [1:06 remaining] 85,  [1:02 remaining] 86,  [57 sec remaining] 87,\n [53 sec remaining] 88,  [49 sec remaining] 89,  [44 sec remaining] 90,\n [40 sec remaining] 91,  [35 sec remaining] 92,  [31 sec remaining] 93,\n [26 sec remaining] 94,  [22 sec remaining] 95,  [18 sec remaining] 96,\n [13 sec remaining] 97,  [9 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [7:05 remaining] 3,\n [7:23 remaining] 4,  [7:22 remaining] 5,  [7:11 remaining] 6,\n [7:18 remaining] 7,  [7:26 remaining] 8,  [7:19 remaining] 9,\n [7:11 remaining] 10,  [7:02 remaining] 11,  [6:54 remaining] 12,\n [6:51 remaining] 13,  [6:45 remaining] 14,  [6:38 remaining] 15,\n [6:34 remaining] 16,  [6:27 remaining] 17,  [6:20 remaining] 18,\n [6:14 remaining] 19,  [6:08 remaining] 20,  [6:03 remaining] 21,\n [5:57 remaining] 22,  [5:52 remaining] 23,  [5:48 remaining] 24,\n [5:43 remaining] 25,  [5:38 remaining] 26,  [5:33 remaining] 27,\n [5:27 remaining] 28,  [5:22 remaining] 29,  [5:18 remaining] 30,\n [5:13 remaining] 31,  [5:08 remaining] 32,  [5:03 remaining] 33,\n [4:59 remaining] 34,  [4:54 remaining] 35,  [4:49 remaining] 36,\n [4:44 remaining] 37,  [4:39 remaining] 38,  [4:34 remaining] 39,\n [4:30 remaining] 40,  [4:26 remaining] 41,  [4:21 remaining] 42,\n [4:16 remaining] 43,  [4:12 remaining] 44,  [4:07 remaining] 45,\n [4:02 remaining] 46,  [3:58 remaining] 47,  [3:53 remaining] 48,\n [3:49 remaining] 49,  [3:44 remaining] 50,  [3:40 remaining] 51,\n [3:35 remaining] 52,  [3:30 remaining] 53,  [3:26 remaining] 54,\n [3:21 remaining] 55,  [3:17 remaining] 56,  [3:12 remaining] 57,\n [3:08 remaining] 58,  [3:03 remaining] 59,  [2:59 remaining] 60,\n [2:54 remaining] 61,  [2:50 remaining] 62,  [2:45 remaining] 63,\n [2:41 remaining] 64,  [2:36 remaining] 65,  [2:32 remaining] 66,\n [2:27 remaining] 67,  [2:23 remaining] 68,  [2:18 remaining] 69,\n [2:14 remaining] 70,  [2:09 remaining] 71,  [2:05 remaining] 72,\n [2:00 remaining] 73,  [1:56 remaining] 74,  [1:51 remaining] 75,\n [1:47 remaining] 76,  [1:42 remaining] 77,  [1:38 remaining] 78,\n [1:33 remaining] 79,  [1:29 remaining] 80,  [1:24 remaining] 81,\n [1:20 remaining] 82,  [1:16 remaining] 83,  [1:11 remaining] 84,\n [1:07 remaining] 85,  [1:02 remaining] 86,  [58 sec remaining] 87,\n [53 sec remaining] 88,  [49 sec remaining] 89,  [45 sec remaining] 90,\n [40 sec remaining] 91,  [36 sec remaining] 92,  [31 sec remaining] 93,\n [27 sec remaining] 94,  [22 sec remaining] 95,  [18 sec remaining] 96,\n [13 sec remaining] 97,  [9 sec remaining] 98,  [4 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=50, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 50 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, \n50.\n\nDone.\n\n\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.3 Violence against civilians\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2021_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [3:52 remaining] 3,\n [3:49 remaining] 4,  [3:48 remaining] 5,  [3:47 remaining] 6,\n [3:43 remaining] 7,  [3:42 remaining] 8,  [3:38 remaining] 9,\n [3:41 remaining] 10,  [3:38 remaining] 11,  [3:35 remaining] 12,\n [3:32 remaining] 13,  [3:29 remaining] 14,  [3:26 remaining] 15,\n [3:23 remaining] 16,  [3:21 remaining] 17,  [3:18 remaining] 18,\n [3:16 remaining] 19,  [3:13 remaining] 20,  [3:11 remaining] 21,\n [3:09 remaining] 22,  [3:07 remaining] 23,  [3:04 remaining] 24,\n [3:02 remaining] 25,  [2:59 remaining] 26,  [2:57 remaining] 27,\n [2:55 remaining] 28,  [2:52 remaining] 29,  [2:50 remaining] 30,\n [2:47 remaining] 31,  [2:45 remaining] 32,  [2:42 remaining] 33,\n [2:40 remaining] 34,  [2:38 remaining] 35,  [2:35 remaining] 36,\n [2:33 remaining] 37,  [2:30 remaining] 38,  [2:28 remaining] 39,\n [2:25 remaining] 40,  [2:23 remaining] 41,  [2:20 remaining] 42,\n [2:18 remaining] 43,  [2:15 remaining] 44,  [2:13 remaining] 45,\n [2:11 remaining] 46,  [2:08 remaining] 47,  [2:06 remaining] 48,\n [2:03 remaining] 49,  [2:01 remaining] 50,  [1:59 remaining] 51,\n [1:56 remaining] 52,  [1:54 remaining] 53,  [1:51 remaining] 54,\n [1:49 remaining] 55,  [1:46 remaining] 56,  [1:44 remaining] 57,\n [1:42 remaining] 58,  [1:40 remaining] 59,  [1:37 remaining] 60,\n [1:35 remaining] 61,  [1:32 remaining] 62,  [1:30 remaining] 63,\n [1:27 remaining] 64,  [1:25 remaining] 65,  [1:24 remaining] 66,\n [1:21 remaining] 67,  [1:19 remaining] 68,  [1:17 remaining] 69,\n [1:15 remaining] 70,  [1:12 remaining] 71,  [1:10 remaining] 72,\n [1:07 remaining] 73,  [1:05 remaining] 74,  [1:02 remaining] 75,\n [1:00 remaining] 76,  [57 sec remaining] 77,  [55 sec remaining] 78,\n [53 sec remaining] 79,  [50 sec remaining] 80,  [48 sec remaining] 81,\n [45 sec remaining] 82,  [43 sec remaining] 83,  [40 sec remaining] 84,\n [38 sec remaining] 85,  [35 sec remaining] 86,  [33 sec remaining] 87,\n [30 sec remaining] 88,  [28 sec remaining] 89,  [25 sec remaining] 90,\n [22 sec remaining] 91,  [20 sec remaining] 92,  [17 sec remaining] 93,\n [15 sec remaining] 94,  [12 sec remaining] 95,  [10 sec remaining] 96,\n [8 sec remaining] 97,  [5 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2022_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [4:25 remaining] 3,\n [4:21 remaining] 4,  [4:28 remaining] 5,  [4:19 remaining] 6,\n [4:15 remaining] 7,  [4:09 remaining] 8,  [4:05 remaining] 9,\n [4:01 remaining] 10,  [4:06 remaining] 11,  [4:03 remaining] 12,\n [4:01 remaining] 13,  [3:58 remaining] 14,  [3:55 remaining] 15,\n [3:54 remaining] 16,  [3:50 remaining] 17,  [3:46 remaining] 18,\n [3:46 remaining] 19,  [3:43 remaining] 20,  [3:39 remaining] 21,\n [3:37 remaining] 22,  [3:34 remaining] 23,  [3:31 remaining] 24,\n [3:29 remaining] 25,  [3:26 remaining] 26,  [3:24 remaining] 27,\n [3:23 remaining] 28,  [3:22 remaining] 29,  [3:20 remaining] 30,\n [3:17 remaining] 31,  [3:14 remaining] 32,  [3:11 remaining] 33,\n [3:08 remaining] 34,  [3:05 remaining] 35,  [3:01 remaining] 36,\n [2:58 remaining] 37,  [2:55 remaining] 38,  [2:52 remaining] 39,\n [2:49 remaining] 40,  [2:46 remaining] 41,  [2:43 remaining] 42,\n [2:40 remaining] 43,  [2:38 remaining] 44,  [2:35 remaining] 45,\n [2:32 remaining] 46,  [2:28 remaining] 47,  [2:26 remaining] 48,\n [2:22 remaining] 49,  [2:19 remaining] 50,  [2:17 remaining] 51,\n [2:14 remaining] 52,  [2:11 remaining] 53,  [2:08 remaining] 54,\n [2:05 remaining] 55,  [2:02 remaining] 56,  [1:59 remaining] 57,\n [1:56 remaining] 58,  [1:53 remaining] 59,  [1:50 remaining] 60,\n [1:47 remaining] 61,  [1:45 remaining] 62,  [1:42 remaining] 63,\n [1:39 remaining] 64,  [1:36 remaining] 65,  [1:33 remaining] 66,\n [1:30 remaining] 67,  [1:27 remaining] 68,  [1:25 remaining] 69,\n [1:22 remaining] 70,  [1:19 remaining] 71,  [1:16 remaining] 72,\n [1:14 remaining] 73,  [1:11 remaining] 74,  [1:08 remaining] 75,\n [1:05 remaining] 76,  [1:02 remaining] 77,  [1:00 remaining] 78,\n [57 sec remaining] 79,  [54 sec remaining] 80,  [51 sec remaining] 81,\n [49 sec remaining] 82,  [46 sec remaining] 83,  [43 sec remaining] 84,\n [41 sec remaining] 85,  [38 sec remaining] 86,  [35 sec remaining] 87,\n [32 sec remaining] 88,  [30 sec remaining] 89,  [27 sec remaining] 90,\n [24 sec remaining] 91,  [22 sec remaining] 92,  [19 sec remaining] 93,\n [16 sec remaining] 94,  [13 sec remaining] 95,  [11 sec remaining] 96,\n [8 sec remaining] 97,  [5 sec remaining] 98,  [3 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2023_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2,  [3:37 remaining] 3,\n [3:40 remaining] 4,  [3:36 remaining] 5,  [3:32 remaining] 6,\n [3:36 remaining] 7,  [3:33 remaining] 8,  [3:29 remaining] 9,\n [3:25 remaining] 10,  [3:28 remaining] 11,  [3:25 remaining] 12,\n [3:23 remaining] 13,  [3:20 remaining] 14,  [3:18 remaining] 15,\n [3:16 remaining] 16,  [3:13 remaining] 17,  [3:12 remaining] 18,\n [3:09 remaining] 19,  [3:08 remaining] 20,  [3:06 remaining] 21,\n [3:03 remaining] 22,  [3:01 remaining] 23,  [2:58 remaining] 24,\n [2:55 remaining] 25,  [2:53 remaining] 26,  [2:50 remaining] 27,\n [2:48 remaining] 28,  [2:45 remaining] 29,  [2:43 remaining] 30,\n [2:40 remaining] 31,  [2:38 remaining] 32,  [2:36 remaining] 33,\n [2:33 remaining] 34,  [2:31 remaining] 35,  [2:30 remaining] 36,\n [2:28 remaining] 37,  [2:26 remaining] 38,  [2:23 remaining] 39,\n [2:21 remaining] 40,  [2:19 remaining] 41,  [2:16 remaining] 42,\n [2:14 remaining] 43,  [2:11 remaining] 44,  [2:09 remaining] 45,\n [2:07 remaining] 46,  [2:04 remaining] 47,  [2:02 remaining] 48,\n [1:59 remaining] 49,  [1:57 remaining] 50,  [1:54 remaining] 51,\n [1:52 remaining] 52,  [1:49 remaining] 53,  [1:47 remaining] 54,\n [1:45 remaining] 55,  [1:42 remaining] 56,  [1:40 remaining] 57,\n [1:38 remaining] 58,  [1:35 remaining] 59,  [1:33 remaining] 60,\n [1:30 remaining] 61,  [1:28 remaining] 62,  [1:26 remaining] 63,\n [1:24 remaining] 64,  [1:21 remaining] 65,  [1:19 remaining] 66,\n [1:17 remaining] 67,  [1:15 remaining] 68,  [1:12 remaining] 69,\n [1:10 remaining] 70,  [1:08 remaining] 71,  [1:06 remaining] 72,\n [1:04 remaining] 73,  [1:02 remaining] 74,  [59 sec remaining] 75,\n [57 sec remaining] 76,  [55 sec remaining] 77,  [52 sec remaining] 78,\n [50 sec remaining] 79,  [48 sec remaining] 80,  [45 sec remaining] 81,\n [43 sec remaining] 82,  [41 sec remaining] 83,  [38 sec remaining] 84,\n [36 sec remaining] 85,  [33 sec remaining] 86,  [31 sec remaining] 87,\n [29 sec remaining] 88,  [26 sec remaining] 89,  [24 sec remaining] 90,\n [22 sec remaining] 91,  [19 sec remaining] 92,  [17 sec remaining] 93,\n [14 sec remaining] 94,  [12 sec remaining] 95,  [10 sec remaining] 96,\n [7 sec remaining] 97,  [5 sec remaining] 98,  [2 sec remaining] \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- acled_quarters_2024_ppp[regions_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInterpretation: 1. Large Distance Scales: - The x-axis stretches to large distances, and while there is visible divergence between the observed and theoretical K-function, this may reflect clustering at large spatial scales. However, in real-world spatial analyses, large scales may not capture important localized clustering that occurs over smaller distances.\n\nEnvelope Overlap:\n\n\nWhile the black observed curve rises above the simulation envelope, the overall broadness of the envelope may obscure fine distinctions. A closer look at smaller scales or at specific distances would provide a more refined understanding of clustering in specific areas and time periods, particularly for regions like Chin or Mandalay in the context of the Burmese civil war.\n\n\nPotential Scale Sensitivity:\n\n\nSpatio-temporal processes often show different behaviors at different spatial or temporal scales. While this graph suggests some clustering, it’s possible that examining specific distance ranges more closely (e.g., shorter spatial ranges or focusing on specific temporal windows) could reveal more localized patterns of interaction that are not easily discernible in this large-scale plot.\n\n\n\nIn conclusion, the general consensus of the plots provides some indication of spatio-temporal clustering, but to gain meaningful insights, a closer, more focused analysis over smaller spatial and temporal distances is required to uncover patterns of conflict that may be masked at these larger scales.\n\n\n1.8.4 Looking Closer\nVisually, we observed that the regions of Chin, Sagaing, Mandalay, and Magway have the highest occurrences of event types such as Explosions/Remote violence, Strategic developments, Battles, and Violence against Civilians. To better understand the spatial and temporal distribution and clustering of these events, we will perform a second-order spatio-temporal point pattern analysis. This will help assess the degree of interaction or clustering of events across space and time within these key regions.\n\n1.8.4.1 Importing the relevant regions into R\n\nchin_sf &lt;- st_read(dsn = \"data/chin\", \n                layer = \"mmr_chn_polbnda_adm4_mimu_250k\")\n\nReading layer `mmr_chn_polbnda_adm4_mimu_250k' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\chin' \n  using driver `ESRI Shapefile'\nSimple feature collection with 482 features and 14 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 92.6021 ymin: 20.6399 xmax: 94.15303 ymax: 24.10598\nGeodetic CRS:  WGS 84\n\nchin_sf &lt;- st_transform(chin_sf, crs = 32647)\n\n\nchin_owin &lt;- as.owin(chin_sf)\n\n\nmagway_sf &lt;- st_read(dsn = \"data/sagaing\", \n                layer = \"mmr_mgy_polbnda_adm4_wfp_mimu_250k_1\")\n\nReading layer `mmr_mgy_polbnda_adm4_wfp_mimu_250k_1' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\sagaing' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1599 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 93.84551 ymin: 18.83204 xmax: 95.85919 ymax: 22.77128\nGeodetic CRS:  WGS 84\n\nmagway_sf &lt;- st_transform(magway_sf, crs = 32647)\n\n\nmagway_owin &lt;- as.owin(magway_sf)\n\n\nmandalay_sf &lt;- st_read(dsn = \"data/mandalay\", \n                layer = \"mmr_mdy_polbnda_adm4_mimu_250k\")\n\nReading layer `mmr_mdy_polbnda_adm4_mimu_250k' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\mandalay' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1463 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 94.82973 ymin: 20.19307 xmax: 96.89598 ymax: 23.68381\nGeodetic CRS:  WGS 84\n\nmandalay_sf &lt;- st_transform(mandalay_sf, crs = 32647)\n\n\nmandalay_owin &lt;- as.owin(mandalay_sf)\n\n\nsagaing_sf &lt;- st_read(dsn = \"data/magway\", \n                layer = \"mmr_sag_polbnda_adm4_250k_mimu_1\")\n\nReading layer `mmr_sag_polbnda_adm4_250k_mimu_1' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\data\\magway' \n  using driver `ESRI Shapefile'\nSimple feature collection with 1825 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 93.94619 ymin: 21.57594 xmax: 97.0669 ymax: 27.37205\nGeodetic CRS:  WGS 84\n\nsagaing_sf &lt;- st_transform(sagaing_sf, crs = 32647)\n\n\nsagaing_owin &lt;- as.owin(sagaing_sf)\n\n\ntemporal_acled_sf &lt;- read_rds(\"data/rds/temporal_acled_sf.rds\")\n\n\n\n1.8.4.2 Chin Region\n\n# Perform spatial intersection to keep only the points within Chin region\nchin_acled_sf &lt;- temporal_acled_sf %&gt;% filter(admin1 == \"Chin\")\n\n# Plot the Chin region and filtered points\ntm_shape(chin_sf) +\n  tm_polygons() +\n  tm_shape(chin_acled_sf) +\n  tm_dots(size = 0.3) +\n  tm_facets(by = \"quarter\", \n            free.coords = FALSE, \n            drop.units = TRUE) + \n  tm_layout(main.title = \"Region and Boundaries of Chin\",\n          main.title.position = \"center\",\n          main.title.size = 1,\n          legend.outside = TRUE,\n          frame = TRUE)\n\n\n\n\n\n\n\nwrite_rds(chin_acled_sf, \"data/rds/chin_acled_sf.rds\")\n\n\n1.8.4.2.1 Explosions/Remote violence\n\nExample &lt;- \"Explosions/Remote violence\"\nchin_acled_quarters_2021_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2022_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2023_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2024_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2021_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2022_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2023_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2024_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.2 Strategic developments\n\nExample &lt;- \"Strategic developments\"\nchin_acled_quarters_2021_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2022_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2023_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2024_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2021_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2022_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2023_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2024_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.3 Battles\n\nExample &lt;- \"Battles\"\nchin_acled_quarters_2021_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2022_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2023_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nchin_acled_quarters_2024_ppp &lt;- as.ppp(chin_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2021_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2022_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2023_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2024_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.4 Violence against civilians\n\nExample &lt;- \"Violence against civilians\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2021_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2022_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2023_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- chin_acled_quarters_2024_ppp[chin_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.3 Sagaing Region\n\nsagaing_acled_sf &lt;- temporal_acled_sf %&gt;% filter(admin1 == \"Sagaing\")\ntm_shape(sagaing_sf)+\n  tm_polygons() +\n  tm_shape(sagaing_acled_sf) +\n  tm_dots(size=0.1) +\n  tm_facets(by=\"quarter\", \n            free.coords=FALSE, \n            drop.units = TRUE) + \n  tm_layout(main.title = \"Region and Boundaries of Sagaing\",\n          main.title.position = \"center\",\n          main.title.size = 1,\n          legend.outside = TRUE,\n          frame = TRUE)\n\n\n\n\n\n\n\nwrite_rds(sagaing_acled_sf, \"data/rds/sagaing_acled_sf.rds\")\n\n\n1.8.4.3.1 Explosions/Remote violence\n\nExample &lt;- \"Explosions/Remote violence\"\nsagaing_acled_quarters_2021_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2022_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2023_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2024_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2021_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2022_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2023_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2024_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.3.2 Strategic developments\n\nExample &lt;- \"Strategic developments\"\nsagaing_acled_quarters_2021_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2022_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2023_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2024_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2021_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2022_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2023_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2024_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.3.3 Battles\n\nExample &lt;- \"Battles\"\nsagaing_acled_quarters_2021_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2022_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2023_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nsagaing_acled_quarters_2024_ppp &lt;- as.ppp(sagaing_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2021_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2022_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2023_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2024_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.3.4 Violence against civilians\n\nExample &lt;- \"Violence against civilians\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2021_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2022_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2023_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- sagaing_acled_quarters_2024_ppp[sagaing_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.4 Mandalay Region\n\nmandalay_acled_sf &lt;- temporal_acled_sf %&gt;% filter(admin1 == \"Mandalay\")\ntm_shape(mandalay_sf)+\n  tm_polygons() +\n  tm_shape(mandalay_acled_sf) +\n  tm_dots(size=0.1) +\n  tm_facets(by=\"quarter\", \n            free.coords=FALSE, \n            drop.units = TRUE) + \n  tm_layout(main.title = \"Region and Boundaries of Mandalay\",\n          main.title.position = \"center\",\n          main.title.size = 1,\n          legend.outside = TRUE,\n          frame = TRUE)\n\n\n\n\n\n\n\nwrite_rds(mandalay_acled_sf, \"data/rds/mandalay_acled_sf.rds\")\n\n\n1.8.4.4.1 Explosions/Remote violence\n\nExample &lt;- \"Explosions/Remote violence\"\nmandalay_acled_quarters_2021_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2022_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2023_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2024_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2021_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2022_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2023_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2024_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.4.2 Strategic developments\n\nExample &lt;- \"Strategic developments\"\nmandalay_acled_quarters_2021_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2022_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2023_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2024_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2021_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2022_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2023_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2024_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.4.3 Battles\n\nExample &lt;- \"Battles\"\nmandalay_acled_quarters_2021_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2022_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2023_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmandalay_acled_quarters_2024_ppp &lt;- as.ppp(mandalay_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2021_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2022_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2023_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2024_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.4.4 Violence against civilians\n\nExample &lt;- \"Violence against civilians\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2021_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2022_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2023_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- mandalay_acled_quarters_2024_ppp[mandalay_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.4 Magway Region\n\nmagway_acled_sf &lt;- temporal_acled_sf %&gt;% filter(admin1 == \"Magway\")\ntm_shape(magway_sf)+\n  tm_polygons() +\n  tm_shape(magway_acled_sf) +\n  tm_dots(size=0.1) +\n  tm_facets(by=\"quarter\", \n            free.coords=FALSE, \n            drop.units = TRUE) + \n  tm_layout(main.title = \"Region and Boundaries of Magway\",\n          main.title.position = \"center\",\n          main.title.size = 1,\n          legend.outside = TRUE,\n          frame = TRUE)\n\n\n\n\n\n\n\nwrite_rds(magway_acled_sf, \"data/rds/magway_acled_sf.rds\")\n\n\n1.8.4.2.1 Explosions/Remote violence\n\nExample &lt;- \"Explosions/Remote violence\"\nmagway_acled_quarters_2021_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2022_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2023_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2024_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2021_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2022_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2023_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2024_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.2 Strategic developments\n\nExample &lt;- \"Strategic developments\"\nmagway_acled_quarters_2021_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2022_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2023_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2024_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2021_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2022_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2023_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2024_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.3 Battles\n\nExample &lt;- \"Battles\"\nmagway_acled_quarters_2021_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2022_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2023_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nmagway_acled_quarters_2024_ppp &lt;- as.ppp(magway_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2021_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2022_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2023_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2024_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.8.4.2.4 Violence against civilians\n\nExample &lt;- \"Violence against civilians\"\nacled_quarters_2021_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2021 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2022_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2022 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2023_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2023 & event_type == Example) %&gt;%\n  select(q))\nacled_quarters_2024_ppp &lt;- as.ppp(temporal_acled_sf %&gt;%\n  filter(year == 2024 & event_type == Example) %&gt;%\n  select(q))\n\n\n2021202220232024\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2021_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2022_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2023_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n# Assuming `acled_spatio_ppp_owin` is your spatio-temporal point pattern object:\nacled_spatio_ppp_owin &lt;- magway_acled_quarters_2024_ppp[magway_owin]\nK_st &lt;- Kinhom(acled_spatio_ppp_owin, correction=\"border\")\n\n# Plot the result for visual inspection\nplot(K_st, main = \"Spatio-temporal K-function\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n# Perform the CSR test with 99 simulations\nK_ck.csr &lt;- envelope(acled_spatio_ppp_owin, Kinhom, nsim=99, correction=\"border\", parallel = parallel::detectCores())\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n# Plot the envelope with the observed K-function\nplot(K_ck.csr, main=\"Spatio-temporal K-function Envelope\", legend=TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nInterpretation:\n\nIn general, the observed K-function (black line) starts within the envelope but begins to deviate upward as the spatial distance increases, crossing beyond the envelope at larger distances.\nThis suggests that possible **spatio-temporal clustering) is occurring at larger distances beyond the theoretical expectations under complete randomness.\nThe envelope allows for a statistical comparison: if the observed K-function exceeds the envelope, it implies significant clustering at those distances.\n\n\n\nThis plot suggests that the observed pattern of events is not completely random and that significant clustering occurs at larger spatial distances and time intervals, which can reveal important insights about the underlying structure of the event occurrences.\nThus, these clusterings could suggests the following:\n\nNon-Random Targeting and Temporal Patterns:\n\n\nThe non-random nature of the observed patterns implies that conflict actors may be targeting specific regions repeatedly over certain periods, driven by strategic or political goals.\nThis could point to strategically significant areas like important roads, military installations, or regions with ethnic minorities being hotspots of repeated violence.\n\n\nLocalized Hotspots of Conflict:\n\n\nThe clustering pattern at larger distances implies that violent events, such as battles or civilian attacks, are concentrated in certain regions rather than being evenly spread across the country.\nRegions like Chin, Sagaing, Magway, and Mandalay, which have been reported as key areas of conflict, experience recurring waves of violence concentrated in specific localities, due strategic importance, military operations, or political importance."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex01.html#conclusion",
    "href": "Take-home_ex/Take-home_ex01.html#conclusion",
    "title": "Take-home Exercise 1: Geospatial Analytics for Social Good: Application of Spatial and Spatio-temporal Point Patterns Analysis to discover the geographical distribution of Armed Conflict in Myanmar",
    "section": "1.9 Conclusion",
    "text": "1.9 Conclusion\nThe war in Myanmar has involved numerous armed groups, including pro-democracy forces and ethnic militias, battling against the military junta. The situation remains highly volatile, with frequent battles occurring across various regions, including Chin, Sagaing, Magway, and Mandalay. The conflict exhibits a cyclical nature, with periods of relative calm punctuated by intense fighting, particularly during dry seasons.\nMyanmar’s political future remains uncertain, with the ongoing struggle between resistance forces and the military junta casting doubt over the country’s ability to maintain unity and stability.\nReferences - BBC News. (2021). ‘Mandalay was a massacre’: Security forces fire at protests. Retrieved from https://www.bbc.com/news/world-asia-56386348\n\nThit, N. (2022). How Sagaing Is at Forefront of Revolution Against Myanmar’s Junta. Retrieved from https://www.irrawaddy.com/opinion/analysis/how-sagaing-is-at-forefront-of-revolution-against-myanmars-junta.html\nND-Burma (2024). Human Rights Violations took place in States and Regions from Aug 22 to 31, 2024. Retrieved from https://reliefweb.int/report/myanmar/human-rights-situation-weekly-update-aug-22-31-2024-enmy\nND-Burma (2024). Human Rights Violations took place in States and Regions from Aug 15 to 21, 2024. Retrieved from https://reliefweb.int/report/myanmar/human-rights-situation-weekly-update-aug-15-21-2024-enmy\nND-Burma (2024). Human Rights Violations took place in States and Regions from Sep 1 to 7, 2024. Retrieved from https://reliefweb.int/report/myanmar/human-rights-situation-weekly-update-september-1-7-2024-enmy"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html",
    "href": "In-class_Ex/In-class_Ex11.html",
    "title": "In Class exercise 11",
    "section": "",
    "text": "Note\n\n\n\n\nExplanatory vs Predictive modeling\n\nExplanatory model =&gt; aims to identify factors/independent variable that are causally related to an outcome.\n\nHedonic Pricing Model using GWmodel\n\nPredictive model =&gt; aims to find the combination of factors that best predicts the dependent variable.\n\nCalibrating Random Forest Model\n\n\nR-square VS Adj R-Square =&gt; Adj R-Square account for the number of predictors in the model, providing a more accurate measure of fit.\nRegression Diagnostics\n\nMulticollinearity\n\nVIF\n\nBelow than 5: lower multicollinearity\nMore than 5 and Below 10: Moderate multicolinearity\nMore than 10: Strong multicolinearity\n\nMake use of the correlation matrix to determine the pairs and drop one of them if their VIF is high.\n\nLinearity Assumption\n\nThe relationship between X and the mean of Y is linear or not.\n\nNormality Assumption\n\nCheck if the residual is normally distributed\n\nSpatial Autocorrelation\n\nUse  Moran’s I test to check the residual spatial autocorrelation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#forward",
    "href": "In-class_Ex/In-class_Ex11.html#forward",
    "title": "In Class exercise 11",
    "section": "Forward",
    "text": "Forward\n\ncondo_fw_mlr &lt;- ols_step_forward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE\n)\ncondo_fw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Base Model              44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP           42984.951    43048.186    38909.581    0.64424    0.64175 \n 11     FAMILY_FRIENDLY         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH        42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_fw_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#backward",
    "href": "In-class_Ex/In-class_Ex11.html#backward",
    "title": "In Class exercise 11",
    "section": "Backward",
    "text": "Backward\n\ncondo_bw_mlr &lt;- ols_step_backward_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE\n)\ncondo_bw_mlr\n\n\n                                     Stepwise Summary                                      \n-----------------------------------------------------------------------------------------\nStep    Variable                   AIC          SBC         SBIC         R2       Adj. R2 \n-----------------------------------------------------------------------------------------\n 0      Full Model              42970.175    43075.567    38895.493    0.65179    0.64736 \n 1      PROX_TOP_PRIMARY_SCH    42968.188    43068.310    38893.478    0.65178    0.64761 \n 2      PROX_SUPERMARKET        42966.534    43061.387    38891.789    0.65170    0.64777 \n 3      PROX_HAWKER_MARKET      42965.558    43055.141    38890.764    0.65145    0.64777 \n 4      PROX_KINDERGARTEN       42966.758    43051.072    38891.872    0.65067    0.64723 \n-----------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_bw_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#bi-direction",
    "href": "In-class_Ex/In-class_Ex11.html#bi-direction",
    "title": "In Class exercise 11",
    "section": "Bi-direction",
    "text": "Bi-direction\n\ncondo_bi_mlr &lt;- ols_step_both_p(\n  condo_mlr,\n  p_val = 0.05,\n  details = FALSE\n)\ncondo_bi_mlr\n\n\n                                       Stepwise Summary                                        \n---------------------------------------------------------------------------------------------\nStep    Variable                       AIC          SBC         SBIC         R2       Adj. R2 \n---------------------------------------------------------------------------------------------\n 0      Base Model                  44449.068    44459.608    40371.745    0.00000    0.00000 \n 1      AREA_SQM (+)                43587.753    43603.562    39510.883    0.45184    0.45146 \n 2      PROX_CBD (+)                43243.523    43264.602    39167.182    0.56928    0.56868 \n 3      PROX_PARK (+)               43177.691    43204.039    39101.331    0.58915    0.58829 \n 4      FREEHOLD (+)                43125.474    43157.092    39049.179    0.60438    0.60327 \n 5      AGE (+)                     43069.222    43106.109    38993.167    0.62010    0.61878 \n 6      PROX_ELDERLYCARE (+)        43046.515    43088.672    38970.548    0.62659    0.62502 \n 7      PROX_SHOPPING_MALL (+)      43020.990    43068.417    38945.209    0.63367    0.63188 \n 8      PROX_URA_GROWTH_AREA (+)    43009.092    43061.788    38933.407    0.63720    0.63517 \n 9      PROX_MRT (+)                42999.058    43057.024    38923.483    0.64023    0.63796 \n 10     PROX_BUS_STOP (+)           42984.951    43048.186    38909.581    0.64424    0.64175 \n 11     FAMILY_FRIENDLY (+)         42981.085    43049.590    38905.797    0.64569    0.64296 \n 12     NO_Of_UNITS (+)             42975.246    43049.021    38900.092    0.64762    0.64465 \n 13     PROX_CHILDCARE (+)          42971.858    43050.902    38896.812    0.64894    0.64573 \n 14     PROX_PRIMARY_SCH (+)        42966.758    43051.072    38891.872    0.65067    0.64723 \n 15     PROX_KINDERGARTEN (+)       42965.558    43055.141    38890.764    0.65145    0.64777 \n---------------------------------------------------------------------------------------------\n\nFinal Model Output \n------------------\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751161.087 \nR-Squared                    0.651       MSE                570600646491.086 \nAdj. R-Squared               0.648       Coef. Var                    43.135 \nPred R-Squared               0.638       AIC                       42965.558 \nMAE                     413583.799       SBC                       43055.141 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.514394e+15          15        1.009596e+14    176.936    0.0000 \nResidual      8.102529e+14        1420    570600646491.086                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     459826.675    114616.014                   4.012    0.000     234991.777     684661.574 \n            AREA_SQM      12720.174       368.610        0.581     34.509    0.000      11997.096      13443.252 \n            PROX_CBD     -75676.065      5816.474       -0.258    -13.011    0.000     -87085.870     -64266.259 \n           PROX_PARK     575749.528     65523.382        0.151      8.787    0.000     447216.504     704282.552 \n            FREEHOLD     360203.286     48768.851        0.140      7.386    0.000     264536.552     455870.021 \n                 AGE     -24697.719      2752.751       -0.167     -8.972    0.000     -30097.615     -19297.824 \n    PROX_ELDERLYCARE     182435.081     39910.469        0.088      4.571    0.000     104145.268     260724.893 \n  PROX_SHOPPING_MALL    -224513.955     36588.872       -0.117     -6.136    0.000    -296288.004    -152739.906 \nPROX_URA_GROWTH_AREA      40145.474     11758.824        0.062      3.414    0.001      17078.942      63212.007 \n            PROX_MRT    -311753.202     57670.032       -0.119     -5.406    0.000    -424880.814    -198625.590 \n       PROX_BUS_STOP     711858.014    135420.040        0.140      5.257    0.000     446213.188     977502.840 \n     FAMILY_FRIENDLY     144034.218     46874.683        0.057      3.073    0.002      52083.153     235985.283 \n         NO_Of_UNITS       -236.270        88.032       -0.051     -2.684    0.007       -408.956        -63.583 \n      PROX_CHILDCARE    -336118.857    108331.761       -0.088     -3.103    0.002    -548626.339    -123611.374 \n    PROX_PRIMARY_SCH     162183.897     60202.895        0.063      2.694    0.007      44087.730     280280.063 \n   PROX_KINDERGARTEN     141915.768     79726.155        0.029      1.780    0.075     -14477.927     298309.464 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\nplot(condo_bi_mlr)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#checking-for-multicollinearity",
    "href": "In-class_Ex/In-class_Ex11.html#checking-for-multicollinearity",
    "title": "In Class exercise 11",
    "section": "Checking for multicollinearity",
    "text": "Checking for multicollinearity\n\ncheck_collinearity(condo_bi_mlr$model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n             AREA_SQM 1.15 [1.10, 1.24]         1.07      0.87     [0.81, 0.91]\n             PROX_CBD 1.60 [1.50, 1.73]         1.27      0.62     [0.58, 0.67]\n            PROX_PARK 1.21 [1.15, 1.30]         1.10      0.83     [0.77, 0.87]\n             FREEHOLD 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n                  AGE 1.41 [1.33, 1.52]         1.19      0.71     [0.66, 0.75]\n     PROX_ELDERLYCARE 1.52 [1.42, 1.63]         1.23      0.66     [0.61, 0.70]\n   PROX_SHOPPING_MALL 1.49 [1.40, 1.60]         1.22      0.67     [0.62, 0.72]\n PROX_URA_GROWTH_AREA 1.33 [1.26, 1.43]         1.16      0.75     [0.70, 0.79]\n             PROX_MRT 1.96 [1.83, 2.13]         1.40      0.51     [0.47, 0.55]\n        PROX_BUS_STOP 2.89 [2.66, 3.15]         1.70      0.35     [0.32, 0.38]\n      FAMILY_FRIENDLY 1.38 [1.30, 1.48]         1.18      0.72     [0.67, 0.77]\n          NO_Of_UNITS 1.45 [1.37, 1.56]         1.21      0.69     [0.64, 0.73]\n       PROX_CHILDCARE 3.29 [3.02, 3.59]         1.81      0.30     [0.28, 0.33]\n     PROX_PRIMARY_SCH 2.21 [2.05, 2.40]         1.49      0.45     [0.42, 0.49]\n    PROX_KINDERGARTEN 1.11 [1.06, 1.20]         1.05      0.90     [0.84, 0.94]\n\n\n\nplot(check_collinearity(condo_bi_mlr$model)) +\n  # theme is used to make the display the column name more friendly\n  theme(axis.text.x = element_text (\n    angle = 45, hjust = 1\n  ))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#linearity-assumption-test",
    "href": "In-class_Ex/In-class_Ex11.html#linearity-assumption-test",
    "title": "In Class exercise 11",
    "section": "Linearity Assumption test",
    "text": "Linearity Assumption test\n\nout &lt;- plot(check_model(condo_bi_mlr$model,\n                        panel = FALSE))\nout[[2]] # have 6 plot"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#normality-assumption-test",
    "href": "In-class_Ex/In-class_Ex11.html#normality-assumption-test",
    "title": "In Class exercise 11",
    "section": "Normality Assumption Test",
    "text": "Normality Assumption Test\n\nplot(check_normality(condo_bi_mlr$model))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#checking-of-outliers",
    "href": "In-class_Ex/In-class_Ex11.html#checking-of-outliers",
    "title": "In Class exercise 11",
    "section": "Checking of Outliers",
    "text": "Checking of Outliers\nMethod =&gt; Can be \"all\" or some of \"cook\", \"pareto\", \"zscore\", \"zscore_robust\", \"iqr\", \"ci\", \"eti\", \"hdi\", \"bci\", \"mahalanobis\", \"mahalanobis_robust\", \"mcd\", \"ics\", \"optics\" or \"lof\".\n\noutliers &lt;- check_outliers(condo_bi_mlr$model,\n                           method = \"cook\")\noutliers\n\nOK: No outliers detected.\n- Based on the following method and threshold: cook (1).\n- For variable: (Whole model)\n\n\n\nplot(check_outliers(condo_bi_mlr$model,\n                           method = \"pareto\"))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#visualising-spatial-non-stationary",
    "href": "In-class_Ex/In-class_Ex11.html#visualising-spatial-non-stationary",
    "title": "In Class exercise 11",
    "section": "Visualising spatial non-stationary",
    "text": "Visualising spatial non-stationary\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr_output &lt;- as.data.frame(condo_fw_mlr$model$residuals) %&gt;%\n  rename(`FW_MLR_RES` = `condo_fw_mlr$model$residuals`)\n\nNext, we will join the newly created data frame with condo_resale_sf object.\n\ncondo_resale_sf &lt;- cbind(condo_resale_sf, \n                        mlr_output$FW_MLR_RES) %&gt;%\n  rename(`MLR_RES` = `mlr_output.FW_MLR_RES`)\n\n\ntmap_mode(\"plot\")\ntm_shape(mpsz)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale_sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") \n\n\n\n\n\n\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex11.html#spatial-stationary-test",
    "href": "In-class_Ex/In-class_Ex11.html#spatial-stationary-test",
    "title": "In Class exercise 11",
    "section": "Spatial Stationary Test",
    "text": "Spatial Stationary Test\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  mutate(nb = st_knn(geometry, k=6,\n                     longlat = FALSE),\n         wt = st_weights(nb,\n                         style = \"W\"),\n         .before = 1)\n\nNext, global_moran_perm() of sfdep is used to perform global Moran permutation test.\n\nglobal_moran_perm(condo_resale_sf$MLR_RES, \n                  condo_resale_sf$nb, \n                  condo_resale_sf$wt, \n                  alternative = \"two.sided\", \n                  nsim = 99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.32254, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06.html",
    "title": "In Class exercise 6",
    "section": "",
    "text": "Local statistics\n\nIdentifying outliers based on a certain attribute of its neighbours\nTobler’s First law of Geography: Everything is related to everything else, but near things are more related than distant things\n\nGeospatial Dependency\n\nSpatial dependence is the spatial relationship of variable values (for themes defined over space, such as rainfall) or locations (for themes defined as objects, such as cities).\n\nSpatial Autocorrelation\n\nSpatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable.\nInferred after the rejections of the null hypothesis\nPositive autocorrelation: A big lump, congregation of points on the grid\nNegative autocorrelation: More outliers can be seen, checkers board pattern seen\n\nLocal Indicator of Spatial Analysis (LISA)\n\nA subset of localised geospatial statistics methods.\nAny spatial statistics that satisfies the following two requirements (Anselin, L. 1995):\n\nthe LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation;\nthe sum of LISAs for all observations is proportional to a global indicator of spatial association.\n\nIdentify outliers or clusters"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06.html#notes",
    "href": "In-class_Ex/In-class_Ex06.html#notes",
    "title": "In Class exercise 6",
    "section": "",
    "text": "Local statistics\n\nIdentifying outliers based on a certain attribute of its neighbours\nTobler’s First law of Geography: Everything is related to everything else, but near things are more related than distant things\n\nGeospatial Dependency\n\nSpatial dependence is the spatial relationship of variable values (for themes defined over space, such as rainfall) or locations (for themes defined as objects, such as cities).\n\nSpatial Autocorrelation\n\nSpatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable.\nInferred after the rejections of the null hypothesis\nPositive autocorrelation: A big lump, congregation of points on the grid\nNegative autocorrelation: More outliers can be seen, checkers board pattern seen\n\nLocal Indicator of Spatial Analysis (LISA)\n\nA subset of localised geospatial statistics methods.\nAny spatial statistics that satisfies the following two requirements (Anselin, L. 1995):\n\nthe LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation;\nthe sum of LISAs for all observations is proportional to a global indicator of spatial association.\n\nIdentify outliers or clusters"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex06.html#installing-and-loading-the-r-packages",
    "title": "In Class exercise 6",
    "section": "6.1 Installing and Loading the R packages",
    "text": "6.1 Installing and Loading the R packages\nFor the purpose of this study, five R packages will be used. They are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nsfdep, an R package that acts as an interface to ‘spdep’ to integrate with ‘sf’ objects and the ‘tidyverse’.\ntidyverse, a collection of R packages designed for data science. It includes packages like dplyr for data manipulation, ggplot2 for data visualization, and tidyr for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.\n\n\npacman::p_load(sf, sfdep, tmap, tidyverse)\n\n\n6.1.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan_sf &lt;- st_read(dsn = \"data/In-class_Ex05/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\In-class_Ex05\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n6.1.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/In-class_Ex05/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n6.1.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed by using left_join() of dplyr package.\n\nhunan_GDPPC &lt;- left_join(hunan_sf,hunan2012)%&gt;%\n  select(1:4, 7, 15)\n\n\n\n6.2 Plotting the chloropleth map\n\nDeriving Queen’s contiguity weights: sfdep methods\n\nwm_q &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wt = st_weights(nb, style = \"W\"),\n         .before = 1)\n\n\n\nComputing Global Moran’s I\n\nmoranI &lt;- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)\nglimpse(moranI)\n\nList of 2\n $ I: num 0.301\n $ K: num 7.64\n\n\nIn general, Moran’s I test will be performed instead of just computing the Moran’s statistics. With sfdep package, Moran’s I test can be performed by using global_moran_test() as shown in the code chunk below:\n\nglobal_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\nExpectation: -0.011494253 negative value suggests clustering\np-value will determine whether the null hypothesis is rejected or not. Not rejecting the null hypothesis would result in the statistic derived from Moran I to be unusable\n\nglobal_moran_perm(wm_q$GDPPC, wm_q$nb, wm_q$wt, nsim=99)\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 100 \n\nstatistic = 0.30075, observed rank = 100, p-value &lt; 2.2e-16\nalternative hypothesis: two.sided\n\n\nAs seen from the moran I statistic, even thought the p-value is far smaller, the statistic is stable, approaching 0.30075\n\nset.seed(1234)\n\nIt is always good to set.seed() before performing simulation, to ensure reproducibility.\n\nlisa &lt;- wm_q %&gt;%\n  mutate(local_moran = local_moran(\n    GDPPC, nb, wt, nsim = 99),\n    .before = 1) %&gt;%\n  unnest(local_moran)\n\nTo ensure consistency, stay with 1 type of p-value either p_ii, p_ii_sim or p_folded_sim\nMean useful if the data follows the trend of standard distribution and Median would be useful if skewness (close to 0) is detected - Note that row consistency also applies to mean or median - Examine the current trend of the skewness to make these decisions\n\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(lisa) + \n  tm_fill(\"ii\") +\n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(\n    main.title = \"local Moran's I of GDPPC\",\n    main.title.size = 1\n  )\n\nmap2 &lt;- tm_shape(lisa) + \n  tm_fill(\"p_ii\", breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) +\n  tm_borders(alpha = 0.5) +\n  tm_layout(\n    main.title = \"p-value of local Moran's I\",\n    main.title.size = 0.8\n  )\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nVisualising LISA map\n\nlisa_sig &lt;- lisa %&gt;%\n  filter(p_ii &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(lisa) + \n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\ntm_shape(lisa_sig) +\n  tm_fill(\"mean\") +\n  tm_borders(alpha = 0.4)\n\n\n\n\n\n\n\n\nLISA map is categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low\n\n\nComputing local Gi* statistics\nAs usual we will need to derive a spatial weight matrix before we can compute local Gi* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.\n\nwm_idw &lt;- hunan_GDPPC %&gt;%\n  mutate(nb = st_contiguity(geometry),\n         wts = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nCalculating the local Gi* by using the code chunk below:\n\nHCSA &lt;- wm_idw %&gt;% \n  mutate(local_Gi = local_gstar_perm(\n    GDPPC, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi)\nHCSA\n\nSimple feature collection with 88 features and 18 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n# A tibble: 88 × 19\n   gi_star cluster   e_gi     var_gi std_dev p_value p_sim p_folded_sim skewness\n     &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.0416 Low     0.0114 0.00000721  0.0376 9.70e-1  0.8          0.4     0.901\n 2 -0.333  Low     0.0111 0.00000553 -0.299  7.65e-1  0.92         0.46    0.941\n 3  0.281  High    0.0121 0.00000832  0.0405 9.68e-1  0.8          0.4     0.912\n 4  0.411  High    0.0117 0.00000943  0.298  7.66e-1  0.68         0.34    1.09 \n 5  0.387  High    0.0113 0.00000869  0.415  6.78e-1  0.5          0.25    0.992\n 6 -0.368  High    0.0116 0.00000605 -0.498  6.18e-1  0.76         0.38    1.15 \n 7  3.56   High    0.0149 0.00000745  2.67   7.56e-3  0.04         0.02    0.950\n 8  2.52   High    0.0135 0.00000482  1.74   8.17e-2  0.14         0.07    0.434\n 9  4.56   High    0.0144 0.00000514  3.77   1.64e-4  0.02         0.01    0.634\n10  1.16   Low     0.0108 0.00000479  1.45   1.48e-1  0.18         0.09    0.476\n# ℹ 78 more rows\n# ℹ 10 more variables: kurtosis &lt;dbl&gt;, nb &lt;nb&gt;, wts &lt;list&gt;, NAME_2 &lt;chr&gt;,\n#   ID_3 &lt;int&gt;, NAME_3 &lt;chr&gt;, ENGTYPE_3 &lt;chr&gt;, County &lt;chr&gt;, GDPPC &lt;dbl&gt;,\n#   geometry &lt;POLYGON [°]&gt;\n\n\n\n\nVisualising hot spot and cold spot areas\n\n\nShow the code\ntmap_mode(\"plot\")\nmap1 &lt;- tm_shape(HCSA) +\n  tm_fill(\"gi_star\") + \n  tm_borders(alpha = 0.5) +\n  tm_view(set.zoom.limits = c(6,8)) +\n  tm_layout(main.title = \"Gi* of GDPPC\",\n            main.title.size = 0.8)\n\nmap2 &lt;- tm_shape(HCSA) +\n  tm_fill(\"p_value\",\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n              labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\")) + \n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"p-value of Gi*\",\n            main.title.size = 0.8)\n\ntmap_arrange(map1, map2, ncol = 2)\n\n\n\n\n\n\n\n\n\n\nHCSA_sig &lt;- HCSA %&gt;% \n  filter(p_sim &lt; 0.05)\ntmap_mode(\"plot\")\ntm_shape(HCSA) +\n  tm_polygons() +\n  tm_borders(alpha = 0.5) +\n  tm_shape(HCSA_sig) +\n  tm_fill(\"gi_star\") +\n  tm_borders(alpha = 0.4)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04.html",
    "title": "In Class exercise 4",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#overview",
    "href": "In-class_Ex/In-class_Ex04.html#overview",
    "title": "In Class exercise 4",
    "section": "",
    "text": "A spatio-temporal point process (also called space-time or spatial-temporal point process) is a random collection of points, where each point represents the time and location of an event. Examples of events include incidence of disease, sightings or births of a species, or the occurrences of fires, earthquakes, lightning strikes, tsunamis, or volcanic eruptions.\nThe analysis of spatio-temporal point patterns is becoming increasingly necessary, given the rapid emergence of geographically and temporally indexed data in a wide range of fields. Several spatio-temporal point patterns analysis methods have been introduced and implemented in R in the last ten years. This chapter shows how various R packages can be combined to run a set of spatio-temporal point pattern analyses in a guided and intuitive way. A real world forest fire events in Kepulauan Bangka Belitung, Indonesia from 1st January 2023 to 31st December 2023 is used to illustrate the methods, procedures and interpretations."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#learning-outcome",
    "href": "In-class_Ex/In-class_Ex04.html#learning-outcome",
    "title": "In Class exercise 4",
    "section": "4.1 Learning Outcome",
    "text": "4.1 Learning Outcome\n\n4.1.1 The research questions\nThe specific question we would like to answer is:\n\nare the locations of forest fire in Kepulauan Bangka Belitung spatial and spatio-temporally independent?\nif the answer is NO, where and when the observed forest fire locations tend to cluster?\n\n\n\n4.1.2 The data\nFor the purpose of this exercise, two data sets are used, they are:\n\nforestfires, a csv file provides locations of forest fire detected from the Moderate Resolution Imaging Spectroradiometer (MODIS) sensor data. The data are downloaded from Fire Information for Resource Management System. For the purpose of this exercise, only forest fires within Kepulauan Bangka Belitung will be used.\nKepulauan_Bangka_Belitung, an ESRI shapefile showing the sub-district (i.e. kelurahan) boundary of Kepulauan Bangka Belitung. The data set was downloaded from Indonesia Geospatial portal. The original data covers the whole Indonesia. For the purpose of this exercise, only sub-districts within Kepulauan Bangka Belitung are extracted."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex04.html#installing-and-loading-the-r-packages",
    "title": "In Class exercise 4",
    "section": "4.2 Installing and Loading the R packages",
    "text": "4.2 Installing and Loading the R packages\nFor the purpose of this study, five R packages will be used. They are:\n\nrgdal for importing geospatial data in GIS file format such as shapefile into R and save them as Spatial*DataFrame,\nmaptools for converting Spatial* object into ppp object,\nraster for handling raster data in R,\nsparr provides functions to estimate fixed and adaptive kernel-smooth spatial relative risk surfaces via the density-ratio method and perform subsequent inferences,\nspatstat for performing Spatial Point Patterns Analysis such as kcross, Lcross, etc., and\ntmap for producing cartographic quality thematic maps.\n\n\npacman::p_load(sf, raster, spatstat, sparr, tmap, tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#importing-data-into-r",
    "href": "In-class_Ex/In-class_Ex04.html#importing-data-into-r",
    "title": "In Class exercise 4",
    "section": "4.3 Importing data into R",
    "text": "4.3 Importing data into R\n\n4.3.1 Importing and Preparing Forest Fire shapeful\n\nkbb_sf &lt;- st_read(dsn = \"data/In-class_Ex04\", \n                  layer = \"Kepulauan_Bangka_Belitung\") %&gt;%\n  st_union() %&gt;%\n  st_zm(drop = TRUE, what = \"ZM\") %&gt;% # dropping the Z-value\n  st_transform(crs = 32748)\n\nReading layer `Kepulauan_Bangka_Belitung' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\In-class_Ex04' \n  using driver `ESRI Shapefile'\nSimple feature collection with 298 features and 27 fields\nGeometry type: POLYGON\nDimension:     XYZ\nBounding box:  xmin: 105.1085 ymin: -3.116593 xmax: 106.8488 ymax: -1.501603\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsummary(kbb_sf)\n\n MULTIPOLYGON    epsg:32748 +proj=utm ... \n            1             0             0 \n\n\nFurthermore we create an owin object from the sf data type\n\nkbb_owin &lt;- as.owin(kbb_sf)\nkbb_owin\n\nwindow: polygonal boundary\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n\n\nTo ensure that the output is an owin object\n\nclass(kbb_owin)\n\n[1] \"owin\"\n\n\n\n\n4.3.2 Importing and Preparing Forest Fire data\nNext we will import the forest data set into R:\n\nfire_sf &lt;- read_csv(\"data/In-class_Ex04/forestfires.csv\") %&gt;%\n  st_as_sf(coords = c(\"longitude\", \"latitude\"), \n           crs = 4326) %&gt;%\n  st_transform(crs = 32748)\n\nBecause ppp object only accept numerical or character as mark. The code below is used to transform acq_date data type to numeric.\n\nfire_sf &lt;- fire_sf %&gt;%\n  mutate(\"DayofYear\" = yday(acq_date)) %&gt;%\n  mutate(\"Month_num\" = month(acq_date)) %&gt;%\n  mutate(\"Month_fac\" = month(acq_date, label = TRUE, abbr = FALSE))\n\nsummary(fire_sf)\n\n   brightness         scan           track          acq_date         \n Min.   :300.3   Min.   :1.000   Min.   :1.000   Min.   :2023-01-10  \n 1st Qu.:314.3   1st Qu.:1.000   1st Qu.:1.000   1st Qu.:2023-08-01  \n Median :318.7   Median :1.100   Median :1.100   Median :2023-09-15  \n Mean   :320.9   Mean   :1.315   Mean   :1.119   Mean   :2023-09-02  \n 3rd Qu.:324.7   3rd Qu.:1.400   3rd Qu.:1.200   3rd Qu.:2023-10-14  \n Max.   :396.2   Max.   :4.200   Max.   :1.900   Max.   :2023-12-18  \n                                                                     \n    acq_time     satellite          instrument          confidence   \n Min.   : 248   Length:741         Length:741         Min.   :  0.0  \n 1st Qu.: 633   Class :character   Class :character   1st Qu.: 57.0  \n Median : 649   Mode  :character   Mode  :character   Median : 68.0  \n Mean   : 731                                         Mean   : 65.6  \n 3rd Qu.: 659                                         3rd Qu.: 77.0  \n Max.   :1915                                         Max.   :100.0  \n                                                                     \n    version        bright_t31         frp          daynight              type  \n Min.   :61.03   Min.   :274.9   Min.   :  3.0   Length:741         Min.   :0  \n 1st Qu.:61.03   1st Qu.:293.6   1st Qu.:  8.4   Class :character   1st Qu.:0  \n Median :61.03   Median :296.6   Median : 13.2   Mode  :character   Median :0  \n Mean   :61.03   Mean   :296.1   Mean   : 20.1                      Mean   :0  \n 3rd Qu.:61.03   3rd Qu.:299.2   3rd Qu.: 21.8                      3rd Qu.:0  \n Max.   :61.03   Max.   :311.2   Max.   :220.2                      Max.   :0  \n                                                                               \n          geometry     DayofYear       Month_num          Month_fac  \n POINT        :741   Min.   : 10.0   Min.   : 1.000   October  :185  \n epsg:32748   :  0   1st Qu.:213.0   1st Qu.: 8.000   September:146  \n +proj=utm ...:  0   Median :258.0   Median : 9.000   August   :143  \n                     Mean   :245.9   Mean   : 8.579   November : 88  \n                     3rd Qu.:287.0   3rd Qu.:10.000   July     : 79  \n                     Max.   :352.0   Max.   :12.000   June     : 34  \n                                                      (Other)  : 66"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#visualising-the-fire-points",
    "href": "In-class_Ex/In-class_Ex04.html#visualising-the-fire-points",
    "title": "In Class exercise 4",
    "section": "4.4 Visualising the Fire Points",
    "text": "4.4 Visualising the Fire Points\n\ntm_shape(kbb_sf)+\n  tm_polygons() +\n  tm_shape(fire_sf) +\n  tm_dots()\n\n\n\n\n\n\n\n\nWe will then prepare a point symbol map showing the monthly geographic distribution of forest fires in 2023. The map should look similar to the figure below.\n\ntm_shape(kbb_sf)+\n  tm_polygons()+\n  tm_shape(fire_sf)+\n  tm_dots(size = 0.1)+\n  tm_facets(by=\"Month_fac\", free.coords = FALSE, drop.units = FALSE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04.html#extracting-forest-fire-by-month",
    "href": "In-class_Ex/In-class_Ex04.html#extracting-forest-fire-by-month",
    "title": "In Class exercise 4",
    "section": "4.5 Extracting forest fire by month",
    "text": "4.5 Extracting forest fire by month\nThe code chunk below is used to remove the unwanted fields from the fire_sf sf data frame. This is because as.ppp() only need the mark field and geometry field from the input sf data frame.\n\nfire_month &lt;- fire_sf %&gt;%\n  select(Month_num)\n\n\n4.5.1 Creating ppp\nThe code chunk below is used to derive a ppp object called fire_month from fire_month sf data frame\n\nfire_month_ppp &lt;- as.ppp(fire_month)\nfire_month_ppp\n\nMarked planar point pattern: 741 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [521564.1, 695791] x [9658137, 9828767] units\n\n\n\n\n4.5.2 Creating Owin object\nThe code chunk below is used to combine origin_am_ppp and am_owin_objects into one.\n\nfire_month_owin &lt;- fire_month_ppp[kbb_owin]\nsummary(fire_month_owin)\n\nMarked planar point pattern:  741 points\nAverage intensity 6.424519e-08 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   8.000   9.000   8.579  10.000  12.000 \n\nWindow: polygonal boundary\n2 separate polygons (no holes)\n           vertices        area relative.area\npolygon 1     47493 11533600000      1.00e+00\npolygon 2       256      306427      2.66e-05\nenclosing rectangle: [512066.8, 705559.4] x [9655398, 9834006] units\n                     (193500 x 178600 units)\nWindow area = 11533900000 square units\nFraction of frame area: 0.334\n\n\nComputing Spatio-Temporal KDE Next, spattemp.density() of sparr package is used to compute the STKDE\n\nst_kde &lt;- spattemp.density(fire_month_owin)\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 15102.47 (spatial)\n  lambda = 0.0304 (temporal)\n\nNo. of observations\n  741 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [512066.8, 705559.4] x [9655398, 9834006]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [1.233458e-27, 8.202976e-10]\n\n\nIn the code chunk below, plot() of R base is used to get the KDE for between July 2023 - December 2023\n\ntims &lt;- c(7, 8, 9, 10, 11, 12)\npar(mfcol=c(2, 3))\nfor(i in tims){\n  plot(st_kde, i, \n       override.par=FALSE,\n       fix.range=TRUE,\n       main=paste(\"KDE at month\", i))\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02.html",
    "title": "In Class exercise 2",
    "section": "",
    "text": "For this in-class exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#getting-started",
    "href": "In-class_Ex/In-class_Ex02.html#getting-started",
    "title": "In Class exercise 2",
    "section": "",
    "text": "For this in-class exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2014-subzone-boundary-data",
    "title": "In Class exercise 2",
    "section": "2.1 Working with Master Plan 2014 Subzone Boundary Data",
    "text": "2.1 Working with Master Plan 2014 Subzone Boundary Data\n\nmpsz14_shp &lt;- st_read(dsn = \"data/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe code chunk below demonstrates data conversion from SHP file format to KML file format:\n\nmpsz14_kml &lt;- st_write(mpsz14_shp, \n  \"data/MasterPlan2014SubzoneBoundaryWebKML.kml\",\n  delete_dsn = TRUE)\n\nThe delete_dsn argument relates to the dsn (Data Source Name) to delete original source before writing the new file"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-master-plan-2019-subzone-boundary-data",
    "title": "In Class exercise 2",
    "section": "2.2 Working with Master Plan 2019 Subzone Boundary Data",
    "text": "2.2 Working with Master Plan 2019 Subzone Boundary Data\n\nmpsz19_kml &lt;- st_read(\"data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"data/MasterPlan2019SubzoneBoundaryWebSHP\", \n                      layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\MasterPlan2019SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02.html#working-with-population-data",
    "href": "In-class_Ex/In-class_Ex02.html#working-with-population-data",
    "title": "In Class exercise 2",
    "section": "2.3 Working with population data",
    "text": "2.3 Working with population data\n\npopdata &lt;- read_csv(\"data/respopagesextod2023/respopagesextod2023.csv\")\n\n\n2.3.1 Data Preparation\n\npopdata2023 &lt;- popdata %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup() %&gt;%\n  pivot_wider(names_from = AG,\n              values_from = POP)\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\nAs seen above, unlike other programming languages, R indexes from ‘1’ instead of ‘0’. The rows begin from [1],[6],[11], etc.\n\n\n2.3.2 Data Wrangling\n\npopdata2023 &lt;- popdata2023 %&gt;%\nmutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\nmutate_at(.vars = vars(PA, SZ),\n          .funs = list(toupper))\n\n\n\n2.3.3 Joining the attribute data and geospatial data\n\nmpsz_2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                       by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp,\n                       by = c(\"SZ\" = \"SUBZONE_N\"))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html",
    "href": "Hands-on_Ex/Hands-on_Ex12.html",
    "title": "Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n\nIn this in-class exercise, you will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#overview",
    "title": "Geographically Weighted Predictive Models",
    "section": "",
    "text": "Predictive modelling uses statistical learning or machine learning techniques to predict outcomes. By and large, the event one wants to predict is in the future. However, a set of known outcome and predictors (also known as variables) will be used to calibrate the predictive models.\nGeospatial predictive modelling is conceptually rooted in the principle that the occurrences of events being modeled are limited in distribution. When geographically referenced data are used, occurrences of events are neither uniform nor random in distribution over space. There are geospatial factors (infrastructure, sociocultural, topographic, etc.) that constrain and influence where the locations of events occur. Geospatial predictive modeling attempts to describe those constraints and influences by spatially correlating occurrences of historical geospatial locations with environmental factors that represent those constraints and influences.\n\n\nIn this in-class exercise, you will learn how to build predictive model by using geographical random forest method. By the end of this hands-on exercise, you will acquire the skills of:\n\npreparing training and test data sets by using appropriate data sampling methods,\ncalibrating predictive models by using both geospatial statistical learning and machine learning methods,\ncomparing and selecting the best model for predicting the future outcome,\npredicting the future outcomes by using the best model calibrated."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#the-data",
    "title": "Geographically Weighted Predictive Models",
    "section": "The Data",
    "text": "The Data\n\nAspatial dataset:\n\nHDB Resale data: a list of HDB resale transacted prices in Singapore from Jan 2017 onwards. It is in csv format which can be downloaded from Data.gov.sg.\n\nGeospatial dataset:\n\nMP14_SUBZONE_WEB_PL: a polygon feature data providing information of URA 2014 Master Plan Planning Subzone boundary data. It is in ESRI shapefile format. This data set was also downloaded from Data.gov.sg\n\nLocational factors with geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nEldercare data is a list of eldercare in Singapore. It is in shapefile format.\nHawker Centre data is a list of hawker centres in Singapore. It is in geojson format.\nParks data is a list of parks in Singapore. It is in geojson format.\nSupermarket data is a list of supermarkets in Singapore. It is in geojson format.\nCHAS clinics data is a list of CHAS clinics in Singapore. It is in geojson format.\nChildcare service data is a list of childcare services in Singapore. It is in geojson format.\nKindergartens data is a list of kindergartens in Singapore. It is in geojson format.\n\nDownloaded from Datamall.lta.gov.sg.\n\nMRT data is a list of MRT/LRT stations in Singapore with the station names and codes. It is in shapefile format.\nBus stops data is a list of bus stops in Singapore. It is in shapefile format.\n\n\nLocational factors without geographic coordinates:\n\nDownloaded from Data.gov.sg.\n\nPrimary school data is extracted from the list on General information of schools from data.gov portal. It is in csv format.\n\nRetrieved/Scraped from other sources\n\nCBD coordinates obtained from Google.\nShopping malls data is a list of Shopping malls in Singapore obtained from Wikipedia.\nGood primary schools is a list of primary schools that are ordered in ranking in terms of popularity and this can be found at Local Salary Forum."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#installing-and-loading-r-packages",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#installing-and-loading-r-packages",
    "title": "Geographically Weighted Predictive Models",
    "section": "Installing and Loading R packages",
    "text": "Installing and Loading R packages\nThis code chunk performs 3 tasks:\n\nA list called packages will be created and will consists of all the R packages required to accomplish this exercise.\nCheck if R packages on package have been installed in R and if not, they will be installed.\nAfter all the R packages have been installed, they will be loaded.\n\n\npacman::p_load(sf, spdep, GWmodel, SpatialML, \n               tmap, rsample, Metrics, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#preparing-data",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#preparing-data",
    "title": "Geographically Weighted Predictive Models",
    "section": "Preparing Data",
    "text": "Preparing Data\n\nReading data file to rds\nReading the input data sets. It is in simple feature data frame.\n\nmdata &lt;- read_rds(\"data/Hands-on_Ex12/mdata.rds\")\n\n\nstr(mdata)\n\nsf [15,901 × 18] (S3: sf/tbl_df/tbl/data.frame)\n $ resale_price            : num [1:15901] 330000 360000 370000 375000 380000 380000 385000 395000 395000 395000 ...\n $ floor_area_sqm          : num [1:15901] 92 91 92 99 92 92 92 92 93 91 ...\n $ storey_order            : int [1:15901] 1 3 1 2 2 4 3 2 4 3 ...\n $ remaining_lease_mths    : num [1:15901] 684 738 733 700 715 732 706 745 731 725 ...\n $ PROX_CBD                : num [1:15901] 8.82 9.84 9.56 9.61 8.35 ...\n $ PROX_ELDERLYCARE        : num [1:15901] 0.251 0.632 1.082 0.347 0.196 ...\n $ PROX_HAWKER             : num [1:15901] 0.4418 0.2697 0.2583 0.4365 0.0701 ...\n $ PROX_MRT                : num [1:15901] 0.689 1.097 0.886 1.409 0.887 ...\n $ PROX_PARK               : num [1:15901] 0.745 0.429 0.78 0.178 0.913 ...\n $ PROX_GOOD_PRISCH        : num [1:15901] 1.27 0.405 2.094 0.138 1.503 ...\n $ PROX_MALL               : num [1:15901] 0.553 1.068 0.975 1.175 1.006 ...\n $ PROX_CHAS               : num [1:15901] 0.136 0.257 0.191 0.299 0.103 ...\n $ PROX_SUPERMARKET        : num [1:15901] 0.271 0.31 0.319 0.459 0.338 ...\n $ WITHIN_350M_KINDERGARTEN: int [1:15901] 1 1 1 1 1 1 1 1 1 0 ...\n $ WITHIN_350M_CHILDCARE   : int [1:15901] 6 5 2 3 3 2 3 4 3 2 ...\n $ WITHIN_350M_BUS         : int [1:15901] 8 8 8 7 6 9 6 6 5 4 ...\n $ WITHIN_1KM_PRISCH       : int [1:15901] 2 2 1 2 2 1 3 2 2 2 ...\n $ geometry                :sfc_POINT of length 15901; first list element:  'XY' num [1:2] 29180 38822\n - attr(*, \"sf_column\")= chr \"geometry\"\n - attr(*, \"agr\")= Factor w/ 3 levels \"constant\",\"aggregate\",..: NA NA NA NA NA NA NA NA NA NA ...\n  ..- attr(*, \"names\")= chr [1:17] \"resale_price\" \"floor_area_sqm\" \"storey_order\" \"remaining_lease_mths\" ...\n\n\n\nnames(mdata)\n\n [1] \"resale_price\"             \"floor_area_sqm\"          \n [3] \"storey_order\"             \"remaining_lease_mths\"    \n [5] \"PROX_CBD\"                 \"PROX_ELDERLYCARE\"        \n [7] \"PROX_HAWKER\"              \"PROX_MRT\"                \n [9] \"PROX_PARK\"                \"PROX_GOOD_PRISCH\"        \n[11] \"PROX_MALL\"                \"PROX_CHAS\"               \n[13] \"PROX_SUPERMARKET\"         \"WITHIN_350M_KINDERGARTEN\"\n[15] \"WITHIN_350M_CHILDCARE\"    \"WITHIN_350M_BUS\"         \n[17] \"WITHIN_1KM_PRISCH\"        \"geometry\"                \n\n\n\n\nData Sampling\nThe entire data are split into training and test data sets with 65% and 35% respectively by using initial_split() of rsample package. rsample is one of the package of tigymodels.\n\nset.seed(1234)\nresale_split &lt;- initial_split(mdata, \n                              prop = 6.5/10,)\ntrain_data &lt;- training(resale_split)\ntest_data &lt;- testing(resale_split)\n\n\nwrite_rds(train_data, \"data/Hands-on_Ex12/train_data.rds\")\nwrite_rds(test_data, \"data/Hands-on_Ex12/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#computing-correlation-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#computing-correlation-matrix",
    "title": "Geographically Weighted Predictive Models",
    "section": "Computing Correlation Matrix",
    "text": "Computing Correlation Matrix\nBefore loading the predictors into a predictive model, it is always a good practice to use correlation matrix to examine if there is sign of multicolinearity.\n\nmdata_nogeo &lt;- mdata %&gt;%\n  st_drop_geometry()\ncorrplot::corrplot(cor(mdata_nogeo[, 2:17]), \n                   diag = FALSE, \n                   order = \"AOE\",\n                   tl.pos = \"td\", \n                   tl.cex = 0.5, \n                   method = \"number\", \n                   type = \"upper\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe correlation matrix above shows that all the correlation values are below 0.8. Hence, there is no sign of multicolinearity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#retriving-the-stored-data",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#retriving-the-stored-data",
    "title": "Geographically Weighted Predictive Models",
    "section": "Retriving the Stored Data",
    "text": "Retriving the Stored Data\n\ntrain_data &lt;- read_rds(\"data/Hands-on_Ex12/train_data.rds\")\ntest_data &lt;- read_rds(\"data/Hands-on_Ex12/test_data.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#building-a-non-spatial-multiple-linear-regression",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#building-a-non-spatial-multiple-linear-regression",
    "title": "Geographically Weighted Predictive Models",
    "section": "Building a non-spatial multiple linear regression",
    "text": "Building a non-spatial multiple linear regression\n\nprice_mlr &lt;- lm(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                data=train_data)\nsummary(price_mlr)\n\n\nCall:\nlm(formula = resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths + \n    PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK + \n    PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\nCoefficients:\n                           Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\nfloor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\nstorey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\nremaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\nPROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\nPROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\nPROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\nPROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\nPROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\nPROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\nPROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\nWITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\nWITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\nWITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\nWITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 61650 on 10320 degrees of freedom\nMultiple R-squared:  0.7373,    Adjusted R-squared:  0.737 \nF-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16\n\n\n\nwrite_rds(price_mlr, \"data/Hands-on_Ex12/price_mlr.rds\" )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#gwr-predictive-method",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#gwr-predictive-method",
    "title": "Geographically Weighted Predictive Models",
    "section": "gwr predictive method",
    "text": "gwr predictive method\nIn this section, you will learn how to calibrate a model to predict HDB resale price by using geographically weighted regression method of GWmodel package.\n\nConverting the sf data.frame to SpatialPointDataFrame\n\ntrain_data_sp &lt;- as_Spatial(train_data)\ntrain_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 10335 \nextent      : 11597.31, 42623.63, 28217.39, 48741.06  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,          PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       218000,             74,            1,                  555, 0.999393538715878, 1.98943787433087e-08, 0.0333358643817954, 0.0220407324774434, 0.0441643212802781, 0.0652540365486641,                0, 6.20621206270077e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1186888,            133,           17,                 1164,  19.6500691667807,     3.30163731686804,   2.86763031236184,   2.13060636038504,   2.41313695915468,   10.6223726149914, 2.27100643784442,    0.808332738794272,     1.57131703651196,                        7,                    20, ... \n\n\n\n\nComputing adaptive bandwidth\nNext, bw.gwr() of GWmodel package will be used to determine the optimal bandwidth to be used.\n\n\n\n\n\n\nNote\n\n\n\nThe code chunk below is used to determine adaptive bandwidth and CV method is used to determine the optimal bandwidth.\n\n\n\nbw_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=train_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\nThe result shows that 40 neighbour points will be the optimal bandwidth to be used if adaptive bandwidth is used for this data set.\n\nwrite_rds(bw_adaptive, \"data/Hands-on_Ex12/bw_adaptive.rds\")\n\n\n\nConstructing the adaptive bandwidth gwr model\nFirst, let us call the save bandwidth by using the code chunk below.\n\nbw_adaptive &lt;- read_rds(\"data/Hands-on_Ex12/bw_adaptive.rds\")\n\nNow, we can go ahead to calibrate the gwr-based hedonic pricing model by using adaptive bandwidth and Gaussian kernel as shown in the code chunk below.\n\ngwr_adaptive &lt;- gwr.basic(formula = resale_price ~\n                            floor_area_sqm + storey_order +\n                            remaining_lease_mths + PROX_CBD + \n                            PROX_ELDERLYCARE + PROX_HAWKER +\n                            PROX_MRT + PROX_PARK + PROX_MALL + \n                            PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                            WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                            WITHIN_1KM_PRISCH,\n                          data=train_data_sp,\n                          bw=bw_adaptive, \n                          kernel = 'gaussian', \n                          adaptive=TRUE,\n                          longlat = FALSE)\n\nThe code chunk below will be used to save the model in rds format for future use.\n\nwrite_rds(gwr_adaptive, \"data/Hands-on_Ex12/gwr_adaptive.rds\")\n\n\n\nRetrieve gwr output object\nThe code chunk below will be used to retrieve the save gwr model object.\n\ngwr_adaptive &lt;- read_rds(\"data/Hands-on_Ex12/gwr_adaptive.rds\")\n\nThe code below can be used to display the model output.\n\ngwr_adaptive\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-10-21 17:11:29.140173 \n   Call:\n   gwr.basic(formula = resale_price ~ floor_area_sqm + storey_order + \n    remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + \n    PROX_MRT + PROX_PARK + PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN + \n    WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH, \n    data = train_data_sp, bw = bw_adaptive, kernel = \"gaussian\", \n    adaptive = TRUE, longlat = FALSE)\n\n   Dependent (y) variable:  resale_price\n   Independent variables:  floor_area_sqm storey_order remaining_lease_mths PROX_CBD PROX_ELDERLYCARE PROX_HAWKER PROX_MRT PROX_PARK PROX_MALL PROX_SUPERMARKET WITHIN_350M_KINDERGARTEN WITHIN_350M_CHILDCARE WITHIN_350M_BUS WITHIN_1KM_PRISCH\n   Number of data points: 10335\n   ***********************************************************************\n   *                    Results of Global Regression                     *\n   ***********************************************************************\n\n   Call:\n    lm(formula = formula, data = data)\n\n   Residuals:\n    Min      1Q  Median      3Q     Max \n-205193  -39120   -1930   36545  472355 \n\n   Coefficients:\n                              Estimate Std. Error t value Pr(&gt;|t|)    \n   (Intercept)              107601.073  10601.261  10.150  &lt; 2e-16 ***\n   floor_area_sqm             2780.698     90.579  30.699  &lt; 2e-16 ***\n   storey_order              14299.298    339.115  42.167  &lt; 2e-16 ***\n   remaining_lease_mths        344.490      4.592  75.027  &lt; 2e-16 ***\n   PROX_CBD                 -16930.196    201.254 -84.124  &lt; 2e-16 ***\n   PROX_ELDERLYCARE         -14441.025    994.867 -14.516  &lt; 2e-16 ***\n   PROX_HAWKER              -19265.648   1273.597 -15.127  &lt; 2e-16 ***\n   PROX_MRT                 -32564.272   1744.232 -18.670  &lt; 2e-16 ***\n   PROX_PARK                 -5712.625   1483.885  -3.850 0.000119 ***\n   PROX_MALL                -14717.388   2007.818  -7.330 2.47e-13 ***\n   PROX_SUPERMARKET         -26881.938   4189.624  -6.416 1.46e-10 ***\n   WITHIN_350M_KINDERGARTEN   8520.472    632.812  13.464  &lt; 2e-16 ***\n   WITHIN_350M_CHILDCARE     -4510.650    354.015 -12.741  &lt; 2e-16 ***\n   WITHIN_350M_BUS             813.493    222.574   3.655 0.000259 ***\n   WITHIN_1KM_PRISCH         -8010.834    491.512 -16.298  &lt; 2e-16 ***\n\n   ---Significance stars\n   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n   Residual standard error: 61650 on 10320 degrees of freedom\n   Multiple R-squared: 0.7373\n   Adjusted R-squared: 0.737 \n   F-statistic:  2069 on 14 and 10320 DF,  p-value: &lt; 2.2e-16 \n   ***Extra Diagnostic information\n   Residual sum of squares: 3.922202e+13\n   Sigma(hat): 61610.08\n   AIC:  257320.2\n   AICc:  257320.3\n   BIC:  247249\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 40 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: Euclidean distance metric is used.\n\n   ****************Summary of GWR coefficient estimates:******************\n                                   Min.     1st Qu.      Median     3rd Qu.\n   Intercept                -3.2478e+08 -4.7727e+05 -8.3004e+03  5.5025e+05\n   floor_area_sqm           -2.8714e+04  1.4475e+03  2.3011e+03  3.3900e+03\n   storey_order              3.3186e+03  8.5899e+03  1.0826e+04  1.3397e+04\n   remaining_lease_mths     -1.4431e+03  2.6063e+02  3.9048e+02  5.2865e+02\n   PROX_CBD                 -1.0837e+07 -5.7697e+04 -1.3787e+04  2.6552e+04\n   PROX_ELDERLYCARE         -3.2195e+07 -4.0643e+04  1.0562e+04  6.1054e+04\n   PROX_HAWKER              -2.3985e+08 -5.1365e+04  3.0026e+03  6.4287e+04\n   PROX_MRT                 -1.1632e+07 -1.0488e+05 -4.9373e+04  5.1037e+03\n   PROX_PARK                -6.5961e+06 -4.8671e+04 -8.8128e+02  5.3498e+04\n   PROX_MALL                -1.8112e+07 -7.4238e+04 -1.3982e+04  4.9779e+04\n   PROX_SUPERMARKET         -4.5761e+06 -6.3461e+04 -1.7429e+04  3.5616e+04\n   WITHIN_350M_KINDERGARTEN -4.1823e+05 -6.0040e+03  9.0209e+01  4.7127e+03\n   WITHIN_350M_CHILDCARE    -1.0273e+05 -2.2375e+03  2.6668e+02  2.6388e+03\n   WITHIN_350M_BUS          -1.1757e+05 -1.4719e+03  1.1626e+02  1.7584e+03\n   WITHIN_1KM_PRISCH        -6.6465e+05 -5.5959e+03  2.6916e+02  5.7500e+03\n                                  Max.\n   Intercept                1.6493e+08\n   floor_area_sqm           5.0907e+04\n   storey_order             2.9537e+04\n   remaining_lease_mths     1.8119e+03\n   PROX_CBD                 2.2411e+07\n   PROX_ELDERLYCARE         8.2444e+07\n   PROX_HAWKER              5.9654e+06\n   PROX_MRT                 2.0189e+08\n   PROX_PARK                1.5188e+07\n   PROX_MALL                1.0443e+07\n   PROX_SUPERMARKET         3.8330e+06\n   WITHIN_350M_KINDERGARTEN 6.6799e+05\n   WITHIN_350M_CHILDCARE    1.0802e+05\n   WITHIN_350M_BUS          3.7313e+04\n   WITHIN_1KM_PRISCH        5.0231e+05\n   ************************Diagnostic information*************************\n   Number of data points: 10335 \n   Effective number of parameters (2trace(S) - trace(S'S)): 1730.101 \n   Effective degrees of freedom (n-2trace(S) + trace(S'S)): 8604.899 \n   AICc (GWR book, Fotheringham, et al. 2002, p. 61, eq 2.33): 238871.9 \n   AIC (GWR book, Fotheringham, et al. 2002,GWR p. 96, eq. 4.22): 237036.9 \n   BIC (GWR book, Fotheringham, et al. 2002,GWR p. 61, eq. 2.34): 238209.1 \n   Residual sum of squares: 4.829191e+12 \n   R-square value:  0.967657 \n   Adjusted R-square value:  0.9611534 \n\n   ***********************************************************************\n   Program stops at: 2024-10-21 17:13:04.188966 \n\n\n\n\nConverting the test data from sf data.frame to SpatialPointDataFrame\n\ntest_data_sp &lt;- test_data %&gt;%\n  as_Spatial()\ntest_data_sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 5566 \nextent      : 11597.31, 42623.63, 28287.8, 48669.59  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 17\nnames       : resale_price, floor_area_sqm, storey_order, remaining_lease_mths,         PROX_CBD,     PROX_ELDERLYCARE,        PROX_HAWKER,           PROX_MRT,          PROX_PARK,   PROX_GOOD_PRISCH,        PROX_MALL,            PROX_CHAS,     PROX_SUPERMARKET, WITHIN_350M_KINDERGARTEN, WITHIN_350M_CHILDCARE, ... \nmin values  :       230888,             74,            1,                  546, 1.00583660772922, 3.34897933104965e-07, 0.0474019664161957, 0.0414043955932523, 0.0502664084494264, 0.0907500295577619,                0, 4.55547870890763e-09, 1.21715176356525e-07,                        0,                     0, ... \nmax values  :      1050000,            138,           14,                 1151,  19.632402730488,     3.30163731686804,   2.83106651960209,   2.13060636038504,   2.41313695915468,   10.6169590126272, 2.26056404492346,     0.79249074802552,     1.53786629004208,                        7,                    16, ... \n\n\n\n\nComputing adaptive bandwidth for the test data\n\ngwr_bw_test_adaptive &lt;- bw.gwr(resale_price ~ floor_area_sqm +\n                  storey_order + remaining_lease_mths +\n                  PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER +\n                  PROX_MRT + PROX_PARK + PROX_MALL + \n                  PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                  WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                  WITHIN_1KM_PRISCH,\n                  data=test_data_sp,\n                  approach=\"CV\",\n                  kernel=\"gaussian\",\n                  adaptive=TRUE,\n                  longlat=FALSE)\n\n\nwrite_rds(gwr_bw_test_adaptive, \"data/Hands-on_Ex12/gwr_bw_test_adaptive.rds\")\n\n\ngwr_bw_test_adaptive &lt;- read_rds(\"data/Hands-on_Ex12/gwr_bw_test_adaptive.rds\")\n\n\n\nComputing predicted values of the test data\n\ngwr_pred &lt;- gwr.predict(formula = resale_price ~\n                          floor_area_sqm + storey_order +\n                          remaining_lease_mths + PROX_CBD + \n                          PROX_ELDERLYCARE + PROX_HAWKER + \n                          PROX_MRT + PROX_PARK + PROX_MALL + \n                          PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                          WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n                          WITHIN_1KM_PRISCH, \n                        data=train_data_sp, \n                        predictdata = test_data_sp, \n                        bw=40, \n                        kernel = 'gaussian', \n                        adaptive=TRUE, \n                        longlat = FALSE)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#preparing-coordinates-data",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#preparing-coordinates-data",
    "title": "Geographically Weighted Predictive Models",
    "section": "Preparing coordinates data",
    "text": "Preparing coordinates data\n\nExtracting coordinates data\nThe code chunk below extract the x,y coordinates of the full, training and test data sets.\n\ncoords &lt;- st_coordinates(mdata)\ncoords_train &lt;- st_coordinates(train_data)\ncoords_test &lt;- st_coordinates(test_data)\n\nBefore continue, we write all the output into rds for future used.\n\ncoords_train &lt;- write_rds(coords_train, \"data/Hands-on_Ex12/coords_train.rds\" )\ncoords_test &lt;- write_rds(coords_test, \"data/Hands-on_Ex12/coords_test.rds\" )\n\n\ncoords_train &lt;- read_rds(\"data/Hands-on_Ex12/coords_train.rds\" )\ncoords_test &lt;- read_rds(\"data/Hands-on_Ex12/coords_test.rds\" )\n\n\n\nDroping geometry field\nFirst, we will drop geometry column of the sf data.frame by using st_drop_geometry() of sf package.\n\ntrain_data &lt;- train_data %&gt;% \n  st_drop_geometry()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#calibrating-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#calibrating-random-forest-model",
    "title": "Geographically Weighted Predictive Models",
    "section": "Calibrating Random Forest Model",
    "text": "Calibrating Random Forest Model\nIn this section, you will learn how to calibrate a model to predict HDB resale price by using random forest function of ranger package.\n\nset.seed(1234)\nrf &lt;- ranger(resale_price ~ floor_area_sqm + storey_order + \n               remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE + \n               PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL + \n               PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n               WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + \n               WITHIN_1KM_PRISCH,\n             data=train_data)\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728 \n\n\n\nwrite_rds(rf, \"data/Hands-on_Ex12/rf.rds\")\n\n\nrf &lt;- read_rds(\"data/Hands-on_Ex12/rf.rds\")\nrf\n\nRanger result\n\nCall:\n ranger(resale_price ~ floor_area_sqm + storey_order + remaining_lease_mths +      PROX_CBD + PROX_ELDERLYCARE + PROX_HAWKER + PROX_MRT + PROX_PARK +      PROX_MALL + PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +      WITHIN_350M_CHILDCARE + WITHIN_350M_BUS + WITHIN_1KM_PRISCH,      data = train_data) \n\nType:                             Regression \nNumber of trees:                  500 \nSample size:                      10335 \nNumber of independent variables:  14 \nMtry:                             3 \nTarget node size:                 5 \nVariable importance mode:         none \nSplitrule:                        variance \nOOB prediction error (MSE):       728602496 \nR squared (OOB):                  0.9495728"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex12.html#calibrating-geographical-random-forest-model",
    "href": "Hands-on_Ex/Hands-on_Ex12.html#calibrating-geographical-random-forest-model",
    "title": "Geographically Weighted Predictive Models",
    "section": "Calibrating Geographical Random Forest Model",
    "text": "Calibrating Geographical Random Forest Model\nIn this section, you will learn how to calibrate a model to predict HDB resale price by using grf() of SpatialML package.\n\nCalibrating using training data\nThe code chunk below calibrate a geographic ranform forest model by using grf() of SpatialML package.\n\nset.seed(1234)\ngwRF_adaptive &lt;- grf(formula = resale_price ~ floor_area_sqm + storey_order +\n                       remaining_lease_mths + PROX_CBD + PROX_ELDERLYCARE +\n                       PROX_HAWKER + PROX_MRT + PROX_PARK + PROX_MALL +\n                       PROX_SUPERMARKET + WITHIN_350M_KINDERGARTEN +\n                       WITHIN_350M_CHILDCARE + WITHIN_350M_BUS +\n                       WITHIN_1KM_PRISCH,\n                     dframe=train_data, \n                     bw=55,\n                     kernel=\"adaptive\",\n                     coords=coords_train)\n\nLet’s save the model output by using the code chunk below.\n\nwrite_rds(gwRF_adaptive, \"data/Hands-on_Ex12/gwRF_adaptive.rds\")\n\n\n\nPredicting by using test data\n\nPreparing the test data\nThe code chunk below will be used to combine the test data with its corresponding coordinates data.\n\ntest_data &lt;- cbind(test_data, coords_test) %&gt;%\n  st_drop_geometry()\n\n\n\nPredicting with test data\nNext, predict.grf() of spatialML package will be used to predict the resale value by using the test data and gwRF_adaptive model calibrated earlier.\n\ngwRF_pred &lt;- predict.grf(gwRF_adaptive, \n                           test_data, \n                           x.var.name=\"X\",\n                           y.var.name=\"Y\", \n                           local.w=1,\n                           global.w=0)\n\nBefore moving on, let us save the output into rds file for future use.\n\ngwRF_pred &lt;- write_rds(gwRF_pred, \"data/Hands-on_Ex12/GRF_pred.rds\")\n\n\n\nConverting the predicting output into a data frame\nThe output of the predict.grf() is a vector of predicted values. It is wiser to convert it into a data frame for further visualisation and analysis.\n\ngwRF_pred &lt;- read_rds(\"data/Hands-on_Ex12/GRF_pred.rds\")\nGRF_pred_df &lt;- as.data.frame(gwRF_pred)\n\nIn the code chunk below, cbind() is used to append the predicted values onto test_datathe\n\ntest_data_p &lt;- cbind(test_data, GRF_pred_df)\n\n\nwrite_rds(test_data_p, \"data/Hands-on_Ex12/test_data_p.rds\")\n\n\n\n\nCalculating Root Mean Square Error\nThe root mean square error (RMSE) allows us to measure how far predicted values are from observed values in a regression analysis. In the code chunk below, rmse() of Metrics package is used to compute the RMSE.\n\nrmse(test_data_p$resale_price, \n     test_data_p$gwRF_pred)\n\n[1] 27302.9\n\n\n\n\nVisualising the predicted values\nAlternatively, scatterplot can be used to visualise the actual resale price and the predicted resale price by using the code chunk below.\n\nggplot(data = test_data_p,\n       aes(x = gwRF_pred,\n           y = resale_price)) +\n  geom_point()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nA better predictive model should have the scatter point close to the diagonal line. The scatter plot can be also used to detect if any outliers in the model."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html",
    "href": "Hands-on_Ex/Hands-on_Ex10.html",
    "title": "Spatially Constrained Cluster Analysis",
    "section": "",
    "text": "In this section, you will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#overview",
    "title": "Spatially Constrained Cluster Analysis",
    "section": "",
    "text": "In this section, you will learn how to derive spatially constrained cluster by using skater() method of spdep package.\n\n\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#data-import-and-prepatation",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#data-import-and-prepatation",
    "title": "Spatially Constrained Cluster Analysis",
    "section": "Data Import and Prepatation",
    "text": "Data Import and Prepatation\nIn this section, you will import all the data into the R environment from the previous week that is needed for this exercise.\nThe code chunks used are shown below:\n\nshan_sf &lt;- read_rds(\"data/Hands-on_Ex09/rds/shan_sf.rds\")\nshan_ict &lt;- read_rds(\"data/Hands-on_Ex09/rds/shan_ict.rds\")\nshan_sf_cluster &lt;- read_rds(\"data/Hands-on_Ex09/rds/shan_sf_cluster.rds\")\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\n\nConverting into SpatialPolygonsDataFrame\nFirst, we need to convert shan_sf into SpatialPolygonsDataFrame. This is because SKATER function only support sp objects such as SpatialPolygonDataFrame.\nThe code chunk below uses as_Spatial() of sf package to convert shan_sf into a SpatialPolygonDataFrame called shan_sp.\n\nshan_sp &lt;- as_Spatial(shan_sf)\n\n\n\nComputing Neighbour List\nNext, poly2nd() of spdep package will be used to compute the neighbours list from polygon list.\n\nshan.nb &lt;- poly2nb(shan_sp)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\nWe can plot the neighbours list on shan_sp by using the code chunk below. Since we now can plot the community area boundaries as well, we plot this graph on top of the map. The first plot command gives the boundaries. This is followed by the plot of the neighbor list object, with coordinates applied to the original SpatialPolygonDataFrame (Shan state township boundaries) to extract the centroids of the polygons. These are used as the nodes for the graph representation. We also set the color to blue and specify add=TRUE to plot the network on top of the boundaries.\n\ncoords &lt;- st_coordinates(\n  st_centroid(st_geometry(shan_sf)))\n\n\nplot(st_geometry(shan_sf), \n     border=grey(.5))\nplot(shan.nb,\n     coords, \n     col=\"blue\", \n     add=TRUE)\n\n\n\n\n\n\n\n\nNote that if you plot the network first and then the boundaries, some of the areas will be clipped. This is because the plotting area is determined by the characteristics of the first plot. In this example, because the boundary map extends further than the graph, we plot it first.\n\n\nComputing minimum spanning tree\n\nCalculating edge costs\nNext, nbcosts() of spdep package is used to compute the cost of each edge. It is the distance between it nodes. This function compute this distance using a data.frame with observations vector in each node.\nThe code chunk below is used to compute the cost of each edge.\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\nFor each observation, this gives the pairwise dissimilarity between its values on the five variables and the values for the neighbouring observation (from the neighbour list). Basically, this is the notion of a generalised weight for a spatial weights matrix.\nNext, We will incorporate these costs into a weights object in the same way as we did in the calculation of inverse of distance weights. In other words, we convert the neighbour list to a list weights object by specifying the just computed lcosts as the weights.\nIn order to achieve this, nb2listw() of spdep package is used as shown in the code chunk below.\nNote that we specify the style as B to make sure the cost values are not row-standardised.\n\nshan.w &lt;- nb2listw(shan.nb, \n                   lcosts, \n                   style=\"B\")\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\n\n\nComputing minimum spanning tree\nThe minimum spanning tree is computed by mean of the mstree() of spdep package as shown in the code chunk below.\n\nshan.mst &lt;- mstree(shan.w)\n\nAfter computing the MST, we can check its class and dimension by using the code chunk below.\n\nclass(shan.mst)\n\n[1] \"mst\"    \"matrix\"\n\ndim(shan.mst)\n\n[1] 54  3\n\n\nNote that the dimension is 54 and not 55. This is because the minimum spanning tree consists on n-1 edges (links) in order to traverse all the nodes.\nWe can display the content of shan.mst by using head() as shown in the code chunk below.\n\nhead(shan.mst)\n\n     [,1] [,2]      [,3]\n[1,]    3    2 257.31610\n[2,]    2    8 204.32952\n[3,]    8    9  90.82891\n[4,]    8    6 140.01101\n[5,]    6   36  95.66782\n[6,]   36    4 138.12050\n\n\nThe plot method for the MST include a way to show the observation numbers of the nodes in addition to the edge. As before, we plot this together with the township boundaries. We can see how the initial neighbour list is simplified to just one edge connecting each of the nodes, while passing through all the nodes.\n\nplot(st_geometry(shan_sf), \n                 border=gray(.5))\nplot.mst(shan.mst, \n         coords, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles=0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\n\n\nComputing spatially constrained clusters using SKATER method\nThe code chunk below compute the spatially constrained cluster using skater() of spdep package.\n\nclust6 &lt;- spdep::skater(edges = shan.mst[,1:2], \n                 data = shan_ict, \n                 method = \"euclidean\", \n                 ncuts = 5)\n\nThe skater() takes three mandatory arguments: - the first two columns of the MST matrix (i.e. not the cost), - the data matrix (to update the costs as units are being grouped), and - the number of cuts. Note: It is set to one less than the number of clusters. So, the value specified is not the number of clusters, but the number of cuts in the graph, one less than the number of clusters.\nThe result of the skater() is an object of class skater. We can examine its contents by using the code chunk below.\n\nstr(clust6)\n\nList of 8\n $ groups      : num [1:55] 6 6 1 6 6 6 6 6 6 6 ...\n $ edges.groups:List of 6\n  ..$ :List of 3\n  .. ..$ node: num 3\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num [1:18] 47 27 53 38 42 15 41 51 43 32 ...\n  .. ..$ edge: num [1:17, 1:3] 53 15 42 38 41 51 15 27 15 43 ...\n  .. ..$ ssw : num 3759\n  ..$ :List of 3\n  .. ..$ node: num [1:22] 13 48 54 55 45 37 34 16 25 52 ...\n  .. ..$ edge: num [1:21, 1:3] 48 55 54 37 34 16 45 25 13 13 ...\n  .. ..$ ssw : num 3423\n  ..$ :List of 3\n  .. ..$ node: num [1:2] 44 20\n  .. ..$ edge: num [1, 1:3] 44 20 95\n  .. ..$ ssw : num 95\n  ..$ :List of 3\n  .. ..$ node: num 23\n  .. ..$ edge: num[0 , 1:3] \n  .. ..$ ssw : num 0\n  ..$ :List of 3\n  .. ..$ node: num [1:11] 6 2 1 36 4 9 10 8 46 5 ...\n  .. ..$ edge: num [1:10, 1:3] 6 1 2 36 4 6 8 9 10 8 ...\n  .. ..$ ssw : num 1458\n $ not.prune   : NULL\n $ candidates  : int [1:6] 1 2 3 4 5 6\n $ ssto        : num 12613\n $ ssw         : num [1:6] 12613 10977 9962 9540 9123 ...\n $ crit        : num [1:2] 1 Inf\n $ vec.crit    : num [1:55] 1 1 1 1 1 1 1 1 1 1 ...\n - attr(*, \"class\")= chr \"skater\"\n\n\nThe most interesting component of this list structure is the groups vector containing the labels of the cluster to which each observation belongs (as before, the label itself is arbitary). This is followed by a detailed summary for each of the clusters in the edges.groups list. Sum of squares measures are given as ssto for the total and ssw to show the effect of each of the cuts on the overall criterion.\nWe can check the cluster assignment by using the conde chunk below.\n\nccs6 &lt;- clust6$groups\nccs6\n\n [1] 6 6 1 6 6 6 6 6 6 6 2 3 3 3 2 3 3 3 2 4 3 2 5 3 3 3 2 3 2 2 3 2 2 3 3 6 3 2\n[39] 2 2 2 2 2 4 3 6 2 3 3 3 2 3 2 3 3\n\n\nWe can find out how many observations are in each cluster by means of the table command. Parenthetially, we can also find this as the dimension of each vector in the lists contained in edges.groups. For example, the first list has node with dimension 12, which is also the number of observations in the first cluster.\n\ntable(ccs6)\n\nccs6\n 1  2  3  4  5  6 \n 1 18 22  2  1 11 \n\n\nLastly, we can also plot the pruned tree that shows the five clusters on top of the townshop area.\n\nplot(st_geometry(shan_sf), \n     border=gray(.5))\nplot(clust6, \n     coords, \n     cex.lab=.7,\n     groups.colors=c(\"red\",\"green\",\"blue\", \"brown\", \"pink\"),\n     cex.circles=0.005, \n     add=TRUE)\n\n\n\n\n\n\n\n\n\n\nVisualising the clusters in choropleth map\nThe code chunk below is used to plot the newly derived clusters by using SKATER method.\n\ngroups_mat &lt;- as.matrix(clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`SP_CLUSTER`=`as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"SP_CLUSTER\")\n\n\n\n\n\n\n\n\nFor easy comparison, it will be better to place both the hierarchical clustering and spatially constrained hierarchical clustering maps next to each other.\n\nhclust.map &lt;- qtm(shan_sf_cluster,\n                  \"CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\nshclust.map &lt;- qtm(shan_sf_spatialcluster,\n                   \"SP_CLUSTER\") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(hclust.map, shclust.map,\n             asp=NA, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#spatially-constrained-clustering-clustgeo-method",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#spatially-constrained-clustering-clustgeo-method",
    "title": "Spatially Constrained Cluster Analysis",
    "section": "Spatially Constrained Clustering: ClustGeo Method",
    "text": "Spatially Constrained Clustering: ClustGeo Method\nIn this section, you will gain hands-on experience on using functions provided by ClustGeo package to perform non-spatially constrained hierarchical cluster analysis and spatially constrained cluster analysis.\n\nA short note about ClustGeo package\nClustGeo package is an R package specially designed to support the need of performing spatially constrained cluster analysis. More specifically, it provides a Ward-like hierarchical clustering algorithm called hclustgeo() including spatial/geographical constraints.\nIn the nutshell, the algorithm uses two dissimilarity matrices D0 and D1 along with a mixing parameter alpha, whereby the value of alpha must be a real number between [0, 1]. D0 can be non-Euclidean and the weights of the observations can be non-uniform. It gives the dissimilarities in the attribute/clustering variable space. D1, on the other hand, gives the dissimilarities in the constraint space. The criterion minimised at each stage is a convex combination of the homogeneity criterion calculated with D0 and the homogeneity criterion calculated with D1.\nThe idea is then to determine a value of alpha which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest. This need is supported by a function called choicealpha().\n\n\nWard-like hierarchical clustering: ClustGeo\nClustGeo package provides function called hclustgeo() to perform a typical Ward-like hierarchical clustering just like hclust() you learned in previous section.\nTo perform non-spatially constrained hierarchical clustering, we only need to provide the function a dissimilarity matrix as shown in the code chunk below.\n\nnongeo_cluster &lt;- hclustgeo(proxmat)\nplot(nongeo_cluster, cex = 0.5)\nrect.hclust(nongeo_cluster, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\nNote that the dissimilarity matrix must be an object of class dist, i.e. an object obtained with the function dist(). For sample code chunk, please refer to 5.7.6 Computing proximity matrix\n\nMapping the clusters formed\nSimilarly, we can plot the clusters on a categorical area shaded map by using the steps we learned in 5.7.12 Mapping the clusters formed.\n\ngroups &lt;- as.factor(cutree(nongeo_cluster, k=6))\n\n\nshan_sf_ngeo_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\n\nqtm(shan_sf_ngeo_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\n\n\n\nSpatially Constrained Hierarchical Clustering\nBefore we can performed spatially constrained hierarchical clustering, a spatial distance matrix will be derived by using st_distance() of sf package.\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\nNotice that as.dist() is used to convert the data frame into matrix.\nNext, choicealpha() will be used to determine a suitable value for the mixing parameter alpha as shown in the code chunk below.\n\ncr &lt;- choicealpha(proxmat, distmat, range.alpha = seq(0, 1, 0.1), K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWith reference to the graphs above, alpha = 0.2 will be used as shown in the code chunk below.\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\n\nNext, cutree() is used to derive the cluster objecct.\n\ngroups &lt;- as.factor(cutree(clustG, k=6))\n\nWe will then join back the group list with shan_sf polygon feature data frame by using the code chunk below.\n\nshan_sf_Gcluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER` = `as.matrix.groups.`)\n\nWe can now plot the map of the newly delineated spatially constrained clusters.\n\nqtm(shan_sf_Gcluster, \"CLUSTER\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex10.html#visual-interpretation-of-clusters",
    "href": "Hands-on_Ex/Hands-on_Ex10.html#visual-interpretation-of-clusters",
    "title": "Spatially Constrained Cluster Analysis",
    "section": "Visual Interpretation of Clusters",
    "text": "Visual Interpretation of Clusters\n\nVisualising individual clustering variable\nCode chunk below is used to reveal the distribution of a clustering variable (i.e RADIO_PR) by cluster.\n\nggplot(data = shan_sf_ngeo_cluster,\n       aes(x = CLUSTER, y = RADIO_PR)) +\n  geom_boxplot()\n\n\n\n\n\n\n\n\nThe boxplot reveals Cluster 3 displays the highest mean Radio Ownership Per Thousand Household. This is followed by Cluster 2, 1, 4, 6 and 5.\n\n\nMultivariate Visualisation\nPast studies shown that parallel coordinate plot can be used to reveal clustering variables by cluster very effectively. In the code chunk below, ggparcoord() of GGally package\n\nggparcoord(data = shan_sf_ngeo_cluster, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ CLUSTER) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\n\n\nThe parallel coordinate plot above reveals that households in Cluster 4 townships tend to own the highest number of TV and mobile-phone. On the other hand, households in Cluster 5 tends to own the lowest of all the five ICT.\nNote that the scale argument of ggparcoor() provide several methods to scale the clustering variables. They are:\n\nstd: univariately, subtract mean and divide by standard deviation.\nrobust: univariately, subtract median and divide by median absolute deviation.\nuniminmax: univariately, scale so the minimum of the variable is zero, and the maximum is one.\nglobalminmax: no scaling is done; the range of the graphs is defined by the global minimum and the global maximum.\ncenter: use uniminmax to standardize vertical height, then center each variable at a value specified by the scaleSummary param.\ncenterObs: use uniminmax to standardize vertical height, then center each variable at the value of the observation specified by the centerObsID param\n\nThere is no one best scaling method to use. You should explore them and select the one that best meet your analysis need.\nLast but not least, we can also compute the summary statistics such as mean, median, sd, etc to complement the visual interpretation.\nIn the code chunk below, group_by() and summarise() of dplyr are used to derive mean values of the clustering variables.\n\nshan_sf_ngeo_cluster %&gt;% \n  st_set_geometry(NULL) %&gt;%\n  group_by(CLUSTER) %&gt;%\n  summarise(mean_RADIO_PR = mean(RADIO_PR),\n            mean_TV_PR = mean(TV_PR),\n            mean_LLPHONE_PR = mean(LLPHONE_PR),\n            mean_MPHONE_PR = mean(MPHONE_PR),\n            mean_COMPUTER_PR = mean(COMPUTER_PR))\n\n# A tibble: 6 × 6\n  CLUSTER mean_RADIO_PR mean_TV_PR mean_LLPHONE_PR mean_MPHONE_PR\n  &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;           &lt;dbl&gt;          &lt;dbl&gt;\n1 1               221.        521.            44.2           246.\n2 2               237.        402.            23.9           134.\n3 3               300.        611.            52.2           392.\n4 4               196.        744.            99.0           651.\n5 5               124.        224.            38.0           132.\n6 6                98.6       499.            74.5           468.\n# ℹ 1 more variable: mean_COMPUTER_PR &lt;dbl&gt;"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html",
    "href": "Hands-on_Ex/Hands-on_ex06.html",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise will teach you how to compute both Global and Local Measures of Spatial Autocorrelation (GMSA & LMSA) using the spdep package in R. By the end of the exercise, you will be able to:\nPart 1: Global Measures of Spatial Autocorrelation (GMSA) Global Measures of Spatial Autocorrelation (GMSA) provide a single summary statistic describing the overall spatial structure in a dataset. Moran’s I is a commonly used statistic for GMSA. This part will guide you through computing and visualizing GMSA statistics.\nPart 2: Local Measures of Spatial Autocorrelation (LMSA) Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surrounding areas. Unlike GMSA, LMSA provides detailed insights into local clusters and outliers. The most common LMSA statistic is Local Indicators of Spatial Association (LISA), along with Getis-Ord’s Gi-statistics for hot and cold spot analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_ex06.html#exercise-overview",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "",
    "text": "In this hands-on exercise will teach you how to compute both Global and Local Measures of Spatial Autocorrelation (GMSA & LMSA) using the spdep package in R. By the end of the exercise, you will be able to:\nPart 1: Global Measures of Spatial Autocorrelation (GMSA) Global Measures of Spatial Autocorrelation (GMSA) provide a single summary statistic describing the overall spatial structure in a dataset. Moran’s I is a commonly used statistic for GMSA. This part will guide you through computing and visualizing GMSA statistics.\nPart 2: Local Measures of Spatial Autocorrelation (LMSA) Local Measures of Spatial Autocorrelation (LMSA) focus on the relationships between each observation and its surrounding areas. Unlike GMSA, LMSA provides detailed insights into local clusters and outliers. The most common LMSA statistic is Local Indicators of Spatial Association (LISA), along with Getis-Ord’s Gi-statistics for hot and cold spot analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_ex06.html#data-acquisition",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.2 Data Acquisition",
    "text": "6.2 Data Acquisition\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_ex06.html#getting-started",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.3 Getting Started",
    "text": "6.3 Getting Started\nFor this exercise, we will use the following 5 R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspdep, an R package focused on spatial dependence and spatial econometrics. It includes functions for computing spatial weights, neighborhood structures, and spatially lagged variables, which are crucial for understanding spatial relationships in data.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\ntidyverse, a collection of R packages designed for data science. It includes packages like dplyr for data manipulation, ggplot2 for data visualization, and tidyr for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_ex06.html#importing-data-into-r",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.4 Importing Data into R",
    "text": "6.4 Importing Data into R\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n6.4.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/Hands-on_Ex05/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\Hands-on_Ex05\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n6.4.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/Hands-on_Ex05/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n6.4.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_ex06.html#visualising-regional-development-indicator",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.5 Visualising Regional Development Indicator",
    "text": "6.5 Visualising Regional Development Indicator\n\nequal &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"equal\",\n          palette = \"viridis\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal interval classification\")\n\nquantile &lt;- tm_shape(hunan) +\n  tm_fill(\"GDPPC\",\n          n = 5,\n          style = \"quantile\",\n          palette = \"viridis\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Equal quantile classification\")\n\ntmap_arrange(equal, \n             quantile, \n             asp=1, \n             ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation",
    "href": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.6 Global Measures of Spatial Autocorrelation",
    "text": "6.6 Global Measures of Spatial Autocorrelation\nIn this section, you will learn how to compute global spatial autocorrelation statistics and to perform spatial complete randomness test for global spatial autocorrelation.\n\n6.6.1 Computing Contiguity Spatial Weights\nBefore we can compute the global spatial autocorrelation statistics, we need to construct a spatial weights of the study area. The spatial weights is used to define the neighbourhood relationships between the geographical units (i.e. county) in the study area.\nIn the code chunk below, poly2nb() of spdep package is used to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\nMore specifically, the code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\n\n\n6.6.2 Row-standardised weights matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=“W” option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\n\n\n\n\n\nWhat can we learn from the code chunk above?\n\n\n\n\nThe input of nb2listw() must be an object of class nb. The syntax of the function has two major arguments, namely style and zero.poly.\nstyle can take values “W”, “B”, “C”, “U”, “minmax” and “S”. B is the basic binary coding, W is row standardised (sums over all links to n), C is globally standardised (sums over all links to n), U is equal to C divided by the number of neighbours (sums over all links to unity), while S is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. 1999, p. 167-168 (sums over all links to n).\nIf zero policy is set to TRUE, weights vectors of zero length are inserted for regions without neighbour in the neighbours list. These will in turn generate lag values of zero, equivalent to the sum of products of the zero row t(rep(0, length=length(neighbours))) %*% x, for arbitrary numerical vector x of length length(neighbours). The spatially lagged value of x for the zero-neighbour region will then be zero, which may (or may not) be a sensible choice."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "href": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation-morans-i",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.7 Global Measures of Spatial Autocorrelation: Moran’s I",
    "text": "6.7 Global Measures of Spatial Autocorrelation: Moran’s I\nIn this section, you will learn how to perform Moran’s I statistics testing by using moran.test() of spdep.\n\n6.7.1 Maron’s I test\nThe code chunk below performs Moran’s I statistical testing using moran.test() of spdep.\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\n\n\n\n\n\nConclusion\n\n\n\nKey Results: 1. Moran’s I statistic = 0.30075 2. Expectation = -0.01149 3. Variance = 0.00435 4. Moran I statistic standard deviate = 4.7351 5. p-value = 1.095e-06\nThe Moran’s I statistic = 0.30075 is positive, indicating positive spatial autocorrelation, meaning that regions with similar GDP per capita values are clustered together.\nThe p-value = 1.095e-06 is extremely small, meaning there is very strong evidence against the null hypothesis of no spatial autocorrelation. We can reject the null hypothesis and conclude that GDP per capita is spatially clustered across the regions in the Hunan dataset.\nIn summary, the Moran’s I test confirms the presence of statistically significant spatial clustering in GDP per capita in Hunan. Regions with high or low GDPPC tend to be near one another, rather than being randomly distributed.\n\n\n\n\n6.7.2 Computing Monte Carlo Moran’s I\nThe code chunk below performs permutation test for Moran’s I statistic by using moran.mc() of spdep. A total of 1000 simulation will be performed.\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nConclusion\n\n\n\nKey Results:\n\nStatistic (Moran’s I) = 0.30075\nObserved rank = 1000\np-value = 0.001\n\nThe Moran’s I value of 0.30075 is positive, indicating positive spatial autocorrelation, meaning regions with similar levels of GDPPC tend to be near each other.\nThe p-value = 0.001 is highly significant, meaning there is less than a 0.1% chance that this level of spatial autocorrelation is due to random chance. Therefore, we reject the null hypothesis of no spatial autocorrelation and conclude that GDPPC is spatially clustered in the Hunan region.\nIn summary, there is statistically significant evidence of spatial clustering in GDP per capita across the regions in the Hunan dataset.\n\n\n\n\n6.7.3 Visualising Monte Carlo Moran’s I\nIt is always a good practice for us the examine the simulated Moran’s I test statistics in greater detail. This can be achieved by plotting the distribution of the statistical values as a histogram by using the code chunk below.\nIn the code chunk below hist() and abline() of R Graphics are used.\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFrom the results provided, here’s what can be observed:\n\nMean of simulated Moran’s I: The mean of the simulated Moran’s I values (excluding the observed value) is -0.01505, which is close to 0. This suggests that under the null hypothesis (random distribution), Moran’s I is expected to be around 0, indicating no spatial autocorrelation.\nVariance: The variance of the simulated Moran’s I values is 0.00437, which shows how much the simulated Moran’s I values spread around the mean.\nSummary Statistics:\n\nMinimum Moran’s I = -0.18339.\n1st Quartile (25%) = -0.06168.\nMedian (50%) = -0.02125.\n3rd Quartile (75%) = 0.02611.\nMaximum Moran’s I = 0.27593.\n\n\nTogether with the histogram of the simulated Moran’s I values, this shows that most values are centered around 0, with a bell-shaped distribution, indicating that under random conditions, spatial autocorrelation is minimal or absent. However, the observed Moran’s I (red line in the histogram) is much larger than the bulk of the simulated values, which indicates significant positive spatial autocorrelation in the real data.\n\n\nUsing ggplot2 package to plot the values:\n\n# Create a data frame for ggplot\nsimulated_data &lt;- data.frame(simulated_morans_I = bperm$res)\n\n# Plot using ggplot2\nggplot(simulated_data, aes(x = simulated_morans_I)) +\n  geom_histogram(bins = 20, fill = \"grey\", color = \"black\") +  # Histogram with 20 bins\n  geom_vline(xintercept = 0, color = \"red\", linetype = \"solid\") +  # Red line at 0\n  labs(title = \"Histogram of Simulated Moran's I\",\n       x = \"Simulated Moran's I\",\n       y = \"Frequency\") +\n  theme_minimal()  # Use a minimal theme for clean visuals"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "href": "Hands-on_Ex/Hands-on_ex06.html#global-measures-of-spatial-autocorrelation-gearys-c",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.8 Global Measures of Spatial Autocorrelation: Geary’s C",
    "text": "6.8 Global Measures of Spatial Autocorrelation: Geary’s C\nIn this section, you will learn how to perform Geary’s C statistics testing by using appropriate functions of spdep package.\n\n6.8.1 Geary’s C test\nThe code chunk below performs Geary’s C test for spatial autocorrelation by using geary.test() of spdep.\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\n\n\n\n\n\nObservation\n\n\n\nKey Results:\n\nGeary’s C statistic = 0.6907\nExpectation = 1.0000\nVariance = 0.0073364\nGeary C statistic standard deviate = 3.6108\np-value = 0.0001526\n\nThe observed Geary’s C statistic of 0.6907 is significantly lower than the expected value of 1, indicating positive spatial autocorrelation. The p-value of 0.0001526 is very small, providing strong evidence to reject the null hypothesis of no spatial autocorrelation.\nIn conclusion, the Geary’s C test confirms that there is significant positive spatial autocorrelation in the GDP per capita values across the regions in Hunan. Similar GDPPC values tend to be clustered together spatially.\n\n\n\n\n6.8.2 Computing Monte Carlo Geary’s C\nThe code chunk below performs permutation test for Geary’s C statistic by using geary.mc() of spdep.\n\nset.seed(1234)\nbperm=geary.mc(hunan$GDPPC, \n               listw=rswm_q, \n               nsim=999)\nbperm\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.69072, observed rank = 1, p-value = 0.001\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nStatistic: The observed Geary’s C statistic is approximately 0.69072. Geary’s C is a measure of spatial autocorrelation, where values less than 1 indicate positive spatial autocorrelation (similar values clustered together).\nObserved Rank: The observed rank is 1, which means that the observed statistic is the smallest among the 999 simulated values.\nP-value: The p-value is 0.001, which is very low (typically, a threshold of 0.05 is used for significance). This suggests that the observed statistic is significantly lower than what would be expected under the null hypothesis of no spatial autocorrelation.\n\nGiven the low p-value, you can conclude that there is strong evidence against the null hypothesis, suggesting that there is significant positive spatial autocorrelation in the GDP per capita (GDPPC) data for Hunan. This implies that regions with similar GDPPC values tend to cluster together spatially.\n\n\n\n\n6.8.3 Visualising the Monte Carlo Geary’s C\nNext, we will plot a histogram to reveal the distribution of the simulated values by using the code chunk below.\n\nmean(bperm$res[1:999])\n\n[1] 1.004402\n\nvar(bperm$res[1:999])\n\n[1] 0.007436493\n\nsummary(bperm$res[1:999])\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.7142  0.9502  1.0052  1.0044  1.0595  1.2722 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nKey Results:\n\nMinimum: 0.7142\n1st Quartile (Q1): 0.9502\nMedian: 1.0052\nMean: 1.0044\n3rd Quartile (Q3): 1.0595\nMaximum: 1.2722\n\nThe median value being very close to the mean suggests a symmetric distribution of the simulated Geary’s C values, which is further confirmed by the range of values (from 0.7142 to 1.2722).\nHistogram: The histogram with the red vertical line at 1 visually illustrates the distribution of the simulated values. Most of the values appear to be above 1, reinforcing the observation of a tendency for dissimilar values to be spatially distributed.\nOverall, these statistics suggest that while the observed Geary’s C statistic (0.69072) indicates significant positive spatial autocorrelation, the simulated values are generally above 1, which points to dissimilar values being more likely to be near each other in space. This contrast emphasizes the clustering of similar GDPPC values in Hunan and indicates that the observed statistic is an extreme outcome under the null hypothesis of no spatial autocorrelation."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#spatial-correlogram",
    "href": "Hands-on_Ex/Hands-on_ex06.html#spatial-correlogram",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.9 Spatial Correlogram",
    "text": "6.9 Spatial Correlogram\nSpatial correlograms are great to examine patterns of spatial autocorrelation in your data or model residuals. They show how correlated are pairs of spatial observations when you increase the distance (lag) between them - they are plots of some index of autocorrelation (Moran’s I or Geary’s c) against distance.Although correlograms are not as fundamental as variograms (a keystone concept of geostatistics), they are very useful as an exploratory and descriptive tool. For this purpose they actually provide richer information than variograms.\n\n6.9.1 Compute Moran’s I correlogram\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Moran’s I. The plot() of base Graph is then used to plot the output.\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\n\n\n\nBy plotting the output might not allow us to provide complete interpretation. This is because not all autocorrelation values are statistically significant. Hence, it is important for us to examine the full analysis report by printing out the analysis results as in the code chunk below.\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThere is strong positive spatial autocorrelation for lower lags (1, 2, and 3), suggesting that regions with similar GDPPC are spatially clustered. As the lag increases, this autocorrelation weakens and eventually becomes negative, indicating that regions with dissimilar GDPPC are more likely to be neighbors at larger spatial lags (5 and 6).\n\n\n\n\n6.9.1 Compute Geary’s C correlogram and plot\nIn the code chunk below, sp.correlogram() of spdep package is used to compute a 6-lag spatial correlogram of GDPPC. The global spatial autocorrelation used in Geary’s C. The plot() of base Graph is then used to plot the output.\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\n\n\n\n\n\nSimilar to the previous step, we will print out the analysis report by using the code chunk below.\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#local-indicators-of-spatial-associationlisa",
    "href": "Hands-on_Ex/Hands-on_ex06.html#local-indicators-of-spatial-associationlisa",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.10 Local Indicators of Spatial Association(LISA)",
    "text": "6.10 Local Indicators of Spatial Association(LISA)\nLocal Indicators of Spatial Association or LISA are statistics that evaluate the existence of clusters and/or outliers in the spatial arrangement of a given variable. For instance if we are studying distribution of GDP per capita of Hunan Provice, People Republic of China, local clusters in GDP per capita mean that there are counties that have higher or lower rates than is to be expected by chance alone; that is, the values occurring are above or below those of a random distribution in space.\nIn this section, you will learn how to apply appropriate Local Indicators for Spatial Association (LISA), especially local Moran’I to detect cluster and/or outlier from GDP per capita 2012 of Hunan Province, PRC.\n\n6.10.1 Computing local Moran’s I\nTo compute local Moran’s I, the localmoran() function of spdep will be used. It computes Ii values, given a set of zi values and a listw object providing neighbour weighting information for the polygon associated with the zi values.\nThe code chunks below are used to compute local Moran’s I of GDPPC2012 at the county level.\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\n6.10.1.1 Mapping the local Moran’s I\nBefore mapping the local Moran’s I map, it is wise to append the local Moran’s I dataframe (i.e. localMI) onto hunan SpatialPolygonDataFrame. The code chunks below can be used to perform the task. The out SpatialPolygonDataFrame is called hunan.localMI.\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\n\n6.10.1.2 Mapping local Moran’s I values\nUsing choropleth mapping functions of tmap package, we can plot the local Moran’s I values by using the code chinks below.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.10.1.3 Mapping local Moran’s I p-values\nThe choropleth shows there is evidence for both positive and negative Ii values. However, it is useful to consider the p-values for each of these values, as consider above.\nThe code chunks below produce a choropleth map of Moran’s I p-values by using functions of tmap package.\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.10.4 Mapping both local Moran’s I values and p-values\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#creating-a-lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_ex06.html#creating-a-lisa-cluster-map",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.11 Creating a LISA Cluster Map",
    "text": "6.11 Creating a LISA Cluster Map\nThe LISA Cluster Map shows the significant locations color coded by type of spatial autocorrelation. The first step before we can generate the LISA cluster map is to plot the Moran scatterplot.\n\n6.11.1 Plotting Moran scatterplot\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nThe code chunk below plots the Moran scatterplot of GDPPC 2012 by using moran.plot() of spdep.\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\n\n\n\n\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\n\n6.11.2 Plotting Moran scatterplot with standardised variable\nFirst we will use scale() to centers and scales the variable. Here centering is done by subtracting the mean (omitting NAs) the corresponding columns, and scaling is done by dividing the (centered) variable by their standard deviations.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \n\nThe as.vector() added to the end is to make sure that the data type we get out of this is a vector, that map neatly into out dataframe.\nNow, we are ready to plot the Moran scatterplot again by using the code chunk below.\n\nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")\n\n\n\n\n\n\n\n\n\n\n6.11.3 Preparing LISA map classes\nThe code chunks below show the steps to prepare a LISA cluster map.\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\n\nNext, derives the spatially lagged variable of interest (i.e. GDPPC) and centers the spatially lagged variable around its mean.\n\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \n\nThis is follow by centering the local Moran’s around the mean.\n\nLM_I &lt;- localMI[,1] - mean(localMI[,1])    \n\nNext, we will set a statistical significance level for the local Moran.\n\nsignif &lt;- 0.05       \n\nThese four command lines define the low-low (1), low-high (2), high-low (3) and high-high (4) categories.\n\nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4      \n\nLastly, places non-significant Moran in the category 0.\n\nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nIn fact, we can combined all the steps into one single code chunk as shown below:\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\n\n\n6.11.4 Plotting LISA map\nNow, we can build the LISA map by using the code chunks below.\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\n\n\n\n\nFor effective interpretation, it is better to plot both the local Moran’s I values map and its corresponding p-values map next to each other.\nThe code chunk below will be used to create such visualisation.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)\n\n\n\n\n\n\n\n\nWe can also include the local Moran’s I map and p-value map as shown below for easy comparison.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThe Local Indicators of Spatial Association (LISA) map consists of two panels, each providing different information about local spatial autocorrelation for GDPPC in the Hunan region:\n\nLeft Panel: Local Moran’s I Statistics\n\nSpatial Clustering:\n\nThe regions are colored based on the value of Local Moran’s I statistics. Areas with positive values indicate clustering of similar values (high-high or low-low), while negative values indicate spatial outliers (high-low or low-high).\nDarker green areas show strong positive autocorrelation (high-high clustering), indicating that regions with high GDPPC are surrounded by other regions with high GDPPC.\nThe small orange region in the middle represents negative autocorrelation, indicating it is a spatial outlier with a lower GDPPC than its neighbors.\n\nSpatial Outliers and Clusters:\n\nMost of the regions are in the range of -1 to 1 (light yellow) indicating weak or no significant local spatial autocorrelation.\nDarker green regions are where significant positive clustering is observed, suggesting economic similarity in terms of GDPPC within these clusters.\n\n\n\n\nRight Panel: Local Moran’s I p-values\n\nSignificance of Spatial Autocorrelation:\n\nThis panel displays the significance of the local Moran’s I statistics. Darker blue colors represent regions with significant local spatial autocorrelation (lower p-values).\nThe areas with the darkest blue (p &lt; 0.001) correspond to significant clusters of either high or low GDPPC. These regions are the same as those showing strong positive autocorrelation in the left panel (dark green areas).\n\nIdentification of Significant Clusters:\n\nThe map helps in identifying the most statistically significant clusters. The significant regions mostly match the dark green regions in the left panel, confirming that these clusters are not due to random spatial patterns but are statistically significant.\nAreas with lighter shades of blue (higher p-values) indicate non-significant local Moran’s I values, implying no strong evidence for spatial autocorrelation in those regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Hands-on_Ex/Hands-on_ex06.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.12 Hot Spot and Cold Spot Area Analysis",
    "text": "6.12 Hot Spot and Cold Spot Area Analysis\nBeside detecting cluster and outliers, localised spatial statistics can be also used to detect hot spot and/or cold spot areas.\nThe term ‘hot spot’ has been used generically across disciplines to describe a region or value that is higher relative to its surroundings (Lepers et al 2005, Aben et al 2012, Isobe et al 2015).\n\n6.12.1 Getis and Ord’s G-Statistics\nAn alternative spatial statistics to detect spatial anomalies is the Getis and Ord’s G-statistics (Getis and Ord, 1972; Ord and Getis, 1995). It looks at neighbours within a defined proximity to identify where either high or low values clutser spatially. Here, statistically significant hot-spots are recognised as areas of high values where other areas within a neighbourhood range also share high values too.\nThe analysis consists of three steps:\n\nDeriving spatial weight matrix\nComputing Gi statistics\nMapping Gi statistics\n\n\n\n6.12.2 Deriving distance-based weight matrix\nFirst, we need to define a new set of neighbours. Whist the spatial autocorrelation considered units which shared borders, for Getis-Ord we are defining neighbours based on distance.\nThere are two type of distance-based proximity matrix, they are:\n\nfixed distance weight matrix; and\nadaptive distance weight matrix.\n\n\n6.12.2.1 Deriving the centroid\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid() on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid(). We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid() function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\n\n\n6.12.2.2 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n6.12.2.3 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\nThe output spatial weights object is called wm62_lw.\n\n\n\n6.12.3 Computing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothe the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\n\nNext, nb2listw() is used to convert the nb object into spatial weights object.\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex06.html#computing-gi-statistics",
    "href": "Hands-on_Ex/Hands-on_ex06.html#computing-gi-statistics",
    "title": "Global and Local Measures of Spatial Autocorrelation",
    "section": "6.13 Computing Gi statistics",
    "text": "6.13 Computing Gi statistics\n\n6.13.1 Gi statistics using fixed distance\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\nThe output of localG() is a vector of G or Gstar values, with attributes “gstari” set to TRUE or FALSE, “call” set to the function call, and class “localG”.\nThe Gi statistics is represented as a Z-score. Greater values represent a greater intensity of clustering and the direction (positive or negative) indicates high or low clusters.\nNext, we will join the Gi values to their corresponding hunan sf data frame by using the code chunk below.\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\nIn fact, the code chunk above performs three tasks. First, it convert the output vector (i.e. gi.fixed) into r matrix object by using as.matrix(). Next, cbind() is used to join hunan@data and gi.fixed matrix to produce a new SpatialPolygonDataFrame called hunan.gi. Lastly, the field name of the gi values is renamed to gstat_fixed by using rename().\n\n\n6.13.2 Mapping Gi values with fixed distance weights\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nThe two maps in the LISA analysis show the distribution of GDPPC and the local Gi statistics for spatial clustering:\n\nLeft Panel: GDPPC Distribution\n\nGDPPC Range:\n\nThe regions are colored based on their GDPPC values, with darker colors representing higher GDPPC.\nThe central-northern region has the highest GDPPC values (dark orange), while most other regions are in the lower to middle range of GDPPC (lighter colors).\n\nGDPPC Clusters:\n\nThis map helps visualize which regions are wealthier relative to others, but it doesn’t provide information on the spatial clustering of these values.\n\n\n\n\nRight Panel: Local Gi Statistics (Hot Spot Analysis)\n\nHot and Cold Spots:\n\nThe Gi statistic is used to identify “hot spots” (areas with high values surrounded by other high values) and “cold spots” (areas with low values surrounded by other low values).\nThe regions in dark red and dark orange in the central-northern part represent statistically significant hot spots, indicating that these regions have high GDPPC values that are spatially clustered.\nSimilarly, areas in blue represent cold spots, indicating regions with low GDPPC values surrounded by other low-value regions.\n\nSignificance of Clusters:\n\nThe darker the red or blue, the stronger the significance of the clustering (high Gi values for hot spots and low Gi values for cold spots).\nThe central region shows the strongest hot spot with a local Gi value in the range of 5 to 6, signifying a very strong clustering of high GDPPC.\n\nSpatial Patterns:\n\nHot spots are concentrated mainly in the central-northern part, which matches the high GDPPC regions in the left panel.\nCold spots are scattered throughout, with notable clustering in the northwestern and southeastern parts of the map.\n\n\n\n\n\n\n\n6.13.3 Gi statistics using adaptive distance\nThe code chunk below are used to compute the Gi values for GDPPC2012 by using an adaptive distance weight matrix (i.e knb_lw).\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\n\n6.13.4 Mapping Gi values with adaptive distance weights\nIt is time for us to visualise the locations of hot spot and cold spot areas. The choropleth mapping functions of tmap package will be used to map the Gi values.\nThe code chunk below shows the functions used to map the Gi values derived using fixed distance weight matrix.\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nFrom the Gi map (right side) in your visualization, the local Gi statistic is mapped to show spatial clusters of high or low values in comparison to surrounding areas. The Gi statistic helps identify statistically significant clusters, and it is commonly used to detect local spatial autocorrelation.\n\nObservations:\n\nHotspots (Red areas): The red regions in the Gi map indicate statistically significant positive spatial autocorrelation or “hotspots,” where high GDP per capita (GDPPC) values cluster together. This suggests that the areas in red (north-eastern region) have higher GDPPC and are surrounded by other high-GDPPC areas.\nColdspots (Blue areas): The blue regions represent negative spatial autocorrelation or “coldspots,” where low GDPPC values cluster together. These areas are likely experiencing lower economic activity relative to their neighbors. The most noticeable coldspot is in the southwest.\nNeutral areas: The lighter shades of blue and red indicate regions with no significant spatial autocorrelation, meaning that the GDPPC in these areas does not display a strong clustering pattern relative to nearby areas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03.html",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, I learn how to to analyze spatial point patterns in R. On top of that I learn to apply first- and second-order analyses to assess the randomness of point distributions, and how to visualize and interpret the spatial concentration of facilities using Kernel Density Estimation (KDE)\nSpatial Point Pattern Analysis involves evaluating the distribution of a set of points on a surface. These points can represent the locations of various events or facilities, such as:\n\nEvents: Crime occurrences, traffic accidents, or disease outbreaks.\nFacilities: Business services like coffee shops, fast food outlets, or essential facilities such as childcare and eldercare centers.\n\nIn this hands-on exercise, we aim to explore the spatial distribution of childcare centers in Singapore using functions from the spatstat package. Specifically, we will address the following questions:\n\nRandomness of Distribution: Are childcare centers in Singapore randomly distributed across the country?\nClusters and Concentrations: If the distribution is not random, where are the areas with higher concentrations of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#exercise-overview",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "",
    "text": "In this hands-on exercise, I learn how to to analyze spatial point patterns in R. On top of that I learn to apply first- and second-order analyses to assess the randomness of point distributions, and how to visualize and interpret the spatial concentration of facilities using Kernel Density Estimation (KDE)\nSpatial Point Pattern Analysis involves evaluating the distribution of a set of points on a surface. These points can represent the locations of various events or facilities, such as:\n\nEvents: Crime occurrences, traffic accidents, or disease outbreaks.\nFacilities: Business services like coffee shops, fast food outlets, or essential facilities such as childcare and eldercare centers.\n\nIn this hands-on exercise, we aim to explore the spatial distribution of childcare centers in Singapore using functions from the spatstat package. Specifically, we will address the following questions:\n\nRandomness of Distribution: Are childcare centers in Singapore randomly distributed across the country?\nClusters and Concentrations: If the distribution is not random, where are the areas with higher concentrations of childcare centers?"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#data-acquisition",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.2 Data Acquisition",
    "text": "3.2 Data Acquisition\nThree data set will be used to answer these question. They are:\n\nCHILDCARE: A point feature dataset containing the location and attribute information of childcare centers in Singapore. This dataset was downloaded from Data.gov.sg and is in GeoJSON format.\nMP14_SUBZONE_WEB_PL: A polygon feature dataset providing information on URA’s 2014 Master Plan Planning Subzone boundaries. This data is in ESRI Shapefile format and was also downloaded from Data.gov.sg.\nCostalOutline: A polygon feature dataset showing the national boundary of Singapore. This dataset is provided by the Singapore Land Authority (SLA) and is in ESRI Shapefile format."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#getting-started",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.3 Getting Started",
    "text": "3.3 Getting Started\nFor this exercise, we will use the following 5 R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nraster, a package for reading, writing, manipulating, and modeling gridded spatial data (rasters). We will use it to convert image outputs generated by spatstat into raster format.\nmaptools, a set of tools for manipulating geographic data, mainly used here to convert spatial objects into the ppp format required by spatstat.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#importing-data-into-r",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.4 Importing Data into R",
    "text": "3.4 Importing Data into R\n\n3.4.1 Importing the spatial data\nIn this section, we’ll use the st_read() function from the sf package to import three geospatial datasets into R:\n\nchildcare_sf &lt;- st_read(\"data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\n\nsg_sf &lt;- st_read(dsn = \"data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\n\n\nmpsz_sf &lt;- st_read(dsn = \"data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe following code chunk changes the referencing system of the newly created simple feature data frames to Singapore national projected coordinate system.\n\nchildcare_sf &lt;- st_transform(childcare_sf, crs = 3414)\nmpsz_sf &lt;- st_transform(mpsz_sf, crs = 3414)\n\n\n\n3.4.2 Mapping the geospatial data sets\nAfter verifying that all datasets share the same CRS, it’s useful to visualize them to confirm their spatial alignment.\n\ntmap_mode(\"plot\")\ntm_shape(mpsz_sf) +\n  tm_polygons() + \n  tm_shape(childcare_sf) + \n  tm_dots() \n\nIn this code chunk:\n\ntm_shape(mpsz_sf): Sets the base layer to the Singapore subzones.\ntm_polygons(): Plots the subzones with a light blue fill and a dark blue border.\ntm_shape(childcare_sf): Adds an overlay layer for the childcare centers.\ntm_dots(): Plots the childcare centers as red dots with a black border.\n\n\ntmap_mode('view')\n\ntm_shape(childcare_sf) +\n  tm_dots()\n\ntmap_mode('plot')\n\nBy ensuring that all geospatial layers align correctly within the same map extent, we confirm that their CRS and coordinate values are consistent—a critical aspect of any geospatial analysis.\n\ntmap_mode('plot')\n\nNotice that at the interactive mode, tmap is using leaflet for R API. The advantage of this interactive pin map is it allows us to navigate and zoom around the map freely. We can also query the information of each simple feature (i.e. the point) by clicking of them. Last but not least, you can also change the background of the internet map layer. Currently, three internet map layers are provided. They are: ESRI.WorldGrayCanvas, OpenStreetMap, and ESRI.WorldTopoMap. The default is ESRI.WorldGrayCanvas."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#geospatial-data-wrangling",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.5 Geospatial Data wrangling",
    "text": "3.5 Geospatial Data wrangling\nAlthough simple feature data frame is gaining popularity again sp’s Spatial* classes, there are, however, many geospatial analysis packages require the input geospatial data in sp’s Spatial* classes. In this section, you will learn how to convert simple feature data frame to sp’s Spatial* class.\n\n3.5.1 Converting sf data frames to sp’s Spatial* class\nTo work with certain geospatial analysis packages that require data in sp’s Spatial* class, you can convert simple feature (sf) data frames to these classes using the as_Spatial() function from the sf package. Below is the code to convert the sf objects to sp’s Spatial* classes:\n\nchildcare &lt;- as_Spatial(childcare_sf)\nmpsz &lt;- as_Spatial(mpsz_sf)\nsg &lt;- as_Spatial(sg_sf)\n\nAfter conversion, you can display the information of these three Spatial* classes as follows:\n\nchildcare\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 2\nnames       :    Name,                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Description \nmin values  :   kml_1, &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;1, MARINA BOULEVARD, #B1 - 01, ONE MARINA BOULEVARD, SINGAPORE 018989&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;THE LITTLE SKOOL-HOUSE INTERNATIONAL PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;08F73931F4A691F4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \nmax values  : kml_999,                  &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSBLOCKHOUSENUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSBUILDINGNAME&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSPOSTALCODE&lt;/th&gt; &lt;td&gt;829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSSTREETNAME&lt;/th&gt; &lt;td&gt;200, PONGGOL SEVENTEENTH AVENUE, SINGAPORE 829646&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSTYPE&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;DESCRIPTION&lt;/th&gt; &lt;td&gt;Child Care Services&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;HYPERLINK&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;LANDXADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;LANDYADDRESSPOINT&lt;/th&gt; &lt;td&gt;0&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;NAME&lt;/th&gt; &lt;td&gt;RAFFLES KIDZ @ PUNGGOL PTE LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;PHOTOURL&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;ADDRESSFLOORNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;379D017BF244B0FA&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20200826094036&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;ADDRESSUNITNUMBER&lt;/th&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt; \n\n\n\nmpsz\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 323 \nextent      : 2667.538, 56396.44, 15748.72, 50256.33  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 15\nnames       : OBJECTID, SUBZONE_NO, SUBZONE_N, SUBZONE_C, CA_IND, PLN_AREA_N, PLN_AREA_C,       REGION_N, REGION_C,          INC_CRC, FMEL_UPD_D,     X_ADDR,     Y_ADDR,    SHAPE_Leng,    SHAPE_Area \nmin values  :        1,          1, ADMIRALTY,    AMSZ01,      N, ANG MO KIO,         AM, CENTRAL REGION,       CR, 00F5E30B5C9B7AD8,      16409,  5092.8949,  19579.069, 871.554887798, 39437.9352703 \nmax values  :      323,         17,    YUNNAN,    YSSZ09,      Y,     YISHUN,         YS,    WEST REGION,       WR, FFCCF172717C2EAF,      16409, 50424.7923, 49552.7904, 68083.9364708,  69748298.792 \n\n\n\nsg\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \nvariables   : 4\nnames       : GDO_GID, MSLINK, MAPID,              COSTAL_NAM \nmin values  :       1,      1,     0,             ISLAND LINK \nmax values  :      60,     67,     0, SINGAPORE - MAIN ISLAND \n\n\n\n\n3.5.2 Converting the Spatial* class into generic sp format\nTo prepare data for use in the spatstat package, you first need to convert the Spatial* classes into a generic sp format:\n\nchildcare_sp &lt;- as(childcare, \"SpatialPoints\")\nsg_sp &lt;- as(sg, \"SpatialPolygons\")\n\nThen, you can display the properties of these sp objects:\n\nchildcare_sp\n\nclass       : SpatialPoints \nfeatures    : 1545 \nextent      : 11203.01, 45404.24, 25667.6, 49300.88  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \n\n\n\nsg_sp\n\nclass       : SpatialPolygons \nfeatures    : 60 \nextent      : 2663.926, 56047.79, 16357.98, 50244.03  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +datum=WGS84 +units=m +no_defs \n\n\n\n\n3.5.3 Converting the generic sp format into spatstat’s ppp format\nTo analyze spatial point patterns, you need to convert the sp objects into ppp objects, which are used by the spatstat package:\n\nchildcare_ppp &lt;- as.ppp(st_coordinates(childcare_sf), st_bbox(childcare_sf))\nchildcare_ppp\n\nMarked planar point pattern: 1545 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n\n\nNow, let us plot childcare_ppp and examine the different.\n\nplot(childcare_ppp)\n\n\n\n\n\n\n\n\nYou can take a quick look at the summary statistics of the newly created ppp object by using the code chunk below.\n\nsummary(childcare_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 1.91145e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: rectangle = [11203.01, 45404.24] x [25667.6, 49300.88] units\n                    (34200 x 23630 units)\nWindow area = 808287000 square units\n\n\nNotice the warning message about duplicates. In spatial point patterns analysis an issue of significant is the presence of duplicates. The statistical methodology used for spatial point patterns processes is based largely on the assumption that process are simple, that is, that the points cannot be coincident.\n\n\n3.5.4 Handling duplicated points\nTo determine the existence of duplicate points, we can check for duplicates in your Point Pattern (PPP) object object by using the code chunk below.\n\nany(duplicated(childcare_ppp))\n\n[1] TRUE\n\n\nTo count the number of points at each location, we can use the multiplicity() function as shown in the code chunk below.\n\nmultiplicity(childcare_ppp)\n\n   1    2    3    4    5    6    7    8    9   10   11   12   13   14   15   16 \n   1    1    1    3    1    1    1    1    2    1    1    1    1    1    1    1 \n  17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32 \n   1    1    1    1    1    1    1    1    1    1    9    1    1    1    1    1 \n  33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n  49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64 \n   1    1    1    1    1    1    2    1    1    3    1    1    1    1    1    1 \n  65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80 \n   1    1    1    1    1    2    1    1    1    1    1    2    1    1    1    1 \n  81   82   83   84   85   86   87   88   89   90   91   92   93   94   95   96 \n   1    1    1    3    1    1    1    1    1    1    1    1    1    1    1    1 \n  97   98   99  100  101  102  103  104  105  106  107  108  109  110  111  112 \n   1    1    1    1    1    1    1    1    2    1    1    1    1    1    1    1 \n 113  114  115  116  117  118  119  120  121  122  123  124  125  126  127  128 \n   1    1    1    1    1    1    2    1    1    1    3    1    1    1    2    1 \n 129  130  131  132  133  134  135  136  137  138  139  140  141  142  143  144 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    3    2 \n 145  146  147  148  149  150  151  152  153  154  155  156  157  158  159  160 \n   1    2    1    1    1    2    2    3    1    5    1    5    1    1    1    2 \n 161  162  163  164  165  166  167  168  169  170  171  172  173  174  175  176 \n   1    1    1    1    2    1    1    1    1    1    1    2    1    1    1    1 \n 177  178  179  180  181  182  183  184  185  186  187  188  189  190  191  192 \n   1    4    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 193  194  195  196  197  198  199  200  201  202  203  204  205  206  207  208 \n   1    1    1    1    1    2    2    1    1    1    1    2    1    4    1    1 \n 209  210  211  212  213  214  215  216  217  218  219  220  221  222  223  224 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    1    1    1 \n 225  226  227  228  229  230  231  232  233  234  235  236  237  238  239  240 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 241  242  243  244  245  246  247  248  249  250  251  252  253  254  255  256 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 257  258  259  260  261  262  263  264  265  266  267  268  269  270  271  272 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    3 \n 273  274  275  276  277  278  279  280  281  282  283  284  285  286  287  288 \n   1    1    1    1    1    1    3    1    1    1    1    1    1    1    1    1 \n 289  290  291  292  293  294  295  296  297  298  299  300  301  302  303  304 \n   1    1    1    1    1    1    1    9    1    1    2    1    1    1    1    1 \n 305  306  307  308  309  310  311  312  313  314  315  316  317  318  319  320 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 321  322  323  324  325  326  327  328  329  330  331  332  333  334  335  336 \n   1    1    1    5    1    1    1    1    1    2    1    1    2    2    1    1 \n 337  338  339  340  341  342  343  344  345  346  347  348  349  350  351  352 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    2    2    1 \n 353  354  355  356  357  358  359  360  361  362  363  364  365  366  367  368 \n   1    1    1    1    9    1    1    1    1    1    1    1    1    1    1    1 \n 369  370  371  372  373  374  375  376  377  378  379  380  381  382  383  384 \n   1    3    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 385  386  387  388  389  390  391  392  393  394  395  396  397  398  399  400 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 401  402  403  404  405  406  407  408  409  410  411  412  413  414  415  416 \n   1    1    2    1    1    1    1    1    1    1    2    1    1    1    1    1 \n 417  418  419  420  421  422  423  424  425  426  427  428  429  430  431  432 \n   1    1    1    1    1    1    1    2    1    1    2    1    1    1    1    1 \n 433  434  435  436  437  438  439  440  441  442  443  444  445  446  447  448 \n   1    1    1    1    2    1    1    1    1    1    1    1    1    1    1    1 \n 449  450  451  452  453  454  455  456  457  458  459  460  461  462  463  464 \n   1    1    9    9    1    1    1    1    1    1    1    1    1    1    2    1 \n 465  466  467  468  469  470  471  472  473  474  475  476  477  478  479  480 \n   2    1    1    1    1    1    1    1    1    1    1    1    2    2    1    1 \n 481  482  483  484  485  486  487  488  489  490  491  492  493  494  495  496 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 497  498  499  500  501  502  503  504  505  506  507  508  509  510  511  512 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    2 \n 513  514  515  516  517  518  519  520  521  522  523  524  525  526  527  528 \n   1    1    1    1    1    1    1    1    1    1    1    2    1    1    3    1 \n 529  530  531  532  533  534  535  536  537  538  539  540  541  542  543  544 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 545  546  547  548  549  550  551  552  553  554  555  556  557  558  559  560 \n   1    1    1    1    1    1    1    1    1    3    1    1    1    1    1    1 \n 561  562  563  564  565  566  567  568  569  570  571  572  573  574  575  576 \n   2    2    2    1    1    1    1    2    1    1    2    1    1    1    2    1 \n 577  578  579  580  581  582  583  584  585  586  587  588  589  590  591  592 \n   1    2    1    1    1    1    1    9    1    4    1    2    1    1    1    1 \n 593  594  595  596  597  598  599  600  601  602  603  604  605  606  607  608 \n   2    1    1    1    1    1    1    1    2    1    2    1    1    1    1    1 \n 609  610  611  612  613  614  615  616  617  618  619  620  621  622  623  624 \n   1    1    1    1    1    1    1    1    1    2    1    2    1    1    1    1 \n 625  626  627  628  629  630  631  632  633  634  635  636  637  638  639  640 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 641  642  643  644  645  646  647  648  649  650  651  652  653  654  655  656 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    4 \n 657  658  659  660  661  662  663  664  665  666  667  668  669  670  671  672 \n   1    1    1    1    1    1    1    3    1    1    1    1    1    1    1    1 \n 673  674  675  676  677  678  679  680  681  682  683  684  685  686  687  688 \n   1    1    1    1    1    4    1    1    1    1    1    4    1    1    1    1 \n 689  690  691  692  693  694  695  696  697  698  699  700  701  702  703  704 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 705  706  707  708  709  710  711  712  713  714  715  716  717  718  719  720 \n   1    1    2    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 721  722  723  724  725  726  727  728  729  730  731  732  733  734  735  736 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 737  738  739  740  741  742  743  744  745  746  747  748  749  750  751  752 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 753  754  755  756  757  758  759  760  761  762  763  764  765  766  767  768 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n 769  770  771  772  773  774  775  776  777  778  779  780  781  782  783  784 \n   1    1    1    1    1    1    1    1    1    4    1    1    1    1    1    1 \n 785  786  787  788  789  790  791  792  793  794  795  796  797  798  799  800 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 801  802  803  804  805  806  807  808  809  810  811  812  813  814  815  816 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 817  818  819  820  821  822  823  824  825  826  827  828  829  830  831  832 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 833  834  835  836  837  838  839  840  841  842  843  844  845  846  847  848 \n   1    1    1    1    1    1    1    2    1    1    1    1    1    1    1    1 \n 849  850  851  852  853  854  855  856  857  858  859  860  861  862  863  864 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 865  866  867  868  869  870  871  872  873  874  875  876  877  878  879  880 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 881  882  883  884  885  886  887  888  889  890  891  892  893  894  895  896 \n   3    1    1    1    2    1    1    1    3    1    1    3    1    1    1    1 \n 897  898  899  900  901  902  903  904  905  906  907  908  909  910  911  912 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 913  914  915  916  917  918  919  920  921  922  923  924  925  926  927  928 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 929  930  931  932  933  934  935  936  937  938  939  940  941  942  943  944 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 945  946  947  948  949  950  951  952  953  954  955  956  957  958  959  960 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n 961  962  963  964  965  966  967  968  969  970  971  972  973  974  975  976 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 977  978  979  980  981  982  983  984  985  986  987  988  989  990  991  992 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n 993  994  995  996  997  998  999 1000 1001 1002 1003 1004 1005 1006 1007 1008 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1009 1010 1011 1012 1013 1014 1015 1016 1017 1018 1019 1020 1021 1022 1023 1024 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1035 1036 1037 1038 1039 1040 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051 1052 1053 1054 1055 1056 \n   1    1    1    1    1    1    1    1    1    2    2    1    1    1    1    1 \n1057 1058 1059 1060 1061 1062 1063 1064 1065 1066 1067 1068 1069 1070 1071 1072 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1073 1074 1075 1076 1077 1078 1079 1080 1081 1082 1083 1084 1085 1086 1087 1088 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1089 1090 1091 1092 1093 1094 1095 1096 1097 1098 1099 1100 1101 1102 1103 1104 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1105 1106 1107 1108 1109 1110 1111 1112 1113 1114 1115 1116 1117 1118 1119 1120 \n   1    1    1    1    1    2    1    1    1    1    1    1    1    1    1    1 \n1121 1122 1123 1124 1125 1126 1127 1128 1129 1130 1131 1132 1133 1134 1135 1136 \n   1    1    1    1    1    1    1    1    2    2    1    1    1    5    1    1 \n1137 1138 1139 1140 1141 1142 1143 1144 1145 1146 1147 1148 1149 1150 1151 1152 \n   1    1    1    1    1    1    1    1    1    2    1    1    1    1    1    1 \n1153 1154 1155 1156 1157 1158 1159 1160 1161 1162 1163 1164 1165 1166 1167 1168 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1169 1170 1171 1172 1173 1174 1175 1176 1177 1178 1179 1180 1181 1182 1183 1184 \n   1    9    1    2    2    1    1    1    2    1    1    1    1    1    1    1 \n1185 1186 1187 1188 1189 1190 1191 1192 1193 1194 1195 1196 1197 1198 1199 1200 \n   1    1    1    1    2    1    1    1    3    1    1    1    1    1    1    1 \n1201 1202 1203 1204 1205 1206 1207 1208 1209 1210 1211 1212 1213 1214 1215 1216 \n   9    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1217 1218 1219 1220 1221 1222 1223 1224 1225 1226 1227 1228 1229 1230 1231 1232 \n   1    1    1    2    1    1    1    1    1    1    1    1    1    1    1    1 \n1233 1234 1235 1236 1237 1238 1239 1240 1241 1242 1243 1244 1245 1246 1247 1248 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1249 1250 1251 1252 1253 1254 1255 1256 1257 1258 1259 1260 1261 1262 1263 1264 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1265 1266 1267 1268 1269 1270 1271 1272 1273 1274 1275 1276 1277 1278 1279 1280 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1281 1282 1283 1284 1285 1286 1287 1288 1289 1290 1291 1292 1293 1294 1295 1296 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    2 \n1297 1298 1299 1300 1301 1302 1303 1304 1305 1306 1307 1308 1309 1310 1311 1312 \n   1    1    1    2    1    2    1    1    1    2    2    2    1    1    1    1 \n1313 1314 1315 1316 1317 1318 1319 1320 1321 1322 1323 1324 1325 1326 1327 1328 \n   1    1    2    1    1    1    1    1    1    1    1    1    2    1    1    1 \n1329 1330 1331 1332 1333 1334 1335 1336 1337 1338 1339 1340 1341 1342 1343 1344 \n   1    1    1    1    3    1    1    1    1    1    1    1    1    1    1    1 \n1345 1346 1347 1348 1349 1350 1351 1352 1353 1354 1355 1356 1357 1358 1359 1360 \n   1    1    1    1    1    1    1    1    4    1    1    1    1    1    2    1 \n1361 1362 1363 1364 1365 1366 1367 1368 1369 1370 1371 1372 1373 1374 1375 1376 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1377 1378 1379 1380 1381 1382 1383 1384 1385 1386 1387 1388 1389 1390 1391 1392 \n   1    1    1    1    1    1    1    1    1    9    1    1    1    1    1    1 \n1393 1394 1395 1396 1397 1398 1399 1400 1401 1402 1403 1404 1405 1406 1407 1408 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1409 1410 1411 1412 1413 1414 1415 1416 1417 1418 1419 1420 1421 1422 1423 1424 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1425 1426 1427 1428 1429 1430 1431 1432 1433 1434 1435 1436 1437 1438 1439 1440 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    2    1 \n1441 1442 1443 1444 1445 1446 1447 1448 1449 1450 1451 1452 1453 1454 1455 1456 \n   1    2    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1457 1458 1459 1460 1461 1462 1463 1464 1465 1466 1467 1468 1469 1470 1471 1472 \n   1    1    1    1    1    1    1    1    1    1    2    1    1    1    1    1 \n1473 1474 1475 1476 1477 1478 1479 1480 1481 1482 1483 1484 1485 1486 1487 1488 \n   1    1    1    1    1    1    2    1    1    1    1    1    1    1    1    1 \n1489 1490 1491 1492 1493 1494 1495 1496 1497 1498 1499 1500 1501 1502 1503 1504 \n   1    1    1    1    1    1    1    1    1    1    5    1    1    1    1    1 \n1505 1506 1507 1508 1509 1510 1511 1512 1513 1514 1515 1516 1517 1518 1519 1520 \n   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1 \n1521 1522 1523 1524 1525 1526 1527 1528 1529 1530 1531 1532 1533 1534 1535 1536 \n   1    1    1    1    1    2    1    1    1    1    2    1    1    1    1    3 \n1537 1538 1539 1540 1541 1542 1543 1544 1545 \n   1    1    1    1    1    1    2    1    1 \n\n\nTo check for the number of locations that have more than one point event, we can use the code chunk below.\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 128\n\n\nThe output show 128 duplicated point events.\nTo view the locations of these duplicate point events, we will plot childcare data by using the code chunk below.\n\ntmap_mode('view')\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\ntmap_mode('plot')\ntmap_mode('view')\n\nThere are three ways to overcome this problem.\n\nThe first and easiest way is to delete the duplicates. But, that will also mean that some useful point events will be lost.\nThe second solution is use jittering. If duplicates are hard to spot, you can apply a slight jitter to the points’ coordinates. Jittering will slightly displace the points so that overlapping points are separated on the map.\nThe third solution is to make each point “unique” and then attach the duplicates of the points to the patterns as marks, as attributes of the points. Then you would need analytical techniques that take into account these marks.\n\nThe jitter parameter will slightly move each point by a small, random amount. This can help to visually separate points that are in the same space.\n\ntm_shape(childcare) +\n  tm_dots(jitter=0.1, alpha=0.4, size=0.05)\n\n\n\n\n\n\n\n\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nAfter jittering we can check if there are any duplicate point in this geospatial data\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE\n\n\n\n\n3.5.5 Creating owin object\nTo confine analysis to a geographical area, convert the SpatialPolygon object to an owin object of spatstat:\n\nsg_owin &lt;- as.owin(sg_sf)\n  \nplot(sg_owin)\n\n\n\n\n\n\n\n\nFurther analysis can be done through the summary() function of Base R:\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\n\n3.5.6 Combining point events object and owin object\nFinally, you can combine the point events with the polygon feature to create a ppp object confined to the Singapore region\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\nsummary(childcareSG_ppp )\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\n*Pattern contains duplicated points*\n\nCoordinates are given to 11 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n      0       0       0       0       0       0 \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\n\nplot(childcareSG_ppp)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#first-order-spatial-point-patterns-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.6 First-order Spatial Point Patterns Analysis",
    "text": "3.6 First-order Spatial Point Patterns Analysis\nIn this section, we will learn how to perform first-order Spatial Point Pattern Analysis (SPPA) using the spatstat package. The focus will be on:\n\nDeriving Kernel Density Estimation (KDE) layers for visualizing and exploring the intensity of point processes.\nPerforming Confirmatory Spatial Point Patterns Analysis using Nearest Neighbour statistics.\n\n\n3.6.1 Kernel Density Estimation\nKernel Density Estimation (KDE) is a non-parametric way to estimate the intensity (density) of spatial point patterns. It helps in visualizing the spatial distribution of points by smoothing the point pattern to create a continuous surface.\n\n3.6.1.1 Computing kernel density estimation using automatic bandwidth selection method\nTo compute the KDE for the spatial point pattern of childcare services in Singapore, we’ll use the density() function from the spatstat package. This function allows for various configurations:\n\nAutomatic Bandwidth Selection: We’ll use  bw.diggle() , a method that selects an optimal bandwidth based on the data. Other methods like  bw.CvL() ,  bw.scott(), or  bw.ppl() can also be used depending on the specific needs of the analysis.\nSmoothing Kernel: The default kernel used is Gaussian. Other options include “Epanechnikov”, “Quartic”, or “Disc”.\nEdge Correction: The intensity estimate is corrected for edge effects to reduce bias, following methods described by Jones (1993) and Diggle (2010).\n\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \n\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nIn this example, the density values range from 0 to 0.000035, which are quite small. This is because the unit of measurement is in meters, making the density values “number of points per square meter”.\nTo check the bandwidth used:\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095 \n\n\n\n\n3.6.1.2 Rescalling KDE values\nThe small density values are due to the measurement unit being in meters. To make the results more interpretable, we can rescale the spatial point pattern from meters to kilometers.\nThe code chunk below rescale the point pattern to kilometers, recompute the KDE with the rescaled data, and plots the rescaled KDE\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp.km, \n                              sigma=bw.diggle, \n                              edge=TRUE, \n                              kernel=\"gaussian\")\nplot(kde_childcareSG_bw)\n\n\n\n\n\n\n\n\nThe KDE output will look identical to the original, but the density values will now be more comprehensible, reflecting “number of points per square kilometer.”\n\n\n\n3.6.2 Working with different automatic badwidth methods\nDifferent bandwidth selection methods can produce different smoothing results:\n\nbw.CvL(): Cross-validation based on the likelihood.\nbw.scott(): Scott’s rule of thumb.\nbw.ppl(): Likelihood cross-validation proposed by Diggle.\n\n\nbw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n\n\nbw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n\n\nbw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n\n\nbw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\nRecommendation:\n\nBaddeley et. (2016) suggested the use of the bw.ppl() algorithm because from their experience it tends to produce the more appropriate values when the pattern consists predominantly of tight clusters.\nBut they also insist that if the purpose of once study is to detect a single tight cluster in the midst of random noise then the bw.diggle() method seems to work best.\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, \n                              sigma=bw.diggle, \n                              edge=TRUE, \n                              kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\n\n\n\n\n\n\n3.6.3 Working with different kernel methods\nBeyond the Gaussian kernel, three other kernels can be used to compute KDE:\n\nEpanechnikov\nQuartic\nDisc\n\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#fixed-and-adaptive-kde",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.7 Fixed and Adaptive KDE",
    "text": "3.7 Fixed and Adaptive KDE\n\n3.7.1 Computing KDE by using fixed bandwidth\nNext, you will compute a KDE layer by defining a bandwidth of 600 meter. Notice that in the code chunk below, the sigma value used is 0.6. This is because the unit of measurement of childcareSG_ppp.km object is in kilometer, hence the 600m is 0.6km.\nTo compute a KDE layer using a fixed bandwidth of 0.6 km, use the following code:\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)\n\n\n\n\n\n\n\n\nThis will generate a KDE layer with a consistent bandwidth across the entire study area, useful for uniform spatial point patterns.\n\n\n3.7.2 Computing KDE by using adaptive bandwidth\nAdaptive bandwidth methods are more suitable for spatial point patterns with high variability, such as urban versus rural areas. The adaptive.density() function of spatstat can be used to create a KDE layer that adjusts the bandwidth based on point density:\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\n\n\n\n\nTo compare the outputs of fixed and adaptive bandwidth KDE:\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed Bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive Bandwidth\")\n\n\n\n\n\n\n\n\n\n\n3.7.3 Converting KDE output into grid object.\nFor mapping purposes, KDE outputs can be converted into grid and raster formats 1. Converting to Grid Object:\n\ngridded_kde_childcareSG_bw &lt;- as(kde_childcareSG.bw, \"SpatialGridDataFrame\")\nspplot(gridded_kde_childcareSG_bw)\n\n\n\n\n\n\n\n\n\nConverting to Raster Object:\n\n\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nAssigning Projection System: Ensure the CRS (Coordinate Reference System) is assigned correctly:\n\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\n\nVisualizing the Raster: Finally, use the tmap package to visualize the raster in a cartographic map:\n\n\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\n\n\n\n\n\n\n\nNotice that the raster values are encoded explicitly onto the raster pixel using the values in “v”” field.\n\n\n3.7.4 Comparing Spatial Point Patterns using KDE\nIn this section, we will learn to compare KDE of childcare at Ponggol, Tampines, Chua Chu Kang and Jurong West planning regions.\n\n3.7.4.1 Extracting study area\n\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\n\nPlotting target planning areas 1. Ponggol\n\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\n\n\n\n\n\n\n\n\nTampines\n\n\nplot(tm, main = \"Tampines\")\n\n\n\n\n\n\n\n\n\nChoa Chu Kang\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\n\n\n\n\n\n\n\n\nJurong West\n\n\nplot(jw, main = \"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.2 Creating owin object\nNow, we will convert these sf objects into owin objects that is required by spatstat.\nThe owin objects represent the study areas as window objects, which are necessary for spatial point pattern analysis in spatstat. These are created by converting the sf objects (pg, tm, ck, and jw) representing different regions into owin format:\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)\n\n\n\n3.7.4.3 Combining childcare points and the study area\nwe are then able to extract childcare that is within the specific region to perform analysis later on.\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\n\nThe childcare centers within each specific region are extracted using the owin objects.\nThese point patterns (ppp objects) are then rescaled from meters to kilometers:\n\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\n\nFinally, the four study areas and the locations of the childcare centers are plotted:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(childcare_pg_ppp.km, main=\"Punggol\")\nplot(childcare_tm_ppp.km, main=\"Tampines\")\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.4 Computing KDE\nThe Kernel Density Estimate (KDE) for each area is computed using the density() function, with the bw.diggle method to derive the bandwidth:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcare_pg_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\"), main=\"Jurong West\")\n\n\n\n\n\n\n\n\n\n\n3.7.4.5 Computing Fixed Bandwidth KDE\nFor comparison, a fixed bandwidth of 250 meters is used to compute KDE for the same areas:\n\npar(mfrow=c(2,2), mar=c(1, 1, 1, 1), cex=0.5)\nplot(density(childcare_pg_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Tampines\")\nplot(density(childcare_ck_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, sigma=0.25, edge=TRUE, kernel=\"gaussian\"), main=\"Jurong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#nearest-neighbour-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.8 Nearest Neighbour Analysis",
    "text": "3.8 Nearest Neighbour Analysis\nIn this section, we will perform the Clark-Evans test of aggregation for a spatial point pattern by using clarkevans.test() of statspat.\n\n3.8.1 Testing Spatial Point Patterns using Clark and Evans Test\nThe Clark-Evans test is performed to assess the spatial distribution of the childcare centers. The hypotheses are:\n\nH0: The distribution of childcare centers is random.\nH1: The distribution of childcare centers is clustered.\n\nThe test is conducted as follows:\n\nclarkevans.test(childcareSG_ppp, correction=\"none\", clipregion=\"sg_owin\", alternative=\"clustered\", nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nResult Interpretation:\n\nR = 0.55631: The R-value is less than 1, indicating a tendency towards clustering.\np-value &lt; 2.2e-16: The p-value is extremely small, suggesting that the clustering pattern is statistically significant. The null hypothesis of CSR (Complete Spatial Randomness) is rejected in favor of the alternative hypothesis, indicating that the childcare centers in Singapore are clustered.\n\n\n\n3.8.2 Clark and Evans Test: Punggol planning area\nIn the code chunk below,  clarkevans.test() of spatstat is used to performs Clark-Evans test of aggregation for childcare centre in Punggol planning area.\n\nclarkevans.test(childcare_pg_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=\"two.sided\",\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_pg_ppp\nR = 0.91928, p-value = 0.2278\nalternative hypothesis: two-sided\n\n\nInterpretation:\n\nR = 0.91163: The R-value is close to 1, indicating a spatial distribution that is close to random.\n\n\np-value = 0.1867: The p-value is greater than 0.05, meaning there is no statistically significant evidence to reject the null hypothesis of CSR. This suggests that the childcare centers in the Punggol area are randomly distributed and do not exhibit significant clustering or regularity."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#second-order-spatial-point-patterns-analysis",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.9 Second-order Spatial Point Patterns Analysis",
    "text": "3.9 Second-order Spatial Point Patterns Analysis\nThis section introduces second-order analyses of spatial point patterns, focusing on measuring interaction between points."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-g-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.10 Analysing Spatial Point Process Using G-Function",
    "text": "3.10 Analysing Spatial Point Process Using G-Function\nThe G function measures the distribution of the distances from an arbitrary event to its nearest event. In this section, you will learn how to compute G-function estimation by using Gest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.10.1 Choa Chu Kang planning area\n\n3.10.1.1 Computing G-function estimation\nThe code chunk below is used to compute G-function using Gest() of spatat package.\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\n\n\n\n\n\n\n3.10.1.2 Performing Complete Spatial Randomness Test\nTo perform a Complete Spatial Randomness (CSR) test using a Monte Carlo simulation with the G-function in R, you are correctly using the envelope() function from the spatstat package. Here’s how you can carry out the test and interpret the results:\n\nHypothesis Definition:\n\nNull Hypothesis (Ho): The distribution of childcare services at Choa Chu Kang is randomly distributed (i.e., follows CSR).\nAlternative Hypothesis (H1): The distribution of childcare services at Choa Chu Kang is not randomly distributed.\n\nSet Up the Test:\n\nYou will perform a Monte Carlo test using the G-function, which measures the distribution of nearest-neighbor distances.\n\n\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n3.10.2 Tampines planning area\n\n3.10.2.1 Computing G-function estimation\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)\n\n\n\n\n\n\n\n\n\n\n3.10.2.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, we perform the Complete Spatial Randomness (CSR) test for the distribution of childcare services in Tampines using the G-function in R, you can follow the steps and code chunk below:\n\nHypothesis:\n\nNull Hypothesis (Ho): The distribution of childcare services at Tampines is randomly distributed (CSR).\nAlternative Hypothesis (H1): The distribution of childcare services at Tampines is not randomly distributed\n\n\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-f-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.11 Analysing Spatial Point Process Using F-Function",
    "text": "3.11 Analysing Spatial Point Process Using F-Function\nThe F-function estimates the empty space function F(r) from a point pattern within a defined window. It provides insights into the spatial distribution by measuring the distribution of distances from a randomly chosen location in the study area to the nearest event (e.g., childcare centers). We will compute the F-function for the Choa Chu Kang and Tampines planning areas and perform a Complete Spatial Randomness (CSR) test using Monte Carlo simulations.\nWe will learn how to compute F-function estimation by using Fest() of spatstat package, and how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.11.1 Choa Chu Kang planning area\n\n3.11.1.1 Computing F-fucntion estimate\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\n\n\n\n\n\n\n3.11.1.2 Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns at Choa Chu Kang, a hypothesis test using the F-function will be conducted. The hypotheses are:\n\nHo (Null Hypothesis): The distribution of childcare services at Choa Chu Kang is randomly distributed.\nH1 (Alternative Hypothesis): The distribution of childcare services at Choa Chu Kang is not randomly distributed.\n\nThe null hypothesis will be rejected if the p-value is smaller than the alpha value of 0.001.\nMonte Carlo Test Using F-function:\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_CK.csr)\n\n\n\n\n\n\n\n\n\n\n\n3.11.2 Tampines planning area\n\n3.11.2.1 Computing F-fucntion estimation\nMonte Carlo test with F-fucntion\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\n\n\n\n\n\n3.11.2.2 Computing F-fucntion estimation\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-k-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.12 Analysing Spatial Point Process Using K-Function",
    "text": "3.12 Analysing Spatial Point Process Using K-Function\nK-function measures the number of events found up to a given distance of any particular event. In this section, you will learn how to compute K-function estimates by using Kest() of spatstat package. You will also learn how to perform monta carlo simulation test using envelope() of spatstat package.\n\n3.12.1 Choa Chu Kang planning area\n\n3.12.1.1 Computing K-fucntion estimation\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n3.12.1.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n3.12.2 Tampines planning area\n\n3.12.2.1 Computing K-fucntion estimation\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n3.12.2.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex03.html#analysing-spatial-point-process-using-l-function",
    "title": "1st & 2nd Order Spatial Point Patterns Analysis Methods",
    "section": "3.13 Analysing Spatial Point Process Using L-Function",
    "text": "3.13 Analysing Spatial Point Process Using L-Function\nThe L-function is a method used to analyze spatial point patterns by transforming the K-function to be more interpretable, particularly by normalizing the function against a theoretical CSR model. This section covers how to compute the L-function estimation and perform a Monte Carlo simulation test using the  Lest() and envelope() of spatstat package.\n\n3.13.1 Choa Chu Kang planning area\n\n3.13.1.1 Computing L-fucntion estimation\nTo compute the L-function estimation for Choa Chu Kang, use the Lest() function with the “Ripley” correction. Then, plot the results.\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\n\n\n\n\n\n3.13.1.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\n\n\n\n\n\n\n3.13.2 Tampines planning area\n\n3.13.2.1 Computing L-fucntion estimation\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\n\n\n\n\n\n3.13.2.2 Performing Complete Spatial Randomness Test\nSimilar to before, a hypothesis test will be conducted to confirm the observed spatial patterns above. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, global=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_tm.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01.html",
    "title": "Geospatial Data Science with R",
    "section": "",
    "text": "In this hands-on exercise, I learnt of how to perform geospatial data science tasks in R by using the sf package.\nUse pacman::p_load to install and load sf and tidyverse"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#exercise-overview",
    "title": "Geospatial Data Science with R",
    "section": "",
    "text": "In this hands-on exercise, I learnt of how to perform geospatial data science tasks in R by using the sf package.\nUse pacman::p_load to install and load sf and tidyverse"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#data-acquisition",
    "title": "Geospatial Data Science with R",
    "section": "1.2 Data Acquisition",
    "text": "1.2 Data Acquisition\nData are key to data analytics including geospatial analytics. Hence, before analysing, we need to assemble the necessary data. These data sources publicly available.\n\nMaster Plan 2014 Subzone Boundary (Web) from data.gov.sg\nPre-Schools Location from data.gov.sg\nCycling Path from LTADataMall\nLatest version of Singapore Airbnb listing data from Inside Airbnb"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#getting-started",
    "title": "Geospatial Data Science with R",
    "section": "1.3 Getting Started",
    "text": "1.3 Getting Started\nFor this exercise, two R packages will be used:\n\nsf for importing, managing, and processing geospatial data\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\n\nTidyverse consists of a family of R packages. In this hands-on exercise, the following packages will be used:\n\nreadr for importing csv data\nreadxl for importing Excel worksheet\ntidyr for manipulating data\ndplyr for transforming data\nggplot2 for visualising data\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf,tidyverse)\n\nThe p_load function conveniently installs (if necessary) and loads the sf and tidyverse packages, making them readily available for use in our analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#importing-geospatial-data-into-r",
    "title": "Geospatial Data Science with R",
    "section": "1.4 Importing Geospatial Data into R",
    "text": "1.4 Importing Geospatial Data into R\nIn this section, you will learn how to import various geospatial data formats into R using the st_read() of sf package. The following datasets will be imported:\n\nMP14_SUBZONE_WEB_PL, a polygon feature layer in ESRI shapefile format,\nCyclingPath, a line feature layer in ESRI shapefile format, and\nPreSchool, a point feature layer in kml file format.\n\n\n1.4.1 Importing polygon feature data (shapefile format)\nThe code below demonstrates how to import the MP14_SUBZONE_WEB_PL shapefile into R as a polygon feature data frame using the st_read() function. When dealing with shapefiles, you need to specify two arguments: dsn (the data source path) and layer (the shapefile name). Note that you do not need to include file extensions like .shp, .dbf, .prj, or .shx.\n\nmpsz = st_read(dsn = \"data/geospatial/MasterPlan2014SubzoneBoundaryWebSHP\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\MasterPlan2014SubzoneBoundaryWebSHP' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThis message indicates that the mpsz object is a simple feature data frame containing 323 multipolygon features and 15 fields, with the SVY21 projected coordinate system. The bounding box provides the data’s spatial extent.\n\n\n1.4.2 Importing polyline feature data (Shapefile Format)\nThe following code demonstrates how to import the CyclingPath shapefile into R as a line feature data frame:\n\ncyclingpath = st_read(dsn = \"data/geospatial/CyclingPath_Jul2024\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\CyclingPath_Jul2024' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\n\nThis output reveals that the cyclingpath object is a simple feature data frame containing 3138 line features and 2 fields, with the same SVY21 projected coordinate system.\n\n\n1.4.3 Importing GIS data in (KML format)\n\npreschool = st_read(\"data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nThis message indicates that preschool is a point feature data frame with 2290 features and 2 fields, using the WGS 84 geodetic coordinate system, different from the previous datasets."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#checking-the-content-of-a-simple-feature-data-frame",
    "title": "Geospatial Data Science with R",
    "section": "1.5 Checking the Content of A Simple Feature Data Frame",
    "text": "1.5 Checking the Content of A Simple Feature Data Frame\nIn this sub-section, we will use different ways to retrieve information related to the content of a simple feature data frame.\n\n1.5.1 Working with st_geometry()\nThe geometry column in an sf data frame is a list of class sfc. To access the geometry list-column, we use a more general approach, the st_geometry() function, as shown below:\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nThis function will display basic information about the feature class, such as the geometry type, geographic extent, and coordinate system.\n\n\n1.5.2 glimpse()\nThe glimpse() function reveals the data type of each field, providing insight into the structure and contents of the data frame.\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\n\n\n\n1.5.3 head()\nIf you need to examine the complete information of a feature object, the head() function in base R is helpful. It displays the first few records of the data frame:\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nThe head() function is particularly useful for quickly inspecting a subset of the data."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#plotting-the-geospatial-data",
    "title": "Geospatial Data Science with R",
    "section": "1.6 Plotting the Geospatial Data",
    "text": "1.6 Plotting the Geospatial Data\nIn geospatial data science, visualizing geospatial features is crucial. The plot() function from base R allows you to quickly visualize these features:\n\nplot(mpsz)\n\n\n\n\n\n\n\n\nBy default, this function creates a multi-plot of all attributes. You can also plot only the geometry using:\n\nplot(st_geometry(mpsz))\n\n\n\n\n\n\n\n\nOr plot the sf object based on a specific attribute:\n\nplot(mpsz[\"PLN_AREA_N\"])"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#working-with-projection",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#working-with-projection",
    "title": "Geospatial Data Science with R",
    "section": "1.7 Working with Projection",
    "text": "1.7 Working with Projection\nMap projection is a key aspect of geospatial data. To perform geoprocessing on two datasets, they must share the same coordinate system.\nIn this section, we will learn how to project a simple feature data frame from one coordinate system to another coordinate system. The technical term of this process is called projection transformation.\n\n1.7.1 Assigning EPSG code to a simple feature data frame\nWhen importing geospatial data into R, the coordinate system might be missing or incorrectly assigned. You can check the coordinate system of a simple feature data frame using st_crs():\nThis is an example the coordinate system of mpsz simple feature data frame by using st_crs() of sf package as shown in the code chunk below.\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\n\nAlthough mpsz data frame is projected in svy21 but when we read until the end of the print, it indicates that the EPSG is 9001. This is a wrong EPSG code because the correct EPSG code for svy21 should be 3414.\nIn order to assign the correct EPSG code to mpsz data frame, st_set_crs() of sf package is used as shown in the code chunk below.\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nNow, let us check the CSR again by using the code chunk below.\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG code is 3414 now.\n\n\n1.7.2 Transforming the projection of preschool from wgs84 to svy21\nIn geospatial analytics, it is very common for us to transform the original data from geographic coordinate system to projected coordinate system. This is because geographic coordinate system is not appropriate if the analysis need to use distance or/and area measurements.\nLet us take preschool simple feature data frame as an example. The print below reveals that it is in wgs84 coordinate system.\n\nst_geometry(preschool)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\nFirst 5 geometries:\n\n\nThis is a scenario that st_set_crs() is not appropriate and st_transform() of sf package should be used. This is because we need to reproject preschool from one coordinate system to another coordinate system mathemetically.\nLet us perform the projection transformation by using the code chunk below.\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\n\nNext, let us display the content of preschool3414 sf data frame as shown below.\n\nst_geometry(preschool3414)\n\nGeometry set for 2290 features \nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 5 geometries:"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#importing-and-converting-an-aspatial-data",
    "title": "Geospatial Data Science with R",
    "section": "1.8 Importing and Converting An Aspatial Data",
    "text": "1.8 Importing and Converting An Aspatial Data\nAn example of aspatial data would be listing of inside Airbnb. This is because it is not a geospatial data but among the data fields, there are two fields that capture the x- and y-coordinates of the data points.\nIn this section, we will be importing an aspatial data into R environment and save it as a tibble data frame. Next, we will convert it into a simple feature data frame.\n\n1.8.1 Importing the aspatial data\n\nlistings &lt;- read_csv(\"data/aspatial/listings.csv\")\n\nAfter importing, it’s important to check that the data was imported correctly using list():\n\nlist(listings) \n\n[[1]]\n# A tibble: 3,540 × 18\n       id name      host_id host_name neighbourhood_group neighbourhood latitude\n    &lt;dbl&gt; &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;               &lt;chr&gt;            &lt;dbl&gt;\n 1  71609 Ensuite …  367042 Belinda   East Region         Tampines          1.35\n 2  71896 B&B  Roo…  367042 Belinda   East Region         Tampines          1.35\n 3  71903 Room 2-n…  367042 Belinda   East Region         Tampines          1.35\n 4 275343 10min wa… 1439258 Kay       Central Region      Bukit Merah       1.29\n 5 275344 15 mins … 1439258 Kay       Central Region      Bukit Merah       1.29\n 6 289234 Booking …  367042 Belinda   East Region         Tampines          1.34\n 7 294281 5 mins w… 1521514 Elizabeth Central Region      Newton            1.31\n 8 324945 Comforta… 1439258 Kay       Central Region      Bukit Merah       1.29\n 9 330095 Relaxing… 1439258 Kay       Central Region      Bukit Merah       1.29\n10 344803 Budget s…  367042 Belinda   East Region         Tampines          1.35\n# ℹ 3,530 more rows\n# ℹ 11 more variables: longitude &lt;dbl&gt;, room_type &lt;chr&gt;, price &lt;dbl&gt;,\n#   minimum_nights &lt;dbl&gt;, number_of_reviews &lt;dbl&gt;, last_review &lt;date&gt;,\n#   reviews_per_month &lt;dbl&gt;, calculated_host_listings_count &lt;dbl&gt;,\n#   availability_365 &lt;dbl&gt;, number_of_reviews_ltm &lt;dbl&gt;, license &lt;chr&gt;\n\n\n\n\n1.8.2 Creating a simple feature data frame from an aspatial data frame\nThe code chunk below converts listing data frame into a simple feature data frame by using st_as_sf() of sf packages\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\n\nThings to learn from the arguments above:\n\ncoords argument requires you to provide the column name of the x-coordinates first then followed by the column name of the y-coordinates.\ncrs argument requires you to provide the coordinates system in epsg format. EPSG: 4326 is wgs84 Geographic Coordinate System and EPSG: 3414 is Singapore SVY21 Projected Coordinate System. You can search for other country’s epsg code by referring to epsg.io.\n%&gt;% is used to nest st_transform() to transform the newly created simple feature data frame into svy21 projected coordinates system.\n\nLet us examine the content of this newly created simple feature data frame.\n\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 17\n$ id                             &lt;dbl&gt; 71609, 71896, 71903, 275343, 275344, 28…\n$ name                           &lt;chr&gt; \"Ensuite Room (Room 1 & 2) near EXPO\", …\n$ host_id                        &lt;dbl&gt; 367042, 367042, 367042, 1439258, 143925…\n$ host_name                      &lt;chr&gt; \"Belinda\", \"Belinda\", \"Belinda\", \"Kay\",…\n$ neighbourhood_group            &lt;chr&gt; \"East Region\", \"East Region\", \"East Reg…\n$ neighbourhood                  &lt;chr&gt; \"Tampines\", \"Tampines\", \"Tampines\", \"Bu…\n$ room_type                      &lt;chr&gt; \"Private room\", \"Private room\", \"Privat…\n$ price                          &lt;dbl&gt; NA, 80, 80, 50, 50, NA, 85, 65, 45, 54,…\n$ minimum_nights                 &lt;dbl&gt; 92, 92, 92, 180, 180, 92, 92, 180, 180,…\n$ number_of_reviews              &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 131, 17, 5, 60,…\n$ last_review                    &lt;date&gt; 2020-01-17, 2019-10-13, 2020-01-09, 20…\n$ reviews_per_month              &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0.11, 0.08, 0.8…\n$ calculated_host_listings_count &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49, 49, 6, 7, 7,…\n$ availability_365               &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 365, 0, 0, 365,…\n$ number_of_reviews_ltm          &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 0, 0, 0, …\n$ license                        &lt;chr&gt; NA, NA, NA, \"S0399\", \"S0399\", NA, NA, \"…\n$ geometry                       &lt;POINT [m]&gt; POINT (41972.5 36390.05), POINT (…\n\n\nTable above shows the content of listing_sf. Notice that a new column called geometry has been added into the data frame. On the other hand, the longitude and latitude columns have been dropped from the data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#geoprocessing-with-sf-package",
    "title": "Geospatial Data Science with R",
    "section": "1.9 Geoprocessing with sf package",
    "text": "1.9 Geoprocessing with sf package\nIn this section, we will perform two commonly used geoprocessing functions, namely buffering and point in polygon count.\n\n1.9.1 Buffering\nThe scenario:\nThe authority is planning to upgrade the exiting cycling path. To do so, they need to acquire 5 metres of reserved land on the both sides of the current cycling path. You are tasked to determine the extend of the land need to be acquired and their total area.\nThe solution:\nFirstly, st_buffer() of sf package is used to compute the 5-meter buffers around cycling paths\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\n\nThis is followed by calculating the area of the buffers as shown in the code chunk below.\n\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\n\nLastly, sum() of Base R will be used to derive the total land involved\n\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nMission Accomplished!\n\n\nPoint-in-polygon count\nThe scenario:\nA pre-school service group want to find out the numbers of pre-schools in each Planning Subzone.\nThe solution:\nThe code chunk below performs two operations at one go. Firstly, identify pre-schools located inside each Planning Subzone by using st_intersects(). Next, length() of Base R is used to calculate numbers of pre-schools that fall inside each planning subzone.\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\n\nYou can check the summary statistics of the newly derived PreSch Count field by using summary() as shown in the code chunk below.\n\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\n\nTo list the planning subzone with the most number of pre-school, the top_n() of dplyr package is used as shown in the code chunk below.\n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\n\nCalculating Density of Preschool by planning subzone\nFirstly, the code chunk below uses st_area() of sf package to derive the area of each planning subzone.\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\n\nNext, mutate() of dplyr package is used to compute the density by using the code chunk below.\n\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex01.html#exploratory-data-analysis-eda",
    "title": "Geospatial Data Science with R",
    "section": "1.10 Exploratory Data Analysis (EDA)",
    "text": "1.10 Exploratory Data Analysis (EDA)\nIn practice, many geospatial analytics start with Exploratory Data Analysis. In this section, you will learn how to use appropriate ggplot2 functions to create functional and yet truthful statistical graphs for EDA purposes.\nFirstly, we will plot a histogram to reveal the distribution of PreSch Density. Conventionally, hist() of R Graphics will be used as shown in the code chunk below.\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\n\n\n\n\n\nAlthough the syntax is very easy to use however the output is far from meeting publication quality. Furthermore, the function has limited room for further customisation.\nIn the code chunk below, appropriate ggplot2 functions will be used.\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\n\n\n\n\n\nUsing ggplot2 method to plot a scatterplot showing the relationship between Pre-school Density and Pre-school Count:\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Welcome! I’m Brian Lim ZhengLong, an undergraduate at Singapore Management University (SMU). This website is dedicated to documenting my learning journey in IS415: Geospatial Analytics and Applications under the guidance of Professor Kam Tin Seong. Join me as I explore the fascinating realms of big data, geospatial analysis, and urban planning.\nLet’s connect and learn together!"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02.html",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to create effective and accurate thematic/choropleth maps and other geospatial visualization techniques using the tmap package in R.\nThematic mapping is a technique that uses map symbols to visualize certain characteristics of geographic features that are not naturally visible, such as population, temperature, crime rates, and property values, among others.\nGeovisualization, on the other hand, involves creating graphical representations to make a place, phenomenon, or process visible. This approach leverages the human brain’s powerful spatial cognition abilities, linked to our eye-brain vision system, to better process and understand spatial information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#exercise-overview",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "",
    "text": "In this hands-on exercise, I learn how to create effective and accurate thematic/choropleth maps and other geospatial visualization techniques using the tmap package in R.\nThematic mapping is a technique that uses map symbols to visualize certain characteristics of geographic features that are not naturally visible, such as population, temperature, crime rates, and property values, among others.\nGeovisualization, on the other hand, involves creating graphical representations to make a place, phenomenon, or process visible. This approach leverages the human brain’s powerful spatial cognition abilities, linked to our eye-brain vision system, to better process and understand spatial information."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#data-acquisition",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nTwo data set will be used to create the choropleth map. They are:\n\nMaster Plan 2014 Subzone Boundary (Web) (i.e. MP14_SUBZONE_WEB_PL) in ESRI shapefile format. It can be downloaded at data.gov.sg This is a geospatial data. It consists of the geographical boundary of Singapore at the planning subzone level. The data is based on URA Master Plan 2014.\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2011-2020 in csv format (i.e.respopagesexfa2011to2020.csv). This is an aspatial data fie. It can be downloaded at Department of Statistics, Singapore Although it does not contain any coordinates values, but it’s PA and SZ fields can be used as unique identifiers to geocode to MP14_SUBZONE_WEB_PL shapefile."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#getting-started",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.3 Getting Started",
    "text": "2.3 Getting Started\nFor this exercise, the following R packages will be used:\n\nreadr for importing delimited text file,\ntidyr for tidying data,\ndplyr for wrangling data and\nsf for handling geospatial data.\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, tmap, tidyverse)\n\nThe p_load function conveniently installs (if necessary) and loads the sf and tidyverse packages, making them readily available for use in our analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#importing-data-into-r",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.4 Importing Data into R",
    "text": "2.4 Importing Data into R\n\n2.4.1 Importing Geospatial Data into R\nThe following code demonstrates how to use the st_read() function from the sf package to import the MP14_SUBZONE_WEB_PL shapefile into R as a simple feature data frame named mpsz:\n\nmpsz &lt;- st_read(dsn = \"data/geospatial/\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nWe can examine the content of mpsz by using the code chunk below\n\nmpsz\n\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 10 features:\n   OBJECTID SUBZONE_NO       SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1         1          1    MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2         2          1    PEARL'S HILL    OTSZ01      Y          OUTRAM\n3         3          3       BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4         4          8  HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5         5          3         REDHILL    BMSZ03      N     BUKIT MERAH\n6         6          7  ALEXANDRA HILL    BMSZ07      N     BUKIT MERAH\n7         7          9   BUKIT HO SWEE    BMSZ09      N     BUKIT MERAH\n8         8          2     CLARKE QUAY    SRSZ02      Y SINGAPORE RIVER\n9         9         13 PASIR PANJANG 1    QTSZ13      N      QUEENSTOWN\n10       10          7       QUEENSWAY    QTSZ07      N      QUEENSTOWN\n   PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1          MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2          OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3          SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4          BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5          BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n6          BM CENTRAL REGION       CR 9D286521EF5E3B59 2014-12-05 25358.82\n7          BM CENTRAL REGION       CR 7839A8577144EFE2 2014-12-05 27680.06\n8          SR CENTRAL REGION       CR 48661DC0FBA09F7A 2014-12-05 29253.21\n9          QT CENTRAL REGION       CR 1F721290C421BFAB 2014-12-05 22077.34\n10         QT CENTRAL REGION       CR 3580D2AFFBEE914C 2014-12-05 24168.31\n     Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1  29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2  29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3  29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4  29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5  30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n6  29991.38   4428.913  1030378.8 MULTIPOLYGON (((25899.7 297...\n7  30230.86   3275.312   551732.0 MULTIPOLYGON (((27746.95 30...\n8  30222.86   2208.619   290184.7 MULTIPOLYGON (((29351.26 29...\n9  29893.78   6571.323  1084792.3 MULTIPOLYGON (((20996.49 30...\n10 30104.18   3454.239   631644.3 MULTIPOLYGON (((24472.11 29...\n\n\nThe reason only the first 10 records are displayed by mpsz is due to its default behaviour. Using head() would allow for the number of display records to change according to the n value.\n\nhead(mpsz, n = 5)\n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\n\n\n2.4.2 Importing Attribute Data into R\nNext, we will import the respopagesexfa2011to2020.csv file into the R environment and save it into an R dataframe called popdata. The task can be performed using the read_csv() function from the readr package, as shown below:\n\npopdata &lt;- read_csv(\"data/aspatial/respopagesexfa2011to2020.csv\")\n\n\n\n2.4.3 Data Preparation\nBefore creating a thematic map, it’s necessary to prepare a data table with values from the year 2020. This table should include the following variables: PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL, and DEPENDENCY.\n\nYOUNG: Includes age groups from 0-4 up to 20-24.\nECONOMY ACTIVE: Includes age groups from 25-29 up to 60-64.\nAGED: Includes age groups 65 and above.\nTOTAL: Includes all age groups.\nDEPENDENCY: The ratio between the young and aged populations against the economy active group.\n\n\n2.4.3.1 Data Wrangling\nThe following data wrangling and transformation functions will be used:\n\npivot_wider() from the tidyr package.\nmutate(), filter(), group_by(), and select() from the dplyr package.\n\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP)%&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[14])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+\nrowSums(.[15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n\n\n2.4.3.2 Joining the attribute data and geospatial data\nBefore performing a georelational join, it’s necessary to convert the values in the PA and SZ fields to uppercase. This is because these fields contain both uppercase and lowercase letters, while the corresponding fields SUBZONE_N and PLN_AREA_N are in uppercase.\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\n\nNext, the left_join() function from the dplyr package is used to join the geospatial data and attribute table using SUBZONE_N and SZ as the common identifiers:\n\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\nTake note: The left_join() function from the dplyr package is used with the mpsz simple feature data frame as the left data table to ensure that the output remains a simple features data frame.\n\nwrite_rds(mpsz_pop2020, \"data/rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#choropleth-mapping-geospatial-data-using-tmap",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.5 Choropleth Mapping Geospatial Data Using tmap",
    "text": "2.5 Choropleth Mapping Geospatial Data Using tmap\nChoropleth mapping involves the symbolisation of enumeration units, such as countries, provinces, states, counties or census units, using area patterns or graduated colors. For example, a social scientist may need to use a choropleth map to portray the spatial distribution of aged population of Singapore by Master Plan 2014 Subzone Boundary.\nTwo approaches can be used to prepare thematic map using tmap, they are:\n\nPlotting a thematic map quickly by using qtm().\nPlotting highly customisable thematic map by using tmap elements.\n\n\n2.5.1 Plotting a choropleth map quickly by using qtm()\nThe quickest way to draw a choropleth map is using the qtm() function, which provides a good default visualization with minimal coding. Here’s how you can use it:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, fill = \"DEPENDENCY\")\n\n\n\n2.5.2 Creating a choropleth map by using tmap’s elements\nWhile qtm() is useful for quickly drawing a choropleth map, it offers limited control over the aesthetics of individual layers. To create a high-quality cartographic choropleth map, you should use tmap elements like tm_shape(), tm_fill(), and tm_borders().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\n\n2.5.2.1 Drawing a base map\nThe foundation of a tmap visualization is tm_shape(), which is followed by layer elements like tm_fill() and tm_polygons().\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\n\n\n\n\n\n\n\n2.5.2.2 Drawing a choropleth map using tm_polygons()\nTo create a choropleth map that shows the geographical distribution of a variable (e.g., DEPENDENCY) by planning subzone, assign the target variable to tm_polygons().\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\nThings to note with tm_polygons():\n\nThe default interval binning method is “pretty.”\nThe default color scheme is “YlOrRd” from ColorBrewer.\nMissing values are shaded in grey.\n\n\n\n2.5.2.3 Drawing a choropleth map using tm_fill() and tm_border()\ntm_polygons() is essentially a wrapper for tm_fill() and tm_border(). tm_fill() colors the polygons, while tm_borders() adds the borders. Examine the difference in output between the 2 following code chunks:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\n\n\n\n\nNotice that light-gray border lines have been added on the choropleth map with tm_border().\nThe alpha argument is used to define transparency number between 0 (totally transparent) and 1 (not transparent). By default, the alpha value of the col is used (normally 1).\nBeside alpha argument, there are three other arguments for tm_borders(), they are:\n\ncol = border colour,\nlwd = border line width. The default is 1, and\nlty = border line type. The default is “solid”.\n\n\n\n\n2.5.3 Data classification methods of tmap\nChoropleth maps often involve data classification to group observations into ranges or classes. tmap offers ten classification methods, including “fixed,” “sd,” “equal,” “pretty” (default), “quantile,” “kmeans,” “hclust,” “bclust,” “fisher,” and “jenks.”\n\n2.5.3.1 Plotting choropleth maps with built-in classification methods\nThe following code demonstrates a quantile classification with 5 classes:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe equal classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe fisher classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe sd classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe hclust classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"hclust\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nThe jenks classification method can be used as shown below:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          palette = \"viridis\",\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nAdditionally, we can try preparing choropleth maps by using similar classification methods (i.e. kmeans) but with differing number of classes. The following code chunks use kmeans clustering with different class sizes (2, 6, 10, 20)\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 2,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 10,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          palette = \"viridis\",\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.5.3.2 Plotting choropleth map with custom break\nFor all the built-in styles, the category breaks are computed internally. In order to override these defaults, the breakpoints can be set explicitly by means of the breaks argument to the tm_fill(). It is important to note that, in tmap the breaks include a minimum and maximum. As a result, in order to end up with n categories, n+1 elements must be specified in the breaks option (the values must be in increasing order).\nBefore we get started, it is always a good practice to get some descriptive statistics on the variable before setting the break points. Code chunk below will be used to compute and display the descriptive statistics of DEPENDENCY field.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6540  0.7063  0.7712  0.7657 19.0000      92 \n\n\nWith reference to the results above, we set break point at 0.60, 0.70, 0.80, and 0.90 using the breaks argument. In addition, we also need to include a minimum and maximum, which we set at 0 and 100. Our breaks vector is thus c(0, 0.60, 0.70, 0.80, 0.90, 1.00)\nNow, we will plot the choropleth map by using the code chunk below.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.5.4 Colour Scheme\ntmap supports color ramps defined by the user or from the RColorBrewer package.\n\n2.5.4.1 Using ColourBrewer palette\nTo change the color scheme, assign the desired palette to the palette argument of tm_fill().\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nTo reverse the color scheme, add a “-” prefix.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n\n2.5.5 Map Layouts\nMap layout involves combining all map elements into a cohesive visualization, including the title, scale bar, compass, margins, and aspect ratios.\n\n2.5.5.1 Map Legend\ntmap provides several options for customizing the legend’s placement, format, and appearance.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n2.5.5.2 Map style\ntmap allows you to change the map’s layout settings using tmap_style().\nThe code chunk below shows the classic style is used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\n\n\n\n\n\n2.5.5.3 Cartographic Furniture\ntmap also provides functions to add other map elements, such as a compass, scale bar, and grid lines.\nIn the code chunk below, tm_compass(), tm_scale_bar() and tm_grid() are used to add compass, scale bar and grid lines onto the choropleth map.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\n\n\n\nTo reset the default style, refer to the code chunk below.\n\ntmap_style(\"white\")\n\n\n\n\n2.5.6 Drawing Small Multiple Choropleth Maps\nSmall multiple maps, or facet maps, allow the visualization of how spatial relationships change with another variable, such as time. These maps are composed of several maps arranged side by side or stacked vertically. In tmap, small multiple maps can be plotted in three different ways:\n\nBy assigning multiple values to at least one of the aesthetic arguments.\nBy defining a group-by variable in tm_facets().\nBy creating multiple stand-alone maps with tmap_arrange().\n\n\n2.5.6.1 By assigning multiple values to at least one of the aesthetic arguments\nOne way to create small multiple choropleth maps is by defining multiple values for an aesthetic argument such as fill. This method is straightforward and allows for visual comparison across variables.\nThe following code chunk uses tm_fill() with multiple variables\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\n\n\n\nIn this example:\n\nThe c(\"YOUNG\", \"AGED\") argument creates two maps side by side, one for the young population and one for the aged population.\nThe style argument is set to \"equal\" to ensure consistent class breaks across the maps.\n\nThe following code chunk uses tm_polygons() with multiple styles\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\n\n\nIn this example:\n\nThe 2 variables, “DEPENDENCY” and “AGED”, are mapped with different classification styles (“equal” and “quantile”) and color palettes (“Blues” and “Greens”)\n\n\n\n2.5.6.2 By defining a group-by variable in tm_facets()\nAnother approach to creating small multiple maps is by using the tm_facets() function, which allows you to create separate maps based on a grouping variable.\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example:\n\nThe by = \"REGION_N\" argument in tm_facets() creates separate maps for each region.\nfree.coords = TRUE allows each facet to have its own coordinate system, and drop.shapes = TRUE drops shapes not belonging to any of the regions.\n\n\n\n2.5.6.3 By creating multiple stand-alone maps with tmap_arrange()\nYou can also create individual maps and then arrange them side by side using tmap_arrange().\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\nIn this example:\n\nTwo maps, youngmap and agedmap, are created individually.\ntmap_arrange() is then used to display these maps side by side with ncol = 2.\n\n\n\n\n2.5.7 Mappping Spatial Object Meeting a Selection Criterion\nInstead of creating small multiple choropleth maps, you can also map spatial objects that meet a specific selection criterion using selection functions.\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\n\n\nIn this example:\n\nThe data is filtered to only include regions within the “CENTRAL REGION”.\nThe resulting map shows the dependency ratio specifically for this region, with additional customization for the legend and layout.\n\nThese methods allow for versatile and detailed visual representations of spatial data, enabling deeper insights into geographical patterns and trends."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02.html#references",
    "href": "Hands-on_Ex/Hands-on_Ex02.html#references",
    "title": "Thematic Mapping and GeoVisualisation with R",
    "section": "2.6. References",
    "text": "2.6. References\nTutorial provided by Professor Kam Tin Seong©, Singapore Management University\nReference: https://r4gdsa.netlify.app/chap02.html\n\n2.6.1 All about tmap package\n\ntmap: Thematic Maps in R\ntmap\ntmap: get started!\ntmap: changes in version 2.0\ntmap: creating thematic maps in a flexible way (useR!2015)\nExploring and presenting maps with tmap (useR!2017)\n\n\n\n2.6.2 Geospatial data wrangling\n\nsf: Simple Features for R\nSimple Features for R: StandardizedSupport for Spatial Vector Data\nReading, Writing and Converting Simple Features\n\n\n\n2.6.3 Data wrangling\n\ndplyr\nTidy data\ntidyr: Easily Tidy Data with ‘spread()’ and ‘gather()’ Functions"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html",
    "href": "Hands-on_Ex/Hands-on_ex05.html",
    "title": "Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you’ll learn how to analyze spatial data in R by performing a series of tasks. You’ll start by importing geospatial data using the sf package and CSV files with the readr package. Next, you’ll combine these datasets through relational joins using dplyr. You’ll then compute spatial weights with the spdep package to understand spatial relationships and calculate spatially lagged variables, which reflect the influence of neighboring observations. This process will enhance your ability to manage and analyze spatial data, providing insights into spatial dependencies and patterns."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#exercise-overview",
    "href": "Hands-on_Ex/Hands-on_ex05.html#exercise-overview",
    "title": "Spatial Weights and Applications",
    "section": "",
    "text": "In this hands-on exercise, you’ll learn how to analyze spatial data in R by performing a series of tasks. You’ll start by importing geospatial data using the sf package and CSV files with the readr package. Next, you’ll combine these datasets through relational joins using dplyr. You’ll then compute spatial weights with the spdep package to understand spatial relationships and calculate spatially lagged variables, which reflect the influence of neighboring observations. This process will enhance your ability to manage and analyze spatial data, providing insights into spatial dependencies and patterns."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#data-acquisition",
    "href": "Hands-on_Ex/Hands-on_ex05.html#data-acquisition",
    "title": "Spatial Weights and Applications",
    "section": "5.2 Data Acquisition",
    "text": "5.2 Data Acquisition\nTwo data sets will be used in this hands-on exercise, they are:\n\nHunan county boundary layer. This is a geospatial data set in ESRI shapefile format.\nHunan_2012.csv: This csv file contains selected Hunan’s local development indicators in 2012."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_ex05.html#getting-started",
    "title": "Spatial Weights and Applications",
    "section": "5.3 Getting Started",
    "text": "5.3 Getting Started\nFor this exercise, we will use the following 5 R packages:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nspdep, an R package focused on spatial dependence and spatial econometrics. It includes functions for computing spatial weights, neighborhood structures, and spatially lagged variables, which are crucial for understanding spatial relationships in data.\nknitr, an R package that enables dynamic report generation. It integrates R code with Markdown or LaTeX to create reproducible documents, which is useful for documenting and sharing your analysis workflows.\ntidyverse, a collection of R packages designed for data science. It includes packages like dplyr for data manipulation, ggplot2 for data visualization, and tidyr for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.\n\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#importing-data-into-r",
    "href": "Hands-on_Ex/Hands-on_ex05.html#importing-data-into-r",
    "title": "Spatial Weights and Applications",
    "section": "5.4 Importing Data into R",
    "text": "5.4 Importing Data into R\nIn this section, you will learn how to bring a geospatial data and its associated attribute table into R environment. The geospatial data is in ESRI shapefile format and the attribute table is in csv format.\n\n5.4.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan &lt;- st_read(dsn = \"data/Hands-on_Ex05/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\Hands-on_Ex05\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n5.4.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/Hands-on_Ex05/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n5.4.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan,hunan2012, join_by(County))%&gt;%\n  select(1:4, 7, 15)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#visualising-regional-development-indicator",
    "href": "Hands-on_Ex/Hands-on_ex05.html#visualising-regional-development-indicator",
    "title": "Spatial Weights and Applications",
    "section": "5.5 Visualising Regional Development Indicator",
    "text": "5.5 Visualising Regional Development Indicator\nNow, we are going to prepare a basemap and a choropleth map showing the distribution of GDPPC 2012 by using qtm() of tmap package.\n\nbasemap &lt;- tm_shape(hunan) +\n  tm_polygons() +\n  tm_text(\"NAME_3\", size=0.4)\n\ngdppc1 &lt;- qtm(hunan, \"GDPPC\", fill.palette = \"viridis\")\ntmap_arrange(basemap, gdppc1, asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#computing-contiguity-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_ex05.html#computing-contiguity-spatial-weights",
    "title": "Spatial Weights and Applications",
    "section": "5.6 Computing Contiguity Spatial Weights",
    "text": "5.6 Computing Contiguity Spatial Weights\nIn this section, you will learn how to use poly2nb() of spdep package to compute contiguity weight matrices for the study area. This function builds a neighbours list based on regions with contiguous boundaries. If you look at the documentation you will see that you can pass a “queen” argument that takes TRUE or FALSE as options. If you do not specify this argument the default is set to TRUE, that is, if you don’t specify queen = FALSE this function will return a list of first order neighbours using the Queen criteria.\n\n5.6.1 Computing (QUEEN) contiguity based neighbours\nThe code chunk below is used to compute Queen contiguity weight matrix.\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nThe output reveals that Polygon ID = 1 is Anxiang county.\nTo reveal the county names of the five neighboring polygons, the code chunk will be used:\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\n\nWe can retrieve the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\nThe printed output above shows that the GDPPC of the five nearest neighbours based on Queen’s method are 20981, 34592, 24473, 21311 and 22879 respectively.\nYou can display the complete weight matrix by using str().\n\nstr(wm_q)\n\nList of 88\n $ : int [1:5] 2 3 4 57 85\n $ : int [1:5] 1 57 58 78 85\n $ : int [1:4] 1 4 5 85\n $ : int [1:4] 1 3 5 6\n $ : int [1:4] 3 4 6 85\n $ : int [1:5] 4 5 69 75 85\n $ : int [1:4] 67 71 74 84\n $ : int [1:7] 9 46 47 56 78 80 86\n $ : int [1:6] 8 66 68 78 84 86\n $ : int [1:8] 16 17 19 20 22 70 72 73\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:3] 11 15 17\n $ : int [1:4] 13 14 17 83\n $ : int [1:5] 10 17 22 72 83\n $ : int [1:7] 10 11 14 15 16 72 83\n $ : int [1:5] 20 22 23 77 83\n $ : int [1:6] 10 20 21 73 74 86\n $ : int [1:7] 10 18 19 21 22 23 82\n $ : int [1:5] 19 20 35 82 86\n $ : int [1:5] 10 16 18 20 83\n $ : int [1:7] 18 20 38 41 77 79 82\n $ : int [1:5] 25 28 31 32 54\n $ : int [1:5] 24 28 31 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:3] 26 29 42\n $ : int [1:5] 24 25 33 49 54\n $ : int [1:3] 27 37 42\n $ : int 33\n $ : int [1:8] 24 25 32 36 39 40 56 81\n $ : int [1:8] 24 31 50 54 55 56 75 85\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 47 80 82 86\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:4] 29 42 43 44\n $ : int [1:4] 23 44 77 79\n $ : int [1:5] 31 40 42 43 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:7] 26 27 29 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:4] 37 38 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:3] 8 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:5] 32 48 52 54 55\n $ : int [1:3] 48 49 52\n $ : int [1:5] 48 49 50 51 54\n $ : int [1:3] 48 55 75\n $ : int [1:6] 24 28 32 49 50 52\n $ : int [1:5] 32 48 50 53 75\n $ : int [1:7] 8 31 32 36 78 80 85\n $ : int [1:6] 1 2 58 64 76 85\n $ : int [1:5] 2 57 68 76 78\n $ : int [1:4] 60 61 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:7] 12 59 60 62 63 77 87\n $ : int [1:3] 61 77 87\n $ : int [1:4] 12 61 77 83\n $ : int [1:2] 57 76\n $ : int 76\n $ : int [1:5] 9 67 68 76 84\n $ : int [1:4] 7 66 76 84\n $ : int [1:5] 9 58 66 76 78\n $ : int [1:3] 6 75 85\n $ : int [1:3] 10 72 73\n $ : int [1:3] 7 73 74\n $ : int [1:5] 10 11 16 17 70\n $ : int [1:5] 10 19 70 71 74\n $ : int [1:6] 7 19 71 73 84 86\n $ : int [1:6] 6 32 53 55 69 85\n $ : int [1:7] 57 58 64 65 66 67 68\n $ : int [1:7] 18 23 38 61 62 63 83\n $ : int [1:7] 2 8 9 56 58 68 85\n $ : int [1:7] 23 38 40 41 43 44 45\n $ : int [1:8] 8 34 35 36 41 45 47 56\n $ : int [1:6] 25 26 31 33 39 42\n $ : int [1:5] 20 21 23 35 41\n $ : int [1:9] 12 13 15 16 17 18 22 63 77\n $ : int [1:6] 7 9 66 67 74 86\n $ : int [1:11] 1 2 3 5 6 32 56 57 69 75 ...\n $ : int [1:9] 8 9 19 21 35 46 47 74 84\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language poly2nb(pl = hunan, queen = TRUE)\n - attr(*, \"type\")= chr \"queen\"\n - attr(*, \"sym\")= logi TRUE\n\n\nBe warned: The output might cut across several pages. Save the trees if you are going to print out the report.\n\n\n5.6.2 Creating (ROOK) contiguity based neighbours\nThe code chunk below is used to compute Rook contiguity weight matrix.\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connect area unit has 10 neighbours. There are two area units with only one heighbours.\n\n\n5.6.3 Visualising contiguity weights\nA connectivity graph takes a point and displays a line to each neighboring point. We are working with polygons at the moment, so we will need to get points in order to make our connectivity graphs. The most typically method for this will be polygon centroids. We will calculate these in the sf package before moving onto the graphs. Getting Latitude and Longitude of Polygon Centroids\nWe will need points to associate with each polygon before we can make our connectivity graph. It will be a little more complicated than just running st_centroid on the sf object: us.bound. We need the coordinates in a separate data frame for this to work. To do this we will use a mapping function. The mapping function applies a given function to each element of a vector and returns a vector of the same length. Our input vector will be the geometry column of us.bound. Our function will be st_centroid. We will be using map_dbl variation of map from the purrr package. For more documentation, check out map documentation\nTo get our longitude values we map the st_centroid function over the geometry column of us.bound and access the longitude value through double bracket notation [[]] and 1. This allows us to get only the longitude, which is the first value in each centroid.\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\n\nWe do the same for latitude with one key difference. We access the second value per each centroid with [[2]].\n\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\n\nNow that we have latitude and longitude, we use cbind to put longitude and latitude into the same object.\n\ncoords &lt;- cbind(longitude, latitude)\n\nWe check the first few observations to see if things are formatted correctly.\n\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\n\n\n5.6.3.1 Plotting Queen contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n5.6.3.2 Plotting Rook contiguity based neighbours map\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\n\n\n\n\n\n5.6.3.3 Plotting both Queen and Rook contiguity based neighbours maps\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#computing-distance-based-neighbours",
    "href": "Hands-on_Ex/Hands-on_ex05.html#computing-distance-based-neighbours",
    "title": "Spatial Weights and Applications",
    "section": "5.7 Computing distance based neighbours",
    "text": "5.7 Computing distance based neighbours\nIn this section, you will learn how to derive distance-based weight matrices by using dnearneigh() of spdep package.\nThe function identifies neighbours of region points by Euclidean distance with a distance band with lower d1= and upper d2= bounds controlled by the bounds= argument. If unprojected coordinates are used and either specified in the coordinates object x or with x as a two column matrix and longlat=TRUE, great circle distances in km will be calculated assuming the WGS84 reference ellipsoid.\n\n5.7.1 Determine the cut-off distance\nFirstly, we need to determine the upper limit for distance band by using the steps below:\n\nReturn a matrix with the indices of points belonging to the set of the k nearest neighbours of each other by using knearneigh() of spdep.\nConvert the knn object returned by knearneigh() into a neighbours list of class nb with a list of integer vectors containing neighbour region number ids by using knn2nb().\nReturn the length of neighbour relationship edges by using nbdists() of spdep. The function returns in the units of the coordinates if the coordinates are projected, in km otherwise.\nRemove the list structure of the returned object by using unlist().\n\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\nThe summary report shows that the largest first nearest neighbour distance is 61.79 km, so using this as the upper threshold gives certainty that all units will have at least one neighbour.\n\n\n5.7.2 Computing fixed distance weight matrix\nNow, we will compute the distance weight matrix by using dnearneigh() as shown in the code chunk below.\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\n\n\n\n\n\n\nReflection\n\n\n\nOn average, each region has about 3.68 neighbors within a 62 km distance. This value is calculated by dividing the total number of links (324) by the total number of regions (88). The links represent spatial connections between regions based on proximity.\n\n\nNext, we will use str() to display the content of wm_d62 weight matrix.\n\nstr(wm_d62)\n\nList of 88\n $ : int [1:5] 3 4 5 57 64\n $ : int [1:4] 57 58 78 85\n $ : int [1:4] 1 4 5 57\n $ : int [1:3] 1 3 5\n $ : int [1:4] 1 3 4 85\n $ : int 69\n $ : int [1:2] 67 84\n $ : int [1:4] 9 46 47 78\n $ : int [1:4] 8 46 68 84\n $ : int [1:4] 16 22 70 72\n $ : int [1:3] 14 17 72\n $ : int [1:5] 13 60 61 63 83\n $ : int [1:4] 12 15 60 83\n $ : int [1:2] 11 17\n $ : int 13\n $ : int [1:4] 10 17 22 83\n $ : int [1:3] 11 14 16\n $ : int [1:3] 20 22 63\n $ : int [1:5] 20 21 73 74 82\n $ : int [1:5] 18 19 21 22 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:4] 10 16 18 20\n $ : int [1:3] 41 77 82\n $ : int [1:4] 25 28 31 54\n $ : int [1:4] 24 28 33 81\n $ : int [1:4] 27 33 42 81\n $ : int [1:2] 26 29\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:2] 27 37\n $ : int 33\n $ : int [1:2] 24 36\n $ : int 50\n $ : int [1:5] 25 26 28 30 81\n $ : int [1:3] 36 45 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:5] 31 34 45 56 80\n $ : int [1:2] 29 42\n $ : int [1:3] 44 77 79\n $ : int [1:4] 40 42 43 81\n $ : int [1:3] 39 45 79\n $ : int [1:5] 23 35 45 79 82\n $ : int [1:5] 26 37 39 43 81\n $ : int [1:3] 39 42 44\n $ : int [1:2] 38 43\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:5] 8 9 35 47 86\n $ : int [1:5] 8 35 46 80 86\n $ : int [1:5] 50 51 52 53 55\n $ : int [1:4] 28 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:4] 48 49 50 52\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:2] 48 55\n $ : int [1:5] 24 28 49 50 52\n $ : int [1:4] 48 50 53 75\n $ : int 36\n $ : int [1:5] 1 2 3 58 64\n $ : int [1:5] 2 57 64 66 68\n $ : int [1:3] 60 87 88\n $ : int [1:4] 12 13 59 61\n $ : int [1:5] 12 60 62 63 87\n $ : int [1:4] 61 63 77 87\n $ : int [1:5] 12 18 61 62 83\n $ : int [1:4] 1 57 58 76\n $ : int 76\n $ : int [1:5] 58 67 68 76 84\n $ : int [1:2] 7 66\n $ : int [1:4] 9 58 66 84\n $ : int [1:2] 6 75\n $ : int [1:3] 10 72 73\n $ : int [1:2] 73 74\n $ : int [1:3] 10 11 70\n $ : int [1:4] 19 70 71 74\n $ : int [1:5] 19 21 71 73 86\n $ : int [1:2] 55 69\n $ : int [1:3] 64 65 66\n $ : int [1:3] 23 38 62\n $ : int [1:2] 2 8\n $ : int [1:4] 38 40 41 45\n $ : int [1:5] 34 35 36 45 47\n $ : int [1:5] 25 26 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:4] 12 13 16 63\n $ : int [1:4] 7 9 66 68\n $ : int [1:2] 2 5\n $ : int [1:4] 21 46 47 74\n $ : int [1:4] 59 61 62 88\n $ : int [1:2] 59 87\n - attr(*, \"class\")= chr \"nb\"\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language dnearneigh(x = coords, d1 = 0, d2 = 62, longlat = TRUE)\n - attr(*, \"dnn\")= num [1:2] 0 62\n - attr(*, \"bounds\")= chr [1:2] \"GE\" \"LE\"\n - attr(*, \"nbtype\")= chr \"distance\"\n - attr(*, \"sym\")= logi TRUE\n\n\nAnother way to display the structure of the weight matrix is to combine table() and card() of spdep.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nn_comp &lt;- n.comp.nb(wm_d62)\nn_comp$nc\n\n[1] 1\n\n\n\ntable(n_comp$comp.id)\n\n\n 1 \n88 \n\n\n\n5.7.2.1 Plotting fixed distance weight matrix\nNext, we will plot the distance weight matrix by using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\n\n\n\nThe red lines show the links of 1st nearest neighbours and the black lines show the links of neighbours within the cut-off distance of 62km.\nAlternatively, we can plot both of them next to each other by using the code chunk below.\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n\n5.7.3 omputing adaptive distance weight matrix\nOne of the characteristics of fixed distance weight matrix is that more densely settled areas (usually the urban areas) tend to have more neighbours and the less densely settled areas (usually the rural counties) tend to have lesser neighbours. Having many neighbours smoothe the neighbour relationship across more neighbours.\nIt is possible to control the numbers of neighbours directly using k-nearest neighbours, either accepting asymmetric neighbours or imposing symmetry as shown in the code chunk below.\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\n\nSimilarly, we can display the content of the matrix by using str().\n\nstr(knn6)\n\nList of 88\n $ : int [1:6] 2 3 4 5 57 64\n $ : int [1:6] 1 3 57 58 78 85\n $ : int [1:6] 1 2 4 5 57 85\n $ : int [1:6] 1 3 5 6 69 85\n $ : int [1:6] 1 3 4 6 69 85\n $ : int [1:6] 3 4 5 69 75 85\n $ : int [1:6] 9 66 67 71 74 84\n $ : int [1:6] 9 46 47 78 80 86\n $ : int [1:6] 8 46 66 68 84 86\n $ : int [1:6] 16 19 22 70 72 73\n $ : int [1:6] 10 14 16 17 70 72\n $ : int [1:6] 13 15 60 61 63 83\n $ : int [1:6] 12 15 60 61 63 83\n $ : int [1:6] 11 15 16 17 72 83\n $ : int [1:6] 12 13 14 17 60 83\n $ : int [1:6] 10 11 17 22 72 83\n $ : int [1:6] 10 11 14 16 72 83\n $ : int [1:6] 20 22 23 63 77 83\n $ : int [1:6] 10 20 21 73 74 82\n $ : int [1:6] 18 19 21 22 23 82\n $ : int [1:6] 19 20 35 74 82 86\n $ : int [1:6] 10 16 18 19 20 83\n $ : int [1:6] 18 20 41 77 79 82\n $ : int [1:6] 25 28 31 52 54 81\n $ : int [1:6] 24 28 31 33 54 81\n $ : int [1:6] 25 27 29 33 42 81\n $ : int [1:6] 26 29 30 37 42 81\n $ : int [1:6] 24 25 33 49 52 54\n $ : int [1:6] 26 27 37 42 43 81\n $ : int [1:6] 26 27 28 33 49 81\n $ : int [1:6] 24 25 36 39 40 54\n $ : int [1:6] 24 31 50 54 55 56\n $ : int [1:6] 25 26 28 30 49 81\n $ : int [1:6] 36 40 41 45 56 80\n $ : int [1:6] 21 41 46 47 80 82\n $ : int [1:6] 31 34 40 45 56 80\n $ : int [1:6] 26 27 29 42 43 44\n $ : int [1:6] 23 43 44 62 77 79\n $ : int [1:6] 25 40 42 43 44 81\n $ : int [1:6] 31 36 39 43 45 79\n $ : int [1:6] 23 35 45 79 80 82\n $ : int [1:6] 26 27 37 39 43 81\n $ : int [1:6] 37 39 40 42 44 79\n $ : int [1:6] 37 38 39 42 43 79\n $ : int [1:6] 34 36 40 41 79 80\n $ : int [1:6] 8 9 35 47 78 86\n $ : int [1:6] 8 21 35 46 80 86\n $ : int [1:6] 49 50 51 52 53 55\n $ : int [1:6] 28 33 48 51 52 54\n $ : int [1:6] 32 48 51 52 54 55\n $ : int [1:6] 28 48 49 50 52 54\n $ : int [1:6] 28 48 49 50 51 54\n $ : int [1:6] 48 50 51 52 55 75\n $ : int [1:6] 24 28 49 50 51 52\n $ : int [1:6] 32 48 50 52 53 75\n $ : int [1:6] 32 34 36 78 80 85\n $ : int [1:6] 1 2 3 58 64 68\n $ : int [1:6] 2 57 64 66 68 78\n $ : int [1:6] 12 13 60 61 87 88\n $ : int [1:6] 12 13 59 61 63 87\n $ : int [1:6] 12 13 60 62 63 87\n $ : int [1:6] 12 38 61 63 77 87\n $ : int [1:6] 12 18 60 61 62 83\n $ : int [1:6] 1 3 57 58 68 76\n $ : int [1:6] 58 64 66 67 68 76\n $ : int [1:6] 9 58 67 68 76 84\n $ : int [1:6] 7 65 66 68 76 84\n $ : int [1:6] 9 57 58 66 78 84\n $ : int [1:6] 4 5 6 32 75 85\n $ : int [1:6] 10 16 19 22 72 73\n $ : int [1:6] 7 19 73 74 84 86\n $ : int [1:6] 10 11 14 16 17 70\n $ : int [1:6] 10 19 21 70 71 74\n $ : int [1:6] 19 21 71 73 84 86\n $ : int [1:6] 6 32 50 53 55 69\n $ : int [1:6] 58 64 65 66 67 68\n $ : int [1:6] 18 23 38 61 62 63\n $ : int [1:6] 2 8 9 46 58 68\n $ : int [1:6] 38 40 41 43 44 45\n $ : int [1:6] 34 35 36 41 45 47\n $ : int [1:6] 25 26 28 33 39 42\n $ : int [1:6] 19 20 21 23 35 41\n $ : int [1:6] 12 13 15 16 22 63\n $ : int [1:6] 7 9 66 68 71 74\n $ : int [1:6] 2 3 4 5 56 69\n $ : int [1:6] 8 9 21 46 47 74\n $ : int [1:6] 59 60 61 62 63 88\n $ : int [1:6] 59 60 61 62 63 87\n - attr(*, \"region.id\")= chr [1:88] \"1\" \"2\" \"3\" \"4\" ...\n - attr(*, \"call\")= language knearneigh(x = coords, k = 6)\n - attr(*, \"sym\")= logi FALSE\n - attr(*, \"type\")= chr \"knn\"\n - attr(*, \"knn-k\")= num 6\n - attr(*, \"class\")= chr \"nb\"\n\n\nNotice that each county has six neighbours, no less no more!\n\n5.7.3.1 Plotting distance based neighbours\nWe can plot the weight matrix using the code chunk below.\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_ex05.html#weights-based-on-idw",
    "title": "Spatial Weights and Applications",
    "section": "5.8 Weights based on IDW",
    "text": "5.8 Weights based on IDW\nIn this section, you will learn how to derive a spatial weight matrix based on Inversed Distance method.\nFirst, we will compute the distances between areas by using nbdists() of spdep.\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_ex05.html#row-standardised-weights-matrix",
    "title": "Spatial Weights and Applications",
    "section": "5.9 Row-standardised Weights Matrix",
    "text": "5.9 Row-standardised Weights Matrix\nNext, we need to assign weights to each neighboring polygon. In our case, each neighboring polygon will be assigned equal weight (style=“W”). This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values. While this is the most intuitive way to summaries the neighbors’ values it has one drawback in that polygons along the edges of the study area will base their lagged values on fewer polygons thus potentially over- or under-estimating the true nature of the spatial autocorrelation in the data. For this example, we’ll stick with the style=\"W\" option for simplicity’s sake but note that other more robust options are available, notably style=“B”.\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\nThe zero.policy=TRUE option allows for lists of non-neighbors. This should be used with caution since the user may not be aware of missing neighbors in their dataset however, a zero.policy of FALSE would return an error.\nTo see the weight of the first polygon’s eight neighbors type:\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor’s income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_ex05.html#application-of-spatial-weight-matrix",
    "title": "Spatial Weights and Applications",
    "section": "5.10 Application of Spatial Weight Matrix",
    "text": "5.10 Application of Spatial Weight Matrix\nIn this section, you will learn how to create four different spatial lagged variables, they are:\n\nspatial lag with row-standardized weights,\nspatial lag as a sum of neighbouring values,\nspatial window average, and\nspatial window sum.\n\n\n5.10.1 Spatial lag with row-standardized weights\nFinally, we’ll compute the average neighbor GDPPC value for each polygon. These values are often referred to as spatially lagged values.\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\nRecalled in the previous section, we retrieved the GDPPC of these five countries by using the code chunk below.\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nQuestion: Can you see the meaning of Spatial lag with row-standardized weights now?\n\nWe can append the spatially lag GDPPC values onto hunan sf data frame by using the code chunk below.\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nThe following table shows the average neighboring income values (stored in the Inc.lag object) for each county.\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\nNext, we will plot both the GDPPC and spatial lag GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\", fill.palette = \"plasma\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n5.10.2 Spatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use the glist parameter in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\n\nQuestion: Can you understand the meaning of Spatial lag as a sum of neighboring values now?\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\ngdppc &lt;- qtm(hunan, \"GDPPC\", fill.palette = \"plasma\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n5.10.3 Spatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\n\n\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more effective comparison, it is advisable to use the core tmap mapping functions.\n\n\n\n\n5.10.4 Spatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\n\n\n\n\n\n\n\nNote\n\n\n\nThe second command line on the code chunk above renames the field names of w_sum_gdppc.res object into NAME_3 and w_sum GDPPC respectively.\n\n\nNext, the code chunk below will be used to append w_sum GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_sum GDPPC and w_sum_gdppc maps next to each other for quick comparison.\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\", fill.palette = \"plasma\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nFor more effective comparison, it is advisable to use the core tmap mapping functions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_ex05.html#references",
    "href": "Hands-on_Ex/Hands-on_ex05.html#references",
    "title": "Spatial Weights and Applications",
    "section": "5.11 References",
    "text": "5.11 References\n\nCreating Neighbours using sf objects"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html",
    "href": "Hands-on_Ex/Hands-on_Ex09.html",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, you will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#overview",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "",
    "text": "In this hands-on exercise, you will gain hands-on experience on how to delineate homogeneous region by using geographically referenced multivariate data. There are two major analysis, namely:\n\nhierarchical cluster analysis; and\nspatially constrained cluster analysis.\n\n\n\nBy the end of this hands-on exercise, you will able:\n\nto convert GIS polygon data into R’s simple feature data.frame by using appropriate functions of sf package of R;\nto convert simple feature data.frame into R’s SpatialPolygonDataFrame object by using appropriate sf of package of R;\nto perform custer analysis by using hclust() of Base R;\nto perform spatially constrained cluster analysis using skater() of Base R; and\nto visualise the analysis output by using ggplot2 and tmap package."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#getting-started",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.2 Getting Started",
    "text": "9.2 Getting Started\n\n9.2.1 The analytical question\nIn geobusiness and spatial policy, it is a common practice to delineate the market or planning area into homogeneous regions by using multivariate data. In this hands-on exercise, we are interested to delineate Shan State, Myanmar into homogeneous regions by using multiple Information and Communication technology (ICT) measures, namely: Radio, Television, Land line phone, Mobile phone, Computer, and Internet at home."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#the-data",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.3 The data",
    "text": "9.3 The data\nTwo data sets will be used in this study. They are:\n\nMyanmar Township Boundary Data (i.e. myanmar_township_boundaries) : This is a GIS data in ESRI shapefile format. It consists of township boundary information of Myanmar. The spatial data are captured in polygon features.\nShan-ICT.csv: This is an extract of The 2014 Myanmar Population and Housing Census Myanmar at the township level.\n\nBoth data sets are download from Myanmar Information Management Unit (MIMU)\n\n9.3.1 Installing and loading R packages\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nSpatial data handling\n\nsf, rgdal and spdep\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\nMultivariate data visualisation and analysis\n\ncoorplot, ggpubr, and heatmaply\n\nCluster analysis\n\ncluster\nClustGeo\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(spdep, tmap, sf, ClustGeo, \n               ggpubr, cluster, factoextra, NbClust,\n               heatmaply, corrplot, psych, tidyverse, GGally)\n\nNote: With tidyverse, we do not have to install readr, ggplot2 and dplyr packages separately. In fact, tidyverse also installs other very useful R packages such as tidyr."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#data-import-and-prepatation",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#data-import-and-prepatation",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.4 Data Import and Prepatation",
    "text": "9.4 Data Import and Prepatation\n\n9.4.1 Importing geospatial data into R environment\nIn this section, you will import Myanmar Township Boundary GIS data and its associated attrbiute table into R environment.\nThe Myanmar Township Boundary GIS data is in ESRI shapefile format. It will be imported into R environment by using the st_read() function of sf.\nThe code chunks used are shown below:\n\nshan_sf &lt;- st_read(dsn = \"data/Hands-on_Ex09/geospatial\", \n                   layer = \"myanmar_township_boundaries\") %&gt;%\n  filter(ST %in% c(\"Shan (East)\", \"Shan (North)\", \"Shan (South)\")) %&gt;%\n  select(c(2:7))\n\nReading layer `myanmar_township_boundaries' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\Hands-on_Ex09\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 330 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 92.17275 ymin: 9.671252 xmax: 101.1699 ymax: 28.54554\nGeodetic CRS:  WGS 84\n\n\nThe imported township boundary object is called shan_sf. It is saved in simple feature data.frame format. We can view the content of the newly created shan_sf simple features data.frame by using the code chunk below.\n\nshan_sf\n\nSimple feature collection with 55 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 96.15107 ymin: 19.29932 xmax: 101.1699 ymax: 24.15907\nGeodetic CRS:  WGS 84\nFirst 10 features:\n             ST ST_PCODE       DT   DT_PCODE        TS  TS_PCODE\n1  Shan (North)   MMR015  Mongmit MMR015D008   Mongmit MMR015017\n2  Shan (South)   MMR014 Taunggyi MMR014D001   Pindaya MMR014006\n3  Shan (South)   MMR014 Taunggyi MMR014D001   Ywangan MMR014007\n4  Shan (South)   MMR014 Taunggyi MMR014D001  Pinlaung MMR014009\n5  Shan (North)   MMR015  Mongmit MMR015D008    Mabein MMR015018\n6  Shan (South)   MMR014 Taunggyi MMR014D001     Kalaw MMR014005\n7  Shan (South)   MMR014 Taunggyi MMR014D001     Pekon MMR014010\n8  Shan (South)   MMR014 Taunggyi MMR014D001  Lawksawk MMR014008\n9  Shan (North)   MMR015  Kyaukme MMR015D003 Nawnghkio MMR015013\n10 Shan (North)   MMR015  Kyaukme MMR015D003   Kyaukme MMR015012\n                         geometry\n1  MULTIPOLYGON (((96.96001 23...\n2  MULTIPOLYGON (((96.7731 21....\n3  MULTIPOLYGON (((96.78483 21...\n4  MULTIPOLYGON (((96.49518 20...\n5  MULTIPOLYGON (((96.66306 24...\n6  MULTIPOLYGON (((96.49518 20...\n7  MULTIPOLYGON (((97.14738 19...\n8  MULTIPOLYGON (((96.94981 22...\n9  MULTIPOLYGON (((96.75648 22...\n10 MULTIPOLYGON (((96.95498 22...\n\n\nNotice that sf.data.frame is conformed to Hardy Wickham’s tidy framework.\nSince shan_sf is conformed to tidy framework, we can also glimpse() to reveal the data type of it’s fields.\n\nglimpse(shan_sf)\n\nRows: 55\nColumns: 7\n$ ST       &lt;chr&gt; \"Shan (North)\", \"Shan (South)\", \"Shan (South)\", \"Shan (South)…\n$ ST_PCODE &lt;chr&gt; \"MMR015\", \"MMR014\", \"MMR014\", \"MMR014\", \"MMR015\", \"MMR014\", \"…\n$ DT       &lt;chr&gt; \"Mongmit\", \"Taunggyi\", \"Taunggyi\", \"Taunggyi\", \"Mongmit\", \"Ta…\n$ DT_PCODE &lt;chr&gt; \"MMR015D008\", \"MMR014D001\", \"MMR014D001\", \"MMR014D001\", \"MMR0…\n$ TS       &lt;chr&gt; \"Mongmit\", \"Pindaya\", \"Ywangan\", \"Pinlaung\", \"Mabein\", \"Kalaw…\n$ TS_PCODE &lt;chr&gt; \"MMR015017\", \"MMR014006\", \"MMR014007\", \"MMR014009\", \"MMR01501…\n$ geometry &lt;MULTIPOLYGON [°]&gt; MULTIPOLYGON (((96.96001 23..., MULTIPOLYGON (((…\n\n\n\n\n9.4.2 Importing aspatial data into R environment\nThe csv file will be import using read_csv function of readr package.\nThe code chunks used are shown below:\n\nict &lt;- read_csv (\"data/Hands-on_Ex09/aspatial/Shan-ICT.csv\")\n\nThe imported InfoComm variables are extracted from The 2014 Myanmar Population and Housing Census Myanmar. The attribute data set is called ict. It is saved in R’s * tibble data.frame* format.\nThe code chunk below reveal the summary statistics of ict data.frame.\n\nsummary(ict)\n\n District Pcode     District Name      Township Pcode     Township Name     \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n Total households     Radio         Television    Land line phone \n Min.   : 3318    Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711    1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685    Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369    Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471    3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604    Max.   :30176   Max.   :62388   Max.   :6736.0  \n  Mobile phone      Computer      Internet at home\n Min.   :  150   Min.   :  20.0   Min.   :   8.0  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0  \n Median : 3559   Median : 244.0   Median : 316.0  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0  \n\n\nThere are a total of eleven fields and 55 observation in the tibble data.frame.\n\n\n9.4.3 Derive new variables using dplyr package\nThe unit of measurement of the values are number of household. Using these values directly will be bias by the underlying total number of households. In general, the townships with relatively higher total number of households will also have higher number of households owning radio, TV, etc.\nIn order to overcome this problem, we will derive the penetration rate of each ICT variable by using the code chunk below.\n\nict_derived &lt;- ict %&gt;%\n  mutate(`RADIO_PR` = `Radio`/`Total households`*1000) %&gt;%\n  mutate(`TV_PR` = `Television`/`Total households`*1000) %&gt;%\n  mutate(`LLPHONE_PR` = `Land line phone`/`Total households`*1000) %&gt;%\n  mutate(`MPHONE_PR` = `Mobile phone`/`Total households`*1000) %&gt;%\n  mutate(`COMPUTER_PR` = `Computer`/`Total households`*1000) %&gt;%\n  mutate(`INTERNET_PR` = `Internet at home`/`Total households`*1000) %&gt;%\n  rename(`DT_PCODE` =`District Pcode`,`DT`=`District Name`,\n         `TS_PCODE`=`Township Pcode`, `TS`=`Township Name`,\n         `TT_HOUSEHOLDS`=`Total households`,\n         `RADIO`=`Radio`, `TV`=`Television`, \n         `LLPHONE`=`Land line phone`, `MPHONE`=`Mobile phone`,\n         `COMPUTER`=`Computer`, `INTERNET`=`Internet at home`) \n\nLet us review the summary statistics of the newly derived penetration rates using the code chunk below.\n\nsummary(ict_derived)\n\n   DT_PCODE              DT              TS_PCODE              TS           \n Length:55          Length:55          Length:55          Length:55         \n Class :character   Class :character   Class :character   Class :character  \n Mode  :character   Mode  :character   Mode  :character   Mode  :character  \n                                                                            \n                                                                            \n                                                                            \n TT_HOUSEHOLDS       RADIO             TV           LLPHONE      \n Min.   : 3318   Min.   :  115   Min.   :  728   Min.   :  20.0  \n 1st Qu.: 8711   1st Qu.: 1260   1st Qu.: 3744   1st Qu.: 266.5  \n Median :13685   Median : 2497   Median : 6117   Median : 695.0  \n Mean   :18369   Mean   : 4487   Mean   :10183   Mean   : 929.9  \n 3rd Qu.:23471   3rd Qu.: 6192   3rd Qu.:13906   3rd Qu.:1082.5  \n Max.   :82604   Max.   :30176   Max.   :62388   Max.   :6736.0  \n     MPHONE         COMPUTER         INTERNET         RADIO_PR     \n Min.   :  150   Min.   :  20.0   Min.   :   8.0   Min.   : 21.05  \n 1st Qu.: 2037   1st Qu.: 121.0   1st Qu.:  88.0   1st Qu.:138.95  \n Median : 3559   Median : 244.0   Median : 316.0   Median :210.95  \n Mean   : 6470   Mean   : 575.5   Mean   : 760.2   Mean   :215.68  \n 3rd Qu.: 7177   3rd Qu.: 507.0   3rd Qu.: 630.5   3rd Qu.:268.07  \n Max.   :48461   Max.   :6705.0   Max.   :9746.0   Max.   :484.52  \n     TV_PR         LLPHONE_PR       MPHONE_PR       COMPUTER_PR    \n Min.   :116.0   Min.   :  2.78   Min.   : 36.42   Min.   : 3.278  \n 1st Qu.:450.2   1st Qu.: 22.84   1st Qu.:190.14   1st Qu.:11.832  \n Median :517.2   Median : 37.59   Median :305.27   Median :18.970  \n Mean   :509.5   Mean   : 51.09   Mean   :314.05   Mean   :24.393  \n 3rd Qu.:606.4   3rd Qu.: 69.72   3rd Qu.:428.43   3rd Qu.:29.897  \n Max.   :842.5   Max.   :181.49   Max.   :735.43   Max.   :92.402  \n  INTERNET_PR     \n Min.   :  1.041  \n 1st Qu.:  8.617  \n Median : 22.829  \n Mean   : 30.644  \n 3rd Qu.: 41.281  \n Max.   :117.985  \n\n\nNotice that six new fields have been added into the data.frame. They are RADIO_PR, TV_PR, LLPHONE_PR, MPHONE_PR, COMPUTER_PR, and INTERNET_PR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#exploratory-data-analysis-eda",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.5 Exploratory Data Analysis (EDA)",
    "text": "9.5 Exploratory Data Analysis (EDA)\n\n9.5.1 EDA using statistical graphics\nWe can plot the distribution of the variables (i.e. Number of households with radio) by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\nHistogram is useful to identify the overall distribution of the data values (i.e. left skew, right skew or normal distribution)\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\nBoxplot is useful to detect if there are outliers.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nNext, we will also plotting the distribution of the newly derived variables (i.e. Radio penetration rate) by using the code chunk below.\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\n\n\n\n\n\n\n\n\nggplot(data=ict_derived, \n       aes(x=`RADIO_PR`)) +\n  geom_boxplot(color=\"black\", \n               fill=\"light blue\")\n\n\n\n\n\n\n\n\nWhat can you observed from the distributions reveal in the histogram and boxplot.\nIn the figure below, multiple histograms are plotted to reveal the distribution of the selected variables in the ict_derived data.frame.\n\n\n\n\n\n\n\n\n\nThe code chunks below are used to create the data visualisation. They consist of two main parts. First, we will create the individual histograms using the code chunk below.\n\nradio &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ntv &lt;- ggplot(data=ict_derived, \n             aes(x= `TV_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nllphone &lt;- ggplot(data=ict_derived, \n             aes(x= `LLPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nmphone &lt;- ggplot(data=ict_derived, \n             aes(x= `MPHONE_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ncomputer &lt;- ggplot(data=ict_derived, \n             aes(x= `COMPUTER_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\ninternet &lt;- ggplot(data=ict_derived, \n             aes(x= `INTERNET_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\")\n\nNext, the ggarrange() function of ggpubr package is used to group these histograms together.\n\nggarrange(radio, tv, llphone, mphone, computer, internet, \n          ncol = 3, \n          nrow = 2)\n\n\n\n9.5.2 EDA using choropleth map\n\n9.5.2.1 Joining geospatial data with aspatial data\nBefore we can prepare the choropleth map, we need to combine both the geospatial data object (i.e. shan_sf) and aspatial data.frame object (i.e. ict_derived) into one. This will be performed by using the left_join function of dplyr package. The shan_sf simple feature data.frame will be used as the base data object and the ict_derived data.frame will be used as the join table.\nThe code chunks below is used to perform the task. The unique identifier used to join both data objects is TS_PCODE.\n\nshan_sf &lt;- left_join(shan_sf, \n                     ict_derived, by=c(\"TS_PCODE\"=\"TS_PCODE\"))\n  \nwrite_rds(shan_sf, \"data/Hands-on_Ex09/rds/shan_sf.rds\")\n\nThe message above shows that TS_CODE field is the common field used to perform the left-join.\nIt is important to note that there is no new output data been created. Instead, the data fields from ict_derived data frame are now updated into the data frame of shan_sf.\n\nshan_sf &lt;- read_rds(\"data/Hands-on_Ex09/rds/shan_sf.rds\")\n\n\n\n9.5.2.2 Preparing a choropleth map\nTo have a quick look at the distribution of Radio penetration rate of Shan State at township level, a choropleth map will be prepared.\nThe code chunks below are used to prepare the choroplethby using the qtm() function of tmap package.\n\nqtm(shan_sf, \"RADIO_PR\")\n\n\n\n\n\n\n\n\nIn order to reveal the distribution shown in the choropleth map above are bias to the underlying total number of households at the townships, we will create two choropleth maps, one for the total number of households (i.e. TT_HOUSEHOLDS.map) and one for the total number of household with Radio (RADIO.map) by using the code chunk below.\n\nTT_HOUSEHOLDS.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"TT_HOUSEHOLDS\",\n          n = 5,\n          style = \"jenks\", \n          title = \"Total households\") + \n  tm_borders(alpha = 0.5) \n\nRADIO.map &lt;- tm_shape(shan_sf) + \n  tm_fill(col = \"RADIO\",\n          n = 5,\n          style = \"jenks\",\n          title = \"Number Radio \") + \n  tm_borders(alpha = 0.5) \n\ntmap_arrange(TT_HOUSEHOLDS.map, RADIO.map,\n             asp=NA, ncol=2)\n\n\n\n\n\n\n\n\nNotice that the choropleth maps above clearly show that townships with relatively larger number of households are also showing relatively higher number of radio ownership.\nNow let us plot the choropleth maps showing the retribution of total number of households and Radio penetration rate by using the code chunk below.\n\ntm_shape(shan_sf) +\n    tm_polygons(c(\"TT_HOUSEHOLDS\", \"RADIO_PR\"),\n                style=\"jenks\") +\n    tm_facets(sync = TRUE, ncol = 2) +\n  tm_legend(legend.position = c(\"right\", \"bottom\"))+\n  tm_layout(outer.margins=0, asp=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nBias in Absolute Figures: If we only look at the left map, larger townships seem more relevant, but the right map (showing penetration rate) gives a more balanced view of radio accessibility.\nSpatial Patterns: The spatial distribution of radio penetration shows some concentration in specific areas that don’t always align with the largest household populations.\n\nThis comparison highlights how different metrics (total number of households vs. penetration rate) can reveal different insights into radio ownership across Shan State."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#correlation-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#correlation-analysis",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.6 Correlation Analysis",
    "text": "9.6 Correlation Analysis\nBefore we perform cluster analysis, it is important for us to ensure that the cluster variables are not highly correlated.\nIn this section, you will learn how to use corrplot.mixed() function of corrplot package to visualise and analyse the correlation of the input variables.\n\ncluster_vars.cor = cor(ict_derived[,12:17])\ncorrplot.mixed(cluster_vars.cor,\n         lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\n\n\n\nThe correlation plot above shows that COMPUTER_PR and INTERNET_PR are highly correlated. This suggest that only one of them should be used in the cluster analysis instead of both."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex09.html#hierarchy-cluster-analysis",
    "href": "Hands-on_Ex/Hands-on_Ex09.html#hierarchy-cluster-analysis",
    "title": "Geographical Segmentation with Spatially Constrained Clustering Techniques",
    "section": "9.7 Hierarchy Cluster Analysis",
    "text": "9.7 Hierarchy Cluster Analysis\nIn this section, you will learn how to perform hierarchical cluster analysis. The analysis consists of four major steps:\n\n9.7.1 Extracting clustering variables\nThe code chunk below will be used to extract the clustering variables from the shan_sf simple feature object into data.frame.\n\ncluster_vars &lt;- shan_sf %&gt;%\n  st_set_geometry(NULL) %&gt;%\n  select(\"TS.x\", \"RADIO_PR\", \"TV_PR\", \"LLPHONE_PR\", \"MPHONE_PR\", \"COMPUTER_PR\")\nhead(cluster_vars,10)\n\n        TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\n1    Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\n2    Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\n3    Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\n4   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\n5     Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\n6      Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\n7      Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\n8   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\n9  Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\n10   Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the final clustering variables list does not include variable INTERNET_PR because it is highly correlated with variable COMPUTER_PR.\nNext, we need to change the rows by township name instead of row number by using the code chunk below\n\nrow.names(cluster_vars) &lt;- cluster_vars$\"TS.x\"\nhead(cluster_vars,10)\n\n               TS.x RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit     Mongmit 286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya     Pindaya 417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan     Ywangan 484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung   Pinlaung 231.6499 541.7189   28.54454  249.4903    13.76255\nMabein       Mabein 449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw         Kalaw 280.7624 611.6204   42.06478  408.7951    29.63160\nPekon         Pekon 318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk   Lawksawk 387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio Nawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme     Kyaukme 210.9548 601.1773   39.58267  372.4930    30.94709\n\n\nNotice that the row number has been replaced into the township name.\nNow, we will delete the TS.x field by using the code chunk below.\n\nshan_ict &lt;- select(cluster_vars, c(2:6))\nhead(shan_ict, 10)\n\n          RADIO_PR    TV_PR LLPHONE_PR MPHONE_PR COMPUTER_PR\nMongmit   286.1852 554.1313   35.30618  260.6944    12.15939\nPindaya   417.4647 505.1300   19.83584  162.3917    12.88190\nYwangan   484.5215 260.5734   11.93591  120.2856     4.41465\nPinlaung  231.6499 541.7189   28.54454  249.4903    13.76255\nMabein    449.4903 708.6423   72.75255  392.6089    16.45042\nKalaw     280.7624 611.6204   42.06478  408.7951    29.63160\nPekon     318.6118 535.8494   39.83270  214.8476    18.97032\nLawksawk  387.1017 630.0035   31.51366  320.5686    21.76677\nNawnghkio 349.3359 547.9456   38.44960  323.0201    15.76465\nKyaukme   210.9548 601.1773   39.58267  372.4930    30.94709\n\n\n\nshan_ict &lt;- read_rds(\"data/Hands-on_Ex09/rds/shan_ict.rds\")\n\n\n\n9.7.2 Data Standardisation\nIn general, multiple variables will be used in cluster analysis. It is not unusual their values range are different. In order to avoid the cluster analysis result is baised to clustering variables with large values, it is useful to standardise the input variables before performing cluster analysis.\n\n\n9.7.2 Min-Max standardisation\nIn the code chunk below, normalize() of heatmaply package is used to stadardisation the clustering variables by using Min-Max method. The summary() is then used to display the summary statistics of the standardised clustering variables.\n\nshan_ict.std &lt;- normalize(shan_ict)\nsummary(shan_ict.std)\n\n    RADIO_PR          TV_PR          LLPHONE_PR       MPHONE_PR     \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.2544   1st Qu.:0.4600   1st Qu.:0.1123   1st Qu.:0.2199  \n Median :0.4097   Median :0.5523   Median :0.1948   Median :0.3846  \n Mean   :0.4199   Mean   :0.5416   Mean   :0.2703   Mean   :0.3972  \n 3rd Qu.:0.5330   3rd Qu.:0.6750   3rd Qu.:0.3746   3rd Qu.:0.5608  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n  COMPUTER_PR     \n Min.   :0.00000  \n 1st Qu.:0.09598  \n Median :0.17607  \n Mean   :0.23692  \n 3rd Qu.:0.29868  \n Max.   :1.00000  \n\n\nNotice that the values range of the Min-max standardised clustering variables are 0-1 now.\n\n\n9.7.3 Z-score standardisation\nZ-score standardisation can be performed easily by using scale() of Base R. The code chunk below will be used to stadardisation the clustering variables by using Z-score method.\n\nshan_ict.z &lt;- scale(shan_ict)\ndescribe(shan_ict.z)\n\n            vars  n mean sd median trimmed  mad   min  max range  skew kurtosis\nRADIO_PR       1 55    0  1  -0.04   -0.06 0.94 -1.85 2.55  4.40  0.48    -0.27\nTV_PR          2 55    0  1   0.05    0.04 0.78 -2.47 2.09  4.56 -0.38    -0.23\nLLPHONE_PR     3 55    0  1  -0.33   -0.15 0.68 -1.19 3.20  4.39  1.37     1.49\nMPHONE_PR      4 55    0  1  -0.05   -0.06 1.01 -1.58 2.40  3.98  0.48    -0.34\nCOMPUTER_PR    5 55    0  1  -0.26   -0.18 0.64 -1.03 3.31  4.34  1.80     2.96\n              se\nRADIO_PR    0.13\nTV_PR       0.13\nLLPHONE_PR  0.13\nMPHONE_PR   0.13\nCOMPUTER_PR 0.13\n\n\nNotice the mean and standard deviation of the Z-score standardised clustering variables are 0 and 1 respectively.\nNote: describe() of psych package is used here instead of summary() of Base R because the earlier provides standard deviation.\nWarning: Z-score standardisation method should only be used if we would assume all variables come from some normal distribution.\n\n\n9.7.4 Visualising the standardised clustering variables\nBeside reviewing the summary statistics of the standardised clustering variables, it is also a good practice to visualise their distribution graphical.\nThe code chunk below plot the scaled Radio_PR field.\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights\n\n\n\n\nRight-Skewed Distribution: In all three histograms, the distribution of RADIO_PR is right-skewed, meaning that while most townships have moderate levels of radio penetration, there are some townships with significantly higher rates.\nNormalization Effects: Both the Min-Max and Z-score standardizations effectively rescale the data, making it easier to analyze and compare across different variables, while maintaining the underlying distribution’s shape.\nUtility of Z-score: Z-score standardization can be particularly useful for identifying outliers and extreme values, as it highlights how far specific data points deviate from the mean in terms of standard deviations.\n\nThis analysis shows that while radio penetration is unevenly distributed, standardization techniques allow us to better understand and compare the values, especially in the context of clustering or further statistical analyses.\n\n\n\nr &lt;- ggplot(data=ict_derived, \n             aes(x= `RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Raw values without standardisation\")\n\nshan_ict_s_df &lt;- as.data.frame(shan_ict.std)\ns &lt;- ggplot(data=shan_ict_s_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Min-Max Standardisation\")\n\nshan_ict_z_df &lt;- as.data.frame(shan_ict.z)\nz &lt;- ggplot(data=shan_ict_z_df, \n       aes(x=`RADIO_PR`)) +\n  geom_density(color=\"black\",\n               fill=\"light blue\") +\n  ggtitle(\"Z-score Standardisation\")\n\nggarrange(r, s, z,\n          ncol = 3,\n          nrow = 1)\n\n\n\n\n\n\n\n\n\n\n9.7.5 Computing proximity matrix\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = 'euclidean')\n\nThe code chunk below can then be used to list the content of proxmat for visual inspection.\n\nproxmat\n\n\n\n9.7.6 Computing hierarchical clustering\nIn R, there are several packages provide hierarchical clustering function. In this hands-on exercise, hclust() of R stats will be used.\nhclust() employed agglomeration method to compute the cluster. Eight clustering algorithms are supported, they are: ward.D, ward.D2, single, complete, average(UPGMA), mcquitty(WPGMA), median(WPGMC) and centroid(UPGMC).\nThe code chunk below performs hierarchical cluster analysis using ward.D method. The hierarchical clustering output is stored in an object of class hclust which describes the tree produced by the clustering process.\n\nhclust_ward &lt;- hclust(proxmat, method = 'ward.D')\n\nWe can then plot the tree by using plot() of R Graphics as shown in the code chunk below.\n\nplot(hclust_ward, cex = 0.6)\n\n\n\n\n\n\n\n\n\n\n9.7.7 Selecting the optimal clustering algorithm\nOne of the challenge in performing hierarchical clustering is to identify stronger clustering structures. The issue can be solved by using use agnes() function of cluster package. It functions like hclus(), however, with the agnes() function you can also get the agglomerative coefficient, which measures the amount of clustering structure found (values closer to 1 suggest strong clustering structure).\nThe code chunk below will be used to compute the agglomerative coefficients of all hierarchical clustering algorithms.\n\nm &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\nnames(m) &lt;- c( \"average\", \"single\", \"complete\", \"ward\")\n\nac &lt;- function(x) {\n  agnes(shan_ict, method = x)$ac\n}\n\nmap_dbl(m, ac)\n\n  average    single  complete      ward \n0.8131144 0.6628705 0.8950702 0.9427730 \n\n\nWith reference to the output above, we can see that Ward’s method provides the strongest clustering structure among the four methods assessed. Hence, in the subsequent analysis, only Ward’s method will be used.\n\n\n9.7.8 Determining Optimal Clusters\nAnother technical challenge face by data analyst in performing clustering analysis is to determine the optimal clusters to retain.\nThere are three commonly used methods to determine the optimal clusters, they are:\n\nElbow Method\nAverage Silhouette Method\nGap Statistic Method\n\n\n9.7.8.1 Gap Statistic Method\nThe gap statistic compares the total within intra-cluster variation for different values of k with their expected values under null reference distribution of the data. The estimate of the optimal clusters will be value that maximize the gap statistic (i.e., that yields the largest gap statistic). This means that the clustering structure is far away from the random uniform distribution of points.\nTo compute the gap statistic, clusGap() of cluster package will be used.\n\nset.seed(12345)\ngap_stat &lt;- clusGap(shan_ict, \n                    FUN = hcut, \n                    nstart = 25, \n                    K.max = 10, \n                    B = 50)\n# Print the result\nprint(gap_stat, method = \"firstmax\")\n\nClustering Gap statistic [\"clusGap\"] from call:\nclusGap(x = shan_ict, FUNcluster = hcut, K.max = 10, B = 50, nstart = 25)\nB=50 simulated reference sets, k = 1..10; spaceH0=\"scaledPCA\"\n --&gt; Number of clusters (method 'firstmax'): 1\n          logW   E.logW       gap     SE.sim\n [1,] 8.407129 8.680794 0.2736651 0.04460994\n [2,] 8.130029 8.350712 0.2206824 0.03880130\n [3,] 7.992265 8.202550 0.2102844 0.03362652\n [4,] 7.862224 8.080655 0.2184311 0.03784781\n [5,] 7.756461 7.978022 0.2215615 0.03897071\n [6,] 7.665594 7.887777 0.2221833 0.03973087\n [7,] 7.590919 7.806333 0.2154145 0.04054939\n [8,] 7.526680 7.731619 0.2049390 0.04198644\n [9,] 7.458024 7.660795 0.2027705 0.04421874\n[10,] 7.377412 7.593858 0.2164465 0.04540947\n\n\nAlso note that the hcut function used is from factoextra package.\nNext, we can visualise the plot by using fviz_gap_stat() of factoextra package.\n\nfviz_gap_stat(gap_stat)\n\n\n\n\n\n\n\n\nWith reference to the gap statistic graph above, the recommended number of cluster to retain is 1. However, it is not logical to retain only one cluster. By examine the gap statistic graph, the 6-cluster gives the largest gap statistic and should be the next best cluster to pick.\nNote: In addition to these commonly used approaches, the NbClust package, published by Charrad et al., 2014, provides 30 indices for determining the relevant number of clusters and proposes to users the best clustering scheme from the different results obtained by varying all combinations of number of clusters, distance measures, and clustering methods.\n\n\n\n9.7.9 Interpreting the dendrograms\nIn the dendrogram displayed above, each leaf corresponds to one observation. As we move up the tree, observations that are similar to each other are combined into branches, which are themselves fused at a higher height.\nThe height of the fusion, provided on the vertical axis, indicates the (dis)similarity between two observations. The higher the height of the fusion, the less similar the observations are. Note that, conclusions about the proximity of two observations can be drawn only based on the height where branches containing those two observations first are fused. We cannot use the proximity of two observations along the horizontal axis as a criteria of their similarity.\nIt’s also possible to draw the dendrogram with a border around the selected clusters by using rect.hclust() of R stats. The argument border is used to specify the border colors for the rectangles.\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, \n            k = 6, \n            border = 2:5)\n\n\n\n\n\n\n\n\n\n\n9.7.10 Visually-driven hierarchical clustering analysis\nIn this section, we will learn how to perform visually-driven hiearchical clustering analysis by using heatmaply package.\nWith heatmaply, we are able to build both highly interactive cluster heatmap or static cluster heatmap.\n\n9.7.10.1 Transforming the data frame into a matrix\nThe data was loaded into a data frame, but it has to be a data matrix to make your heatmap.\nThe code chunk below will be used to transform shan_ict data frame into a data matrix.\n\nshan_ict_mat &lt;- data.matrix(shan_ict)\n\n\n\n9.7.10.2 Plotting interactive cluster heatmap using heatmaply()\nIn the code chunk below, the heatmaply() of heatmaply package is used to build an interactive cluster heatmap.\n\nheatmaply(normalize(shan_ict_mat),\n          Colv=NA,\n          dist_method = \"euclidean\",\n          hclust_method = \"ward.D\",\n          seriate = \"OLO\",\n          colors = Blues,\n          k_row = 6,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"Geographic Segmentation of Shan State by ICT indicators\",\n          xlab = \"ICT Indicators\",\n          ylab = \"Townships of Shan State\"\n          )\n\n\n\n\n\n\n\n\n9.7.11 Mapping the clusters formed\nWith closed examination of the dendragram above, we have decided to retain six clusters.\ncutree() of R Base will be used in the code chunk below to derive a 6-cluster model.\n\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nThe output is called groups. It is a list object.\nIn order to visualise the clusters, the groups object need to be appended onto shan_sf simple feature object.\nThe code chunk below form the join in three steps:\n\nthe groups list object will be converted into a matrix;\ncbind() is used to append groups matrix onto shan_sf to produce an output simple feature object called shan_sf_cluster; and\nrename of dplyr package is used to rename as.matrix.groups field as CLUSTER.\n\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`)\n\nNext, qtm() of tmap package is used to plot the choropleth map showing the cluster formed.\n\nqtm(shan_sf_cluster, \"CLUSTER\")\n\n\n\n\n\n\n\n\nThe choropleth map above reveals the clusters are very fragmented. The is one of the major limitation when non-spatial clustering algorithm such as hierarchical cluster analysis method is used."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html",
    "href": "Hands-on_Ex/Hands-on_Ex11.html",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#overview",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#overview",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "",
    "text": "Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#the-data",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#the-data",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "The Data",
    "text": "The Data\nTwo data sets will be used in this model building exercise, they are:\n\nURA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)\ncondo_resale_2015 in csv format (i.e. condo_resale_2015.csv)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#getting-started",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#getting-started",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Getting Started",
    "text": "Getting Started\nBefore we get started, it is important for us to install the necessary R packages into R and launch these R packages into R environment.\nThe R packages needed for this exercise are as follows:\n\nR package for building OLS and performing diagnostics tests\n\nolsrr\n\nR package for calibrating geographical weighted family of models\n\nGWmodel\n\nR package for multivariate data visualisation and analysis\n\ncorrplot\n\nSpatial data handling\n\nsf\n\nAttribute data handling\n\ntidyverse, especially readr, ggplot2 and dplyr\n\nChoropleth mapping\n\ntmap\n\n\nThe code chunks below installs and launches these R packages into R environment.\n\npacman::p_load(olsrr, corrplot, ggpubr, sf, spdep, GWmodel, tmap, gtsummary, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#a-short-note-about-gwmodel",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#a-short-note-about-gwmodel",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "A short note about GWmodel",
    "text": "A short note about GWmodel\nGWmodel package provides a collection of localised spatial statistical methods, namely: GW summary statistics, GW principal components analysis, GW discriminant analysis and various forms of GW regression; some of which are provided in basic and robust (outlier resistant) forms. Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#geospatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#geospatial-data-wrangling",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Geospatial Data Wrangling",
    "text": "Geospatial Data Wrangling\n\nImporting geospatial data\nThe geospatial data used in this hands-on exercise is called MP14_SUBZONE_WEB_PL. It is in ESRI shapefile format. The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.\nThe code chunk below is used to import MP_SUBZONE_WEB_PL shapefile by using st_read() of sf packages.\n\nmpsz = st_read(dsn = \"data/Hands-on_Ex10/geospatial\", layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Hands-on_Ex\\data\\Hands-on_Ex10\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nThe report above shows that the R object used to contain the imported MP14_SUBZONE_WEB_PL shapefile is called mpsz and it is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.\n\n\nUpdating CRS information\nThe code chunk below updates the newly imported mpsz with the correct ESPG code (i.e. 3414)\n\nmpsz_svy21 &lt;- st_transform(mpsz, 3414)\n\nAfter transforming the projection metadata, you can varify the projection of the newly transformed mpsz_svy21 by using st_crs() of sf package.\nThe code chunk below will be used to varify the newly transformed mpsz_svy21.\n\nst_crs(mpsz_svy21)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nNotice that the EPSG: is indicated as 3414 now.\nNext, you will reveal the extent of mpsz_svy21 by using st_bbox() of sf package.\n\nst_bbox(mpsz_svy21) #view extent\n\n     xmin      ymin      xmax      ymax \n 2667.538 15748.721 56396.440 50256.334"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#aspatial-data-wrangling",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#aspatial-data-wrangling",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Aspatial Data Wrangling",
    "text": "Aspatial Data Wrangling\n\nImporting the aspatial data\nThe condo_resale_2015 is in csv file format. The codes chunk below uses read_csv() function of readr package to import condo_resale_2015 into R as a tibble data frame called condo_resale.\n\ncondo_resale = read_csv(\"data/Hands-on_Ex10/aspatial/Condo_resale_2015.csv\")\n\nAfter importing the data file into R, it is important for us to examine if the data file has been imported correctly.\nThe codes chunks below uses glimpse() to display the data structure of will do the job.\n\nglimpse(condo_resale)\n\nRows: 1,436\nColumns: 23\n$ LATITUDE             &lt;dbl&gt; 1.287145, 1.328698, 1.313727, 1.308563, 1.321437,…\n$ LONGITUDE            &lt;dbl&gt; 103.7802, 103.8123, 103.7971, 103.8247, 103.9505,…\n$ POSTCODE             &lt;dbl&gt; 118635, 288420, 267833, 258380, 467169, 466472, 3…\n$ SELLING_PRICE        &lt;dbl&gt; 3000000, 3880000, 3325000, 4250000, 1400000, 1320…\n$ AREA_SQM             &lt;dbl&gt; 309, 290, 248, 127, 145, 139, 218, 141, 165, 168,…\n$ AGE                  &lt;dbl&gt; 30, 32, 33, 7, 28, 22, 24, 24, 27, 31, 17, 22, 6,…\n$ PROX_CBD             &lt;dbl&gt; 7.941259, 6.609797, 6.898000, 4.038861, 11.783402…\n$ PROX_CHILDCARE       &lt;dbl&gt; 0.16597932, 0.28027246, 0.42922669, 0.39473543, 0…\n$ PROX_ELDERLYCARE     &lt;dbl&gt; 2.5198118, 1.9333338, 0.5021395, 1.9910316, 1.121…\n$ PROX_URA_GROWTH_AREA &lt;dbl&gt; 6.618741, 7.505109, 6.463887, 4.906512, 6.410632,…\n$ PROX_HAWKER_MARKET   &lt;dbl&gt; 1.76542207, 0.54507614, 0.37789301, 1.68259969, 0…\n$ PROX_KINDERGARTEN    &lt;dbl&gt; 0.05835552, 0.61592412, 0.14120309, 0.38200076, 0…\n$ PROX_MRT             &lt;dbl&gt; 0.5607188, 0.6584461, 0.3053433, 0.6910183, 0.528…\n$ PROX_PARK            &lt;dbl&gt; 1.1710446, 0.1992269, 0.2779886, 0.9832843, 0.116…\n$ PROX_PRIMARY_SCH     &lt;dbl&gt; 1.6340256, 0.9747834, 1.4715016, 1.4546324, 0.709…\n$ PROX_TOP_PRIMARY_SCH &lt;dbl&gt; 3.3273195, 0.9747834, 1.4715016, 2.3006394, 0.709…\n$ PROX_SHOPPING_MALL   &lt;dbl&gt; 2.2102717, 2.9374279, 1.2256850, 0.3525671, 1.307…\n$ PROX_SUPERMARKET     &lt;dbl&gt; 0.9103958, 0.5900617, 0.4135583, 0.4162219, 0.581…\n$ PROX_BUS_STOP        &lt;dbl&gt; 0.10336166, 0.28673408, 0.28504777, 0.29872340, 0…\n$ NO_Of_UNITS          &lt;dbl&gt; 18, 20, 27, 30, 30, 31, 32, 32, 32, 32, 34, 34, 3…\n$ FAMILY_FRIENDLY      &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0…\n$ FREEHOLD             &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1…\n$ LEASEHOLD_99YR       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n\n\n\nhead(condo_resale$LONGITUDE) #see the data in XCOORD column\n\n[1] 103.7802 103.8123 103.7971 103.8247 103.9505 103.9386\n\nhead(condo_resale$LATITUDE) #see the data in YCOORD column\n\n[1] 1.287145 1.328698 1.313727 1.308563 1.321437 1.314198\n\n\nNext, summary() of base R is used to display the summary statistics of cond_resale tibble data frame.\n\nsummary(condo_resale)\n\n    LATITUDE       LONGITUDE        POSTCODE      SELLING_PRICE     \n Min.   :1.240   Min.   :103.7   Min.   : 18965   Min.   :  540000  \n 1st Qu.:1.309   1st Qu.:103.8   1st Qu.:259849   1st Qu.: 1100000  \n Median :1.328   Median :103.8   Median :469298   Median : 1383222  \n Mean   :1.334   Mean   :103.8   Mean   :440439   Mean   : 1751211  \n 3rd Qu.:1.357   3rd Qu.:103.9   3rd Qu.:589486   3rd Qu.: 1950000  \n Max.   :1.454   Max.   :104.0   Max.   :828833   Max.   :18000000  \n    AREA_SQM          AGE           PROX_CBD       PROX_CHILDCARE    \n Min.   : 34.0   Min.   : 0.00   Min.   : 0.3869   Min.   :0.004927  \n 1st Qu.:103.0   1st Qu.: 5.00   1st Qu.: 5.5574   1st Qu.:0.174481  \n Median :121.0   Median :11.00   Median : 9.3567   Median :0.258135  \n Mean   :136.5   Mean   :12.14   Mean   : 9.3254   Mean   :0.326313  \n 3rd Qu.:156.0   3rd Qu.:18.00   3rd Qu.:12.6661   3rd Qu.:0.368293  \n Max.   :619.0   Max.   :37.00   Max.   :19.1804   Max.   :3.465726  \n PROX_ELDERLYCARE  PROX_URA_GROWTH_AREA PROX_HAWKER_MARKET PROX_KINDERGARTEN \n Min.   :0.05451   Min.   :0.2145       Min.   :0.05182    Min.   :0.004927  \n 1st Qu.:0.61254   1st Qu.:3.1643       1st Qu.:0.55245    1st Qu.:0.276345  \n Median :0.94179   Median :4.6186       Median :0.90842    Median :0.413385  \n Mean   :1.05351   Mean   :4.5981       Mean   :1.27987    Mean   :0.458903  \n 3rd Qu.:1.35122   3rd Qu.:5.7550       3rd Qu.:1.68578    3rd Qu.:0.578474  \n Max.   :3.94916   Max.   :9.1554       Max.   :5.37435    Max.   :2.229045  \n    PROX_MRT         PROX_PARK       PROX_PRIMARY_SCH  PROX_TOP_PRIMARY_SCH\n Min.   :0.05278   Min.   :0.02906   Min.   :0.07711   Min.   :0.07711     \n 1st Qu.:0.34646   1st Qu.:0.26211   1st Qu.:0.44024   1st Qu.:1.34451     \n Median :0.57430   Median :0.39926   Median :0.63505   Median :1.88213     \n Mean   :0.67316   Mean   :0.49802   Mean   :0.75471   Mean   :2.27347     \n 3rd Qu.:0.84844   3rd Qu.:0.65592   3rd Qu.:0.95104   3rd Qu.:2.90954     \n Max.   :3.48037   Max.   :2.16105   Max.   :3.92899   Max.   :6.74819     \n PROX_SHOPPING_MALL PROX_SUPERMARKET PROX_BUS_STOP       NO_Of_UNITS    \n Min.   :0.0000     Min.   :0.0000   Min.   :0.001595   Min.   :  18.0  \n 1st Qu.:0.5258     1st Qu.:0.3695   1st Qu.:0.098356   1st Qu.: 188.8  \n Median :0.9357     Median :0.5687   Median :0.151710   Median : 360.0  \n Mean   :1.0455     Mean   :0.6141   Mean   :0.193974   Mean   : 409.2  \n 3rd Qu.:1.3994     3rd Qu.:0.7862   3rd Qu.:0.220466   3rd Qu.: 590.0  \n Max.   :3.4774     Max.   :2.2441   Max.   :2.476639   Max.   :1703.0  \n FAMILY_FRIENDLY     FREEHOLD      LEASEHOLD_99YR  \n Min.   :0.0000   Min.   :0.0000   Min.   :0.0000  \n 1st Qu.:0.0000   1st Qu.:0.0000   1st Qu.:0.0000  \n Median :0.0000   Median :0.0000   Median :0.0000  \n Mean   :0.4868   Mean   :0.4227   Mean   :0.4882  \n 3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.0000  \n Max.   :1.0000   Max.   :1.0000   Max.   :1.0000  \n\n\n\n\nConverting aspatial data frame into a sf object\nCurrently, the condo_resale tibble data frame is aspatial. We will convert it to a sf object. The code chunk below converts condo_resale data frame into a simple feature data frame by using st_as_sf() of sf packages.\n\ncondo_resale.sf &lt;- st_as_sf(condo_resale,\n                            coords = c(\"LONGITUDE\", \"LATITUDE\"),\n                            crs=4326) %&gt;%\n  st_transform(crs=3414)\n\nNotice that st_transform() of sf package is used to convert the coordinates from wgs84 (i.e. crs:4326) to svy21 (i.e. crs=3414).\nNext, head() is used to list the content of condo_resale.sf object.\n\nhead(condo_resale.sf)\n\nSimple feature collection with 6 features and 21 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 22085.12 ymin: 29951.54 xmax: 41042.56 ymax: 34546.2\nProjected CRS: SVY21 / Singapore TM\n# A tibble: 6 × 22\n  POSTCODE SELLING_PRICE AREA_SQM   AGE PROX_CBD PROX_CHILDCARE PROX_ELDERLYCARE\n     &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;          &lt;dbl&gt;            &lt;dbl&gt;\n1   118635       3000000      309    30     7.94          0.166            2.52 \n2   288420       3880000      290    32     6.61          0.280            1.93 \n3   267833       3325000      248    33     6.90          0.429            0.502\n4   258380       4250000      127     7     4.04          0.395            1.99 \n5   467169       1400000      145    28    11.8           0.119            1.12 \n6   466472       1320000      139    22    10.3           0.125            0.789\n# ℹ 15 more variables: PROX_URA_GROWTH_AREA &lt;dbl&gt;, PROX_HAWKER_MARKET &lt;dbl&gt;,\n#   PROX_KINDERGARTEN &lt;dbl&gt;, PROX_MRT &lt;dbl&gt;, PROX_PARK &lt;dbl&gt;,\n#   PROX_PRIMARY_SCH &lt;dbl&gt;, PROX_TOP_PRIMARY_SCH &lt;dbl&gt;,\n#   PROX_SHOPPING_MALL &lt;dbl&gt;, PROX_SUPERMARKET &lt;dbl&gt;, PROX_BUS_STOP &lt;dbl&gt;,\n#   NO_Of_UNITS &lt;dbl&gt;, FAMILY_FRIENDLY &lt;dbl&gt;, FREEHOLD &lt;dbl&gt;,\n#   LEASEHOLD_99YR &lt;dbl&gt;, geometry &lt;POINT [m]&gt;\n\n\nNotice that the output is in point feature data frame."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#exploratory-data-analysis-eda",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#exploratory-data-analysis-eda",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\nIn the section, you will learn how to use statistical graphics functions of ggplot2 package to perform EDA.\n\nEDA using statistical graphics\nWe can plot the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA) as shown in the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nThe figure above reveals a right skewed distribution. This means that more condominium units were transacted at relative lower prices.\nStatistically, the skewed dsitribution can be normalised by using log transformation. The code chunk below is used to derive a new variable called LOG_SELLING_PRICE by using a log transformation on the variable SELLING_PRICE. It is performed using mutate() of dplyr package.\n\ncondo_resale.sf &lt;- condo_resale.sf %&gt;%\n  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))\n\nNow, you can plot the LOG_SELLING_PRICE using the code chunk below.\n\nggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\n\n\n\n\n\n\n\nNotice that the distribution is relatively less skewed after the transformation.\n\n\nMultiple Histogram Plots distribution of variables\nIn this section, you will learn how to draw a small multiple histograms (also known as trellis plot) by using ggarrange() of ggpubr package.\nThe code chunk below is used to create 12 histograms. Then, ggarrange() is used to organised these histogram into a 3 columns by 4 rows small multiple plot.\n\nAREA_SQM &lt;- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nAGE &lt;- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CBD &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_CHILDCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) + \n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_ELDERLYCARE &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_URA_GROWTH_AREA &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_URA_GROWTH_AREA`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_HAWKER_MARKET &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_KINDERGARTEN &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_MRT &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PARK &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nPROX_TOP_PRIMARY_SCH &lt;- ggplot(data=condo_resale.sf, \n                               aes(x= `PROX_TOP_PRIMARY_SCH`)) +\n  geom_histogram(bins=20, color=\"black\", fill=\"light blue\")\n\nggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, \n          PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT,\n          PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  \n          ncol = 3, nrow = 4)\n\n\n\n\n\n\n\n\n\n\nDrawing Statistical Point Map\nLastly, we want to reveal the geospatial distribution condominium resale prices in Singapore. The map will be prepared by using tmap package.\nFirst, we will turn on the interactive mode of tmap by using the code chunk below.\n\ntmap_mode(\"view\")\n\nNext, the code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tm_polygons() +\ntm_shape(condo_resale.sf) +  \n  tm_dots(col = \"SELLING_PRICE\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\nNotice that tm_dots() is used instead of tm_bubbles().\nset.zoom.limits argument of tm_view() sets the minimum and maximum zoom level to 11 and 14 respectively.\nBefore moving on to the next section, the code below will be used to turn R display into plot mode.\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex11.html#hedonic-pricing-modelling-in-r",
    "href": "Hands-on_Ex/Hands-on_Ex11.html#hedonic-pricing-modelling-in-r",
    "title": "Calibrating Hedonic Pricing Model for Private Highrise Property with GWR Method",
    "section": "Hedonic Pricing Modelling in R",
    "text": "Hedonic Pricing Modelling in R\nIn this section, you will learn how to building hedonic pricing models for condominium resale units using lm() of R base.\n\nSimple Linear Regression Method\nFirst, we will build a simple linear regression model by using SELLING_PRICE as the dependent variable and AREA_SQM as the independent variable.\n\ncondo.slr &lt;- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nlm() returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).\nThe functions summary() and anova() can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by lm.\n\nsummary(condo.slr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3695815  -391764   -87517   258900 13503875 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -258121.1    63517.2  -4.064 5.09e-05 ***\nAREA_SQM      14719.0      428.1  34.381  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 942700 on 1434 degrees of freedom\nMultiple R-squared:  0.4518,    Adjusted R-squared:  0.4515 \nF-statistic:  1182 on 1 and 1434 DF,  p-value: &lt; 2.2e-16\n\n\nThe output report reveals that the SELLING_PRICE can be explained by using the formula:\n      *y = -258121.1 + 14719x1*\nThe R-squared of 0.4518 reveals that the simple regression model built is able to explain about 45% of the resale prices.\nSince p-value is much smaller than 0.0001, we will reject the null hypothesis that mean is a good estimator of SELLING_PRICE. This will allow us to infer that simple linear regression model above is a good estimator of SELLING_PRICE.\nThe Coefficients: section of the report reveals that the p-values of both the estimates of the Intercept and ARA_SQM are smaller than 0.001. In view of this, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As a results, we will be able to infer that the B0 and B1 are good parameter estimates.\nTo visualise the best fit curve on a scatterplot, we can incorporate lm() as a method function in ggplot’s geometry as shown in the code chunk below.\n\nggplot(data=condo_resale.sf,  \n       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +\n  geom_point() +\n  geom_smooth(method = lm)\n\n\n\n\n\n\n\n\nFigure above reveals that there are a few statistical outliers with relatively high selling prices.\n\n\nMultiple Linear Regression Method\n\nVisualising the relationships of the independent variables\nBefore building a multiple regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. Beside the pairs() of R, there are many packages support the display of a correlation matrix. In this section, the corrplot package will be used.\nThe code chunk below is used to plot a scatterplot matrix of the relationship between the independent variables in condo_resale data.frame.\n\ncorrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = \"AOE\",\n         tl.pos = \"td\", tl.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\n\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\nFrom the scatterplot matrix, it is clear that Freehold is highly correlated to LEASE_99YEAR. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, LEASE_99YEAR is excluded in the subsequent model building.\n\n\n\nBuilding a hedonic pricing model using multiple linear regression method\nThe code chunk below using lm() to calibrate the multiple linear regression model.\n\ncondo.mlr &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE    + \n                  PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                  PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + PROX_KINDERGARTEN + \n                  PROX_MRT  + PROX_PARK + PROX_PRIMARY_SCH + \n                  PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n                  PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n                data=condo_resale.sf)\nsummary(condo.mlr)\n\n\nCall:\nlm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD + PROX_CHILDCARE + \n    PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET + \n    PROX_KINDERGARTEN + PROX_MRT + PROX_PARK + PROX_PRIMARY_SCH + \n    PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_SUPERMARKET + \n    PROX_BUS_STOP + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, \n    data = condo_resale.sf)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-3475964  -293923   -23069   241043 12260381 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)           481728.40  121441.01   3.967 7.65e-05 ***\nAREA_SQM               12708.32     369.59  34.385  &lt; 2e-16 ***\nAGE                   -24440.82    2763.16  -8.845  &lt; 2e-16 ***\nPROX_CBD              -78669.78    6768.97 -11.622  &lt; 2e-16 ***\nPROX_CHILDCARE       -351617.91  109467.25  -3.212  0.00135 ** \nPROX_ELDERLYCARE      171029.42   42110.51   4.061 5.14e-05 ***\nPROX_URA_GROWTH_AREA   38474.53   12523.57   3.072  0.00217 ** \nPROX_HAWKER_MARKET     23746.10   29299.76   0.810  0.41782    \nPROX_KINDERGARTEN     147468.99   82668.87   1.784  0.07466 .  \nPROX_MRT             -314599.68   57947.44  -5.429 6.66e-08 ***\nPROX_PARK             563280.50   66551.68   8.464  &lt; 2e-16 ***\nPROX_PRIMARY_SCH      180186.08   65237.95   2.762  0.00582 ** \nPROX_TOP_PRIMARY_SCH    2280.04   20410.43   0.112  0.91107    \nPROX_SHOPPING_MALL   -206604.06   42840.60  -4.823 1.57e-06 ***\nPROX_SUPERMARKET      -44991.80   77082.64  -0.584  0.55953    \nPROX_BUS_STOP         683121.35  138353.28   4.938 8.85e-07 ***\nNO_Of_UNITS             -231.18      89.03  -2.597  0.00951 ** \nFAMILY_FRIENDLY       140340.77   47020.55   2.985  0.00289 ** \nFREEHOLD              359913.01   49220.22   7.312 4.38e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 755800 on 1417 degrees of freedom\nMultiple R-squared:  0.6518,    Adjusted R-squared:  0.6474 \nF-statistic: 147.4 on 18 and 1417 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nPreparing Publication Quality Table: olsrr method\nWith reference to the report above, it is clear that not all the independent variables are statistically significant. We will revised the model by removing those variables which are not statistically significant.\nNow, we are ready to calibrate the revised model by using the code chunk below.\n\ncondo.mlr1 &lt;- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + \n                   PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE +\n                   PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK + \n                   PROX_PRIMARY_SCH + PROX_SHOPPING_MALL    + PROX_BUS_STOP + \n                   NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD,\n                 data=condo_resale.sf)\nols_regress(condo.mlr1)\n\n                                Model Summary                                 \n-----------------------------------------------------------------------------\nR                            0.807       RMSE                     751998.679 \nR-Squared                    0.651       MSE                571471422208.591 \nAdj. R-Squared               0.647       Coef. Var                    43.168 \nPred R-Squared               0.638       AIC                       42966.758 \nMAE                     414819.628       SBC                       43051.072 \n-----------------------------------------------------------------------------\n RMSE: Root Mean Square Error \n MSE: Mean Square Error \n MAE: Mean Absolute Error \n AIC: Akaike Information Criteria \n SBC: Schwarz Bayesian Criteria \n\n                                     ANOVA                                       \n--------------------------------------------------------------------------------\n                    Sum of                                                      \n                   Squares          DF         Mean Square       F         Sig. \n--------------------------------------------------------------------------------\nRegression    1.512586e+15          14        1.080418e+14    189.059    0.0000 \nResidual      8.120609e+14        1421    571471422208.591                      \nTotal         2.324647e+15        1435                                          \n--------------------------------------------------------------------------------\n\n                                               Parameter Estimates                                                \n-----------------------------------------------------------------------------------------------------------------\n               model           Beta    Std. Error    Std. Beta       t        Sig           lower          upper \n-----------------------------------------------------------------------------------------------------------------\n         (Intercept)     527633.222    108183.223                   4.877    0.000     315417.244     739849.200 \n            AREA_SQM      12777.523       367.479        0.584     34.771    0.000      12056.663      13498.382 \n                 AGE     -24687.739      2754.845       -0.167     -8.962    0.000     -30091.739     -19283.740 \n            PROX_CBD     -77131.323      5763.125       -0.263    -13.384    0.000     -88436.469     -65826.176 \n      PROX_CHILDCARE    -318472.751    107959.512       -0.084     -2.950    0.003    -530249.889    -106695.613 \n    PROX_ELDERLYCARE     185575.623     39901.864        0.090      4.651    0.000     107302.737     263848.510 \nPROX_URA_GROWTH_AREA      39163.254     11754.829        0.060      3.332    0.001      16104.571      62221.936 \n            PROX_MRT    -294745.107     56916.367       -0.112     -5.179    0.000    -406394.234    -183095.980 \n           PROX_PARK     570504.807     65507.029        0.150      8.709    0.000     442003.938     699005.677 \n    PROX_PRIMARY_SCH     159856.136     60234.599        0.062      2.654    0.008      41697.849     278014.424 \n  PROX_SHOPPING_MALL    -220947.251     36561.832       -0.115     -6.043    0.000    -292668.213    -149226.288 \n       PROX_BUS_STOP     682482.221    134513.243        0.134      5.074    0.000     418616.359     946348.082 \n         NO_Of_UNITS       -245.480        87.947       -0.053     -2.791    0.005       -418.000        -72.961 \n     FAMILY_FRIENDLY     146307.576     46893.021        0.057      3.120    0.002      54320.593     238294.560 \n            FREEHOLD     350599.812     48506.485        0.136      7.228    0.000     255447.802     445751.821 \n-----------------------------------------------------------------------------------------------------------------\n\n\n\n\nPreparing Publication Quality Table: gtsummary method\nThe gtsummary package provides an elegant and flexible way to create publication-ready summary tables in R.\nIn the code chunk below, tbl_regression() is used to create a well formatted regression report.\n\ntbl_regression(condo.mlr1, intercept = TRUE)\n\n\n\n\n\n\n\nCharacteristic\nBeta\n95% CI1\np-value\n\n\n\n\n(Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n\n\nAREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n\n\nAGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n\n\nPROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n\n\nPROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n\n\nPROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n\n\nPROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n\n\nPROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n\n\nPROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n\n\nPROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n\n\nPROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n\n\nPROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n\n\nNO_Of_UNITS\n-245\n-418, -73\n0.005\n\n\nFAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n\n\nFREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n\n\n\n1 CI = Confidence Interval\n\n\n\n\n\n\n\n\nWith gtsummary package, model statistics can be included in the report by either appending them to the report table by using add_glance_table() or adding as a table source note by using add_glance_source_note() as shown in the code chunk below.\n\ntbl_regression(condo.mlr1, \n               intercept = TRUE) %&gt;% \n  add_glance_source_note(\n    label = list(sigma ~ \"\\U03C3\"),\n    include = c(r.squared, adj.r.squared, \n                AIC, statistic,\n                p.value, sigma))\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n527,633\n315,417, 739,849\n&lt;0.001\n    AREA_SQM\n12,778\n12,057, 13,498\n&lt;0.001\n    AGE\n-24,688\n-30,092, -19,284\n&lt;0.001\n    PROX_CBD\n-77,131\n-88,436, -65,826\n&lt;0.001\n    PROX_CHILDCARE\n-318,473\n-530,250, -106,696\n0.003\n    PROX_ELDERLYCARE\n185,576\n107,303, 263,849\n&lt;0.001\n    PROX_URA_GROWTH_AREA\n39,163\n16,105, 62,222\n&lt;0.001\n    PROX_MRT\n-294,745\n-406,394, -183,096\n&lt;0.001\n    PROX_PARK\n570,505\n442,004, 699,006\n&lt;0.001\n    PROX_PRIMARY_SCH\n159,856\n41,698, 278,014\n0.008\n    PROX_SHOPPING_MALL\n-220,947\n-292,668, -149,226\n&lt;0.001\n    PROX_BUS_STOP\n682,482\n418,616, 946,348\n&lt;0.001\n    NO_Of_UNITS\n-245\n-418, -73\n0.005\n    FAMILY_FRIENDLY\n146,308\n54,321, 238,295\n0.002\n    FREEHOLD\n350,600\n255,448, 445,752\n&lt;0.001\n  \n  \n    \n      R² = 0.651; Adjusted R² = 0.647; AIC = 42,967; Statistic = 189; p-value = &lt;0.001; σ = 755,957\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nFor more customisation options, refer to Tutorial: tbl_regression\n\nChecking for multicolinearity\nIn this section, we would like to introduce you a fantastic R package specially programmed for performing OLS regression. It is called olsrr. It provides a collection of very useful methods for building better multiple linear regression models:\n\ncomprehensive regression output\nresidual diagnostics\nmeasures of influence\nheteroskedasticity tests\ncollinearity diagnostics\nmodel fit assessment\nvariable contribution assessment\nvariable selection procedures\n\nIn the code chunk below, the ols_vif_tol() of olsrr package is used to test if there are sign of multicollinearity.\n\nols_vif_tol(condo.mlr1)\n\n              Variables Tolerance      VIF\n1              AREA_SQM 0.8728554 1.145665\n2                   AGE 0.7071275 1.414172\n3              PROX_CBD 0.6356147 1.573280\n4        PROX_CHILDCARE 0.3066019 3.261559\n5      PROX_ELDERLYCARE 0.6598479 1.515501\n6  PROX_URA_GROWTH_AREA 0.7510311 1.331503\n7              PROX_MRT 0.5236090 1.909822\n8             PROX_PARK 0.8279261 1.207837\n9      PROX_PRIMARY_SCH 0.4524628 2.210126\n10   PROX_SHOPPING_MALL 0.6738795 1.483945\n11        PROX_BUS_STOP 0.3514118 2.845664\n12          NO_Of_UNITS 0.6901036 1.449058\n13      FAMILY_FRIENDLY 0.7244157 1.380423\n14             FREEHOLD 0.6931163 1.442759\n\n\nSince the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.\n\n\nTest for Non-Linearity\nIn multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.\nIn the code chunk below, the ols_plot_resid_fit() of olsrr package is used to perform linearity assumption test.\n\nols_plot_resid_fit(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure above reveals that most of the data poitns are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.\n\n\nTest for Normality Assumption\nLastly, the code chunk below uses ols_plot_resid_hist() of olsrr package to perform normality assumption test.\n\nols_plot_resid_hist(condo.mlr1)\n\n\n\n\n\n\n\n\nThe figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble normal distribution.\nIf you prefer formal statistical test methods, the ols_test_normality() of olsrr package can be used as shown in the code chun below.\n\nols_test_normality(condo.mlr1)\n\n-----------------------------------------------\n       Test             Statistic       pvalue  \n-----------------------------------------------\nShapiro-Wilk              0.6856         0.0000 \nKolmogorov-Smirnov        0.1366         0.0000 \nCramer-von Mises         121.0768        0.0000 \nAnderson-Darling         67.9551         0.0000 \n-----------------------------------------------\n\n\nThe summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis and infer that there is statistical evidence that the residual are not normally distributed.\n\n\nTesting for Spatial Autocorrelation\nThe hedonic model we try to build are using geographically referenced attributes, hence it is also important for us to visual the residual of the hedonic pricing model.\nIn order to perform spatial autocorrelation test, we need to convert condo_resale.sf from sf data frame into a SpatialPointsDataFrame.\nFirst, we will export the residual of the hedonic pricing model and save it as a data frame.\n\nmlr.output &lt;- as.data.frame(condo.mlr1$residuals)\n\nNext, we will join the newly created data frame with condo_resale.sf object.\n\ncondo_resale.res.sf &lt;- cbind(condo_resale.sf, \n                        condo.mlr1$residuals) %&gt;%\nrename(`MLR_RES` = `condo.mlr1.residuals`)\n\nNext, we will convert condo_resale.res.sf from simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.\nThe code chunk below will be used to perform the data conversion process.\n\ncondo_resale.sp &lt;- as_Spatial(condo_resale.res.sf)\ncondo_resale.sp\n\nclass       : SpatialPointsDataFrame \nfeatures    : 1436 \nextent      : 14940.85, 43352.45, 24765.67, 48382.81  (xmin, xmax, ymin, ymax)\ncrs         : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs \nvariables   : 23\nnames       : POSTCODE, SELLING_PRICE, AREA_SQM, AGE,    PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN,    PROX_MRT,   PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH, PROX_SHOPPING_MALL, ... \nmin values  :    18965,        540000,       34,   0, 0.386916393,    0.004927023,      0.054508623,          0.214539508,        0.051817113,       0.004927023, 0.052779424, 0.029064164,      0.077106132,          0.077106132,                  0, ... \nmax values  :   828833,       1.8e+07,      619,  37, 19.18042832,     3.46572633,      3.949157205,           9.15540001,        5.374348075,       2.229045366,  3.48037319,  2.16104919,      3.928989144,          6.748192062,        3.477433767, ... \n\n\nNext, we will use tmap package to display the distribution of the residuals on an interactive map.\nThe code churn below will turn on the interactive mode of tmap.\n\ntmap_mode(\"view\")\n\nThe code chunks below is used to create an interactive point symbol map.\n\ntm_shape(mpsz_svy21)+\n  tmap_options(check.and.fix = TRUE) +\n  tm_polygons(alpha = 0.4) +\ntm_shape(condo_resale.res.sf) +  \n  tm_dots(col = \"MLR_RES\",\n          alpha = 0.6,\n          style=\"quantile\") +\n  tm_view(set.zoom.limits = c(11,14))\n\n\n\n\n\nRemember to switch back to “plot” mode before continue.\n\ntmap_mode(\"plot\")\n\nThe figure above reveal that there is sign of spatial autocorrelation.\nTo proof that our observation is indeed true, the Moran’s I test will be performed\nFirst, we will compute the distance-based weight matrix by using dnearneigh() function of spdep.\n\nnb &lt;- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)\nsummary(nb)\n\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\n\nNext, nb2listw() of spdep packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.\n\nnb_lw &lt;- nb2listw(nb, style = 'W')\nsummary(nb_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 1436 \nNumber of nonzero links: 66266 \nPercentage nonzero weights: 3.213526 \nAverage number of links: 46.14624 \n10 disjoint connected subgraphs\nLink number distribution:\n\n  1   3   5   7   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24 \n  3   3   9   4   3  15  10  19  17  45  19   5  14  29  19   6  35  45  18  47 \n 25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44 \n 16  43  22  26  21  11   9  23  22  13  16  25  21  37  16  18   8  21   4  12 \n 45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64 \n  8  36  18  14  14  43  11  12   8  13  12  13   4   5   6  12  11  20  29  33 \n 65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84 \n 15  20  10  14  15  15  11  16  12  10   8  19  12  14   9   8   4  13  11   6 \n 85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 \n  4   9   4   4   4   6   2  16   9   4   5   9   3   9   4   2   1   2   1   1 \n105 106 107 108 109 110 112 116 125 \n  1   5   9   2   1   3   1   1   1 \n3 least connected regions:\n193 194 277 with 1 link\n1 most connected region:\n285 with 125 links\n\nWeights style: W \nWeights constants summary:\n     n      nn   S0       S1       S2\nW 1436 2062096 1436 94.81916 5798.341\n\n\nNext, lm.morantest() of spdep package will be used to perform Moran’s I test for residual spatial autocorrelation\n\nlm.morantest(condo.mlr1, nb_lw)\n\n\n    Global Moran I for regression residuals\n\ndata:  \nmodel: lm(formula = SELLING_PRICE ~ AREA_SQM + AGE + PROX_CBD +\nPROX_CHILDCARE + PROX_ELDERLYCARE + PROX_URA_GROWTH_AREA + PROX_MRT +\nPROX_PARK + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL + PROX_BUS_STOP +\nNO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data = condo_resale.sf)\nweights: nb_lw\n\nMoran I statistic standard deviate = 24.366, p-value &lt; 2.2e-16\nalternative hypothesis: greater\nsample estimates:\nObserved Moran I      Expectation         Variance \n    1.438876e-01    -5.487594e-03     3.758259e-05 \n\n\nThe Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.\nSince the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03.html",
    "title": "In Class exercise 3",
    "section": "",
    "text": "Conduct a Monte Carlo simulation to test for Complete Spatial Randomness (CSR)\nMonte Carlo simulation test of CSR:\n\nTo determine the simulation envelope, use the 95th percentile (maximum) and 5th percentile (minimum) values of G(r) from the simulations.\nWhen randomising data it is important to set seed to have it be repeatable\n\nNearest Neighbour Index:\n\nBefore hypothesis, one should determine confidence interval (confidence level) to justify conclusion reached\nDue to the unpredictability of real life data, uncertainty would need to be considered via the confidence level\n\n99 - 99.9 confidence level should be avoided due to the perceived notion that it is almost fully accurate, which cannot happen due to real world uncertainty\n\nReject P-value, if P-value&lt; Alpha value\n\nL Functions Interpretation:\n\nSigns of clustering can be determined from how much higher the L value is above the envelope\n\nRipley’s K function:\n\nBoth G function and K function are distance based, but G function is for any particular zone (isolated), but K function is cumulative in nature (inclusive)\nUsage lies in zoning based on the various interval ranges"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#notes",
    "href": "In-class_Ex/In-class_Ex03.html#notes",
    "title": "In Class exercise 3",
    "section": "",
    "text": "Conduct a Monte Carlo simulation to test for Complete Spatial Randomness (CSR)\nMonte Carlo simulation test of CSR:\n\nTo determine the simulation envelope, use the 95th percentile (maximum) and 5th percentile (minimum) values of G(r) from the simulations.\nWhen randomising data it is important to set seed to have it be repeatable\n\nNearest Neighbour Index:\n\nBefore hypothesis, one should determine confidence interval (confidence level) to justify conclusion reached\nDue to the unpredictability of real life data, uncertainty would need to be considered via the confidence level\n\n99 - 99.9 confidence level should be avoided due to the perceived notion that it is almost fully accurate, which cannot happen due to real world uncertainty\n\nReject P-value, if P-value&lt; Alpha value\n\nL Functions Interpretation:\n\nSigns of clustering can be determined from how much higher the L value is above the envelope\n\nRipley’s K function:\n\nBoth G function and K function are distance based, but G function is for any particular zone (isolated), but K function is cumulative in nature (inclusive)\nUsage lies in zoning based on the various interval ranges"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#getting-started",
    "href": "In-class_Ex/In-class_Ex03.html#getting-started",
    "title": "In Class exercise 3",
    "section": "3.1 Getting Started",
    "text": "3.1 Getting Started\nMaptools is retired and binary is removed from CRAN. However, we can download froom Posit Public Package Manager\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse)\n\n\n3.1.1 Working with st_union()\nThe code chunk below is used to derive the coastal outline in tibble data frame sg_sf &lt;- mpsz_sf %&gt;% st_union()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03.html#viewing-data-for-take-home-exercise-1",
    "href": "In-class_Ex/In-class_Ex03.html#viewing-data-for-take-home-exercise-1",
    "title": "In Class exercise 3",
    "section": "3.2 Viewing data for Take Home exercise 1",
    "text": "3.2 Viewing data for Take Home exercise 1\n\nacled_sf &lt;- read_csv(\"data/ACLED_Myanmar.csv\") %&gt;% \n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"), crs = 4326) %&gt;% \n  st_transform(crs= 32647) %&gt;%\n  mutate(event_date = dmy(event_date))\n\n\ntmap_mode('view')\nacled_sf %&gt;%\n  filter(year == 2023 |\n           event_type == \"Political violence\") %&gt;%\n  tm_shape()+\n  tm_dots()\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05.html",
    "title": "In Class exercise 5",
    "section": "",
    "text": "A way to define spatial neighbourhood (Polygon vs Centroid)\n\nDefining spatial weights\nUsing a centroid to determine the neighhours around a particular area\ncentroid would be able to gauge how far any neighbour is close to the area in focus\n\nLimitations of centroid: irregular shaped areas, land\n\n\nContiguity Neighbours\n\nCommon shared boundary\n\nRook’s case, Bishop’s case, Queen’s case\n\nMultiple order used in measuring contiguity\nCan be seen a graph with differing cases focusing on where their neighbours are connected"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#notes",
    "href": "In-class_Ex/In-class_Ex05.html#notes",
    "title": "In Class exercise 5",
    "section": "",
    "text": "A way to define spatial neighbourhood (Polygon vs Centroid)\n\nDefining spatial weights\nUsing a centroid to determine the neighhours around a particular area\ncentroid would be able to gauge how far any neighbour is close to the area in focus\n\nLimitations of centroid: irregular shaped areas, land\n\n\nContiguity Neighbours\n\nCommon shared boundary\n\nRook’s case, Bishop’s case, Queen’s case\n\nMultiple order used in measuring contiguity\nCan be seen a graph with differing cases focusing on where their neighbours are connected"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#installing-and-loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex05.html#installing-and-loading-the-r-packages",
    "title": "In Class exercise 5",
    "section": "5.1 Installing and Loading the R packages",
    "text": "5.1 Installing and Loading the R packages\nFor the purpose of this study, five R packages will be used. They are:\n\nsf, a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nspdep, an R package focused on spatial dependence and spatial econometrics. It includes functions for computing spatial weights, neighborhood structures, and spatially lagged variables, which are crucial for understanding spatial relationships in data.\nknitr, an R package that enables dynamic report generation. It integrates R code with Markdown or LaTeX to create reproducible documents, which is useful for documenting and sharing your analysis workflows.\ntidyverse, a collection of R packages designed for data science. It includes packages like dplyr for data manipulation, ggplot2 for data visualization, and tidyr for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.\nGWmodel, a collection of techniques from a particular branch of spatial statistics,termed geographically-weighted (GW) models. GW models suit situations when data are not described well by some global model, but where there are spatial regions where a suitably localised calibration provides a better description.\n\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel)\n\n\n5.1.1 Import shapefile into r environment\nThe code chunk below uses st_read() of sf package to import Hunan shapefile into R. The imported shapefile will be simple features Object of sf.\n\nhunan_sf &lt;- st_read(dsn = \"data/In-class_Ex05/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\In-class_Ex\\data\\In-class_Ex05\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\n\n\n\n5.1.2 Import csv file into r environment\nNext, we will import Hunan_2012.csv into R by using read_csv() of readr package. The output is R dataframe class.\n\nhunan2012 &lt;- read_csv(\"data/In-class_Ex05/aspatial/Hunan_2012.csv\")\nhunan2012\n\n# A tibble: 88 × 29\n   County    City   avg_wage deposite    FAI Gov_Rev Gov_Exp    GDP GDPPC    GIO\n   &lt;chr&gt;     &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 Anhua     Yiyang    30544   10967   6832.    457.   2703  13225  14567  9277.\n 2 Anren     Chenz…    28058    4599.  6386.    221.   1455.  4941. 12761  4189.\n 3 Anxiang   Chang…    31935    5517.  3541     244.   1780. 12482  23667  5109.\n 4 Baojing   Hunan…    30843    2250   1005.    193.   1379.  4088. 14563  3624.\n 5 Chaling   Zhuzh…    31251    8241.  6508.    620.   1947  11585  20078  9158.\n 6 Changning Hengy…    28518   10860   7920     770.   2632. 19886  24418 37392 \n 7 Changsha  Chang…    54540   24332  33624    5350    7886. 88009  88656 51361 \n 8 Chengbu   Shaoy…    28597    2581.  1922.    161.   1192.  2570. 10132  1681.\n 9 Chenxi    Huaih…    33580    4990   5818.    460.   1724.  7755. 17026  6644.\n10 Cili      Zhang…    33099    8117.  4498.    500.   2306. 11378  18714  5843.\n# ℹ 78 more rows\n# ℹ 19 more variables: Loan &lt;dbl&gt;, NIPCR &lt;dbl&gt;, Bed &lt;dbl&gt;, Emp &lt;dbl&gt;,\n#   EmpR &lt;dbl&gt;, EmpRT &lt;dbl&gt;, Pri_Stu &lt;dbl&gt;, Sec_Stu &lt;dbl&gt;, Household &lt;dbl&gt;,\n#   Household_R &lt;dbl&gt;, NOIP &lt;dbl&gt;, Pop_R &lt;dbl&gt;, RSCG &lt;dbl&gt;, Pop_T &lt;dbl&gt;,\n#   Agri &lt;dbl&gt;, Service &lt;dbl&gt;, Disp_Inc &lt;dbl&gt;, RORP &lt;dbl&gt;, ROREmp &lt;dbl&gt;\n\n\n\n\n5.1.3 Performing relational join\nThe code chunk below will be used to update the attribute table of hunan’s SpatialPolygonsDataFrame with the attribute fields of hunan2012 data frame. This is performed by using left_join() of dplyr package.\n\nhunan_sf &lt;- left_join(hunan_sf,hunan2012)%&gt;%\n  select(1:3, 7, 15, 16, 31, 32)\n\n\n\n5.1.4 Store file locally\nWriting to rds would allow for quick retrieval of required data\n\nhunan_sf &lt;- read_rds(\"data/rds/hunan_sf.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#converting-to-spatialpolgyondataframe",
    "href": "In-class_Ex/In-class_Ex05.html#converting-to-spatialpolgyondataframe",
    "title": "In Class exercise 5",
    "section": "5.2 Converting to SpatialPolgyonDataFrame",
    "text": "5.2 Converting to SpatialPolgyonDataFrame\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "href": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth",
    "title": "In Class exercise 5",
    "section": "5.3 Geographically Weighted Summary Statistics with Adaptive Bandwidth",
    "text": "5.3 Geographically Weighted Summary Statistics with Adaptive Bandwidth\nAkaike information criterion (AIC) approach to determine the recommended number of neighbours\n\nbw_AIC_adapt &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = 'AIC',\n                 adaptive = TRUE,\n                 kernel = 'bisquare',\n                 longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\nCross validation approach to determine the recommended number of neighbours\n\nbw_CV_adapt &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = 'CV',\n                 adaptive = TRUE,\n                 kernel = 'bisquare',\n                 longlat = T)         \n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "href": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-fixed-bandwidth",
    "title": "In Class exercise 5",
    "section": "5.4 Geographically Weighted Summary Statistics with Fixed Bandwidth",
    "text": "5.4 Geographically Weighted Summary Statistics with Fixed Bandwidth\nAkaike information criterion (AIC) approach to determine the recommended number of neighbours\n\nbw_AIC_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = 'AIC',\n                 adaptive = FALSE,\n                 kernel = 'bisquare',\n                 longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\nCross validation approach to determine the recommended number of neighbours\n\nbw_CV_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                 data = hunan_sp,\n                 approach = 'CV',\n                 adaptive = FALSE,\n                 kernel = 'bisquare',\n                 longlat = T)         \n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\nIt can be observed that unlike the determination of the adaptive bandwidth, fixed bandwidth yield vastly different results for the methods of AIC and Cross Validation"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-1",
    "href": "In-class_Ex/In-class_Ex05.html#geographically-weighted-summary-statistics-with-adaptive-bandwidth-1",
    "title": "In Class exercise 5",
    "section": "5.4 Geographically Weighted Summary Statistics with adaptive Bandwidth",
    "text": "5.4 Geographically Weighted Summary Statistics with adaptive Bandwidth\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC_adapt,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\ngwstat[[\"SDF\"]]\n\nclass       : SpatialPolygonsDataFrame \nfeatures    : 88 \nextent      : 108.7831, 114.2544, 24.6342, 30.12812  (xmin, xmax, ymin, ymax)\ncrs         : +proj=longlat +datum=WGS84 +no_defs \nvariables   : 5\nnames       :         GDPPC_LM,        GDPPC_LSD,       GDPPC_LVar,         GDPPC_LSKe,         GDPPC_LCV \nmin values  : 13688.6986033259, 4282.59917616925, 18340655.7037255, -0.215059890053628, 0.200050258645349 \nmax values  : 49005.8382943034, 22568.8411539952, 509352591.034267,    3.7525953469342, 0.801815253056721 \n\n\nCode chunk below is used to extract SDF data table from gwss object output from gwss(). It will be converted into data.frame by using as.data.frame()\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\n\nNext, cbind() is used to append the newly derived data.frame onto hunan_sf sf data.frame in the code chunk below\n\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df)\n\n\ntm_shape(hunan_gstat) +\n  tm_fill(\"GDPPC_LM\",\n  n = 5,\n  style = \"quantile\") +\n  tm_borders(alpha = 0.5) +\n  tm_layout(main.title = \"Distribution of geographically weighted mean\",\n            main.title.position = \"center\",\n            main.title.size = 2.0,\n            legend.text.size = 1.2,\n            legend.height = 1.50,\n            legend.width = 1.50,\n            frame = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html",
    "href": "In-class_Ex/In-class_Ex10.html",
    "title": "In Class exercise 10",
    "section": "",
    "text": "pacman::p_load(spdep, sp, tmap, sf, ClustGeo, cluster, factoextra, NbClust, tidyverse, GGally)\n\n\nshan_sf &lt;- read_rds(\"data/In-class_Ex09/rds/shan_sf.rds\")\nshan_ict &lt;- read_rds(\"data/In-class_Ex09/rds/shan_ict.rds\")\nshan_sf_cluster &lt;- read_rds(\"data/In-class_Ex09/rds/shan_sf_cluster.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex10.html#loading-the-r-packages",
    "title": "In Class exercise 10",
    "section": "",
    "text": "pacman::p_load(spdep, sp, tmap, sf, ClustGeo, cluster, factoextra, NbClust, tidyverse, GGally)\n\n\nshan_sf &lt;- read_rds(\"data/In-class_Ex09/rds/shan_sf.rds\")\nshan_ict &lt;- read_rds(\"data/In-class_Ex09/rds/shan_ict.rds\")\nshan_sf_cluster &lt;- read_rds(\"data/In-class_Ex09/rds/shan_sf_cluster.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#conventional-hierarchical-clustering",
    "href": "In-class_Ex/In-class_Ex10.html#conventional-hierarchical-clustering",
    "title": "In Class exercise 10",
    "section": "6.1 Conventional Hierarchical Clustering",
    "text": "6.1 Conventional Hierarchical Clustering\nIn R, many packages provide functions to calculate distance matrix. We will compute the proximity matrix by using dist() of R.\ndist() supports six distance proximity calculations, they are: euclidean, maximum, manhattan, canberra, binary and minkowski. The default is euclidean proximity matrix.\nThe code chunk below is used to compute the proximity matrix using euclidean method.\n\nproxmat &lt;- dist(shan_ict, method = \"euclidean\")\nhclust_ward &lt;- hclust(proxmat, method = \"ward.D\")\ngroups &lt;- as.factor(cutree(hclust_ward, k=6))\n\nhclust() will take the proximity matrix to perform hierarchical clustering to create a hierarchical clustering object to get the the groups based on the cutree( method\nThis chunk of code is meant to tidy the shan_sf_cluster dataset\n\nshan_sf_cluster &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`CLUSTER`=`as.matrix.groups.`) %&gt;%\n  select(-c(3:4, 7:9)) %&gt;%\n  rename(TS = TS.x)\n\nThis chunk of code to create the dendogram\n\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, k = 6, border = 2.5)\n\n\n\n\n\n\n\n\nThis chunk of code to create the cluster map of the shan_sf_cluster object\n\nqtm(shan_sf_cluster, \"CLUSTER\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex10.html#spatially-constrained-clustering",
    "href": "In-class_Ex/In-class_Ex10.html#spatially-constrained-clustering",
    "title": "In Class exercise 10",
    "section": "Spatially Constrained Clustering",
    "text": "Spatially Constrained Clustering\n\nSKATER (Spatial ’K’luser Analysis by Tree Edge Removal) Alogrithm\nREDCAP (Reorganisation with dynamically\nClustGeo Algorithm\n\n\nSKATER Algorithm\nSpatially Constrained Clustering: SKATER Method\n\nComputing nearest neighbours (Minimum Spanning Tree)\n\n\nshan.nb &lt;- poly2nb(shan_sf)\nsummary(shan.nb)\n\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\n\n\nVisualising the neighbours\n\n\nplot(st_geometry(shan_sf),\n     border=grey(.5))\npts &lt;- st_coordinates(st_centroid(shan_sf))\nplot(shan.nb, pts, col=\"blue\", add=TRUE)\n\n\n\n\n\n\n\n\n\nComputing minimum spanning tree (MST)\n\n\nCalculating edge costs\n\n\nlcosts &lt;- nbcosts(shan.nb, shan_ict)\n\n\nIncorporating these costs into a weights object\n\n\nshan.w &lt;- nb2listw(shan.nb, lcosts, style = \"B\")\n\nsummary(shan.w)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n\n\n\nVisualising MST\n\n\nshan.mst &lt;- mstree(shan.w)\n\n\nplot(st_geometry(shan_sf), border=gray(.5))\nplot.mst(shan.mst, \n         pts, \n         col=\"blue\", \n         cex.lab=0.7, \n         cex.circles = 0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\nComputing spatially constrained clusters using SKATER method\n\nskater.clust6 &lt;- skater(edges = shan.mst[,1:2],\n                        data = shan_ict,\n                        method = \"euclidean\",\n                        ncuts = 5)\n\nThe following code chunk plots the skater tree\n\nplot(st_geometry(shan_sf), border=gray(.5))\nplot(skater.clust6, \n         pts, \n         cex.lab=.7,\n         groups.colors=c(\"red\", \"green\", \"blue\", \"brown\", \"pink\"),\n         cex.circles = 0.005, \n         add=TRUE)\n\n\n\n\n\n\n\n\nVisualising clusters in chloropeth map\n\ngroups_mat&lt;- as.matrix(skater.clust6$groups)\nshan_sf_spatialcluster &lt;- cbind(shan_sf_cluster, as.factor(groups_mat)) %&gt;%\n  rename(`skater_CLUSTER` = `as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n\n\n\n\n\n\n\n\n\n\nClustGeo Algoritm\n\nCompute Spatial Distance Matrix To compute the distance matrix using st_distance() of sf package.\n\n\ndist &lt;- st_distance(shan_sf, shan_sf)\ndistmat &lt;- as.dist(dist)\n\n\nCluster Graph\n\n\ncr &lt;- choicealpha(proxmat, distmat, \n                  range.alpha = seq(0, 1, 0.1), \n                  K=6, graph = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaving ClustGeo Output\n\n\nclustG &lt;- hclustgeo(proxmat, distmat, alpha = 0.2)\ngroups &lt;- as.factor(cutree(clustG, k=6))\nshan_sf_GclusterGeo &lt;- cbind(shan_sf, as.matrix(groups)) %&gt;%\n  rename(`clustGeo` = `as.matrix.groups.`)\n\nqtm(shan_sf_GclusterGeo, \"clustGeo\")\n\n\n\n\n\n\n\n\n\nCharacterising the Clusters\n\n\nggparcoord(data = shan_sf_GclusterGeo, \n           columns = c(17:21), \n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ clustGeo) + \n  theme(axis.text.x = element_text(angle = 30))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "Welcome to my IS415 Geospatial Analytics and Applications. In this website, you will find my coursework prepared for this course.\n\n\n\n\n\n\n\n\n\n\n\n\nGeospatial Data Science with R\n\n\n\n\n\n\nBrian Lim\n\n\nAug 16, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nThematic Mapping and GeoVisualisation with R\n\n\n\n\n\n\nBrian Lim\n\n\nAug 23, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n1st & 2nd Order Spatial Point Patterns Analysis Methods\n\n\n\n\n\n\nBrian Lim\n\n\nAug 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSpatial Weights and Applications\n\n\n\n\n\n\nBrian Lim\n\n\nSep 13, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGlobal and Local Measures of Spatial Autocorrelation\n\n\n\n\n\n\nBrian Lim\n\n\nSep 19, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeographical Segmentation with Spatially Constrained Clustering Techniques\n\n\n\n\n\n\nBrian Lim\n\n\nOct 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nSpatially Constrained Cluster Analysis\n\n\n\n\n\n\nBrian Lim\n\n\nOct 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nCalibrating Hedonic Pricing Model for Private Highrise Property with GWR Method\n\n\n\n\n\n\nBrian Lim\n\n\nOct 21, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nGeographically Weighted Predictive Models\n\n\n\n\n\n\nBrian Lim\n\n\nOct 28, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug abuse is associated with profound health, financial, and social consequences, making it a critical global issue. Despite numerous efforts to combat the problem, illicit drug use remains highly prevalent, affecting millions of people worldwide. In 2021, it was estimated that 1 in 17 individuals aged 15–64 had used a drug in the past 12 months, with the total number of drug users rising from 240 million in 2011 to 296 million in 2021.\nThailand, in particular, is in a unique geopolitical position near the Golden Triangle of Indochina—the largest drug production site in Asia. This, combined with ongoing transportation infrastructure development, has made Thailand not only a significant market for drug consumption but also a critical transit route for drug trafficking to other countries. As a result, the nation faces a growing challenge in managing the social and health issues associated with drug abuse.\nAmong Thailand’s youth population, drug abuse is a major social issue. With approximately 2.7 million youths involved in drug use, it is estimated that around 300,000 individuals aged between 15 and 19 require drug treatment. Alarmingly, drug involvement is particularly prevalent among vocational-school students, almost double that of secondary-school students, indicating that certain sub-populations may be at higher risk.\nGiven this context, the primary objective of this exercise is to explore whether key drug abuse indicators in Thailand are spatially independent or exhibit patterns of spatial dependence. Understanding these spatial dynamics is crucial for identifying clusters, outliers, and potential hotspots that can inform targeted interventions. Additionally, the temporal evolution of these spatial patterns from 2017 to 2022 will be analyzed to uncover trends and shifts over time.\nThis exercise aims to provide a comprehensive understanding of the spatial and temporal dynamics of drug abuse in Thailand. By identifying areas of concern and tracking their changes over time, the results can support policymakers and stakeholders in designing more effective, location-based strategies to mitigate the impact of drug abuse in the country."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#exercise-overview",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#exercise-overview",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "",
    "text": "Drug abuse is associated with profound health, financial, and social consequences, making it a critical global issue. Despite numerous efforts to combat the problem, illicit drug use remains highly prevalent, affecting millions of people worldwide. In 2021, it was estimated that 1 in 17 individuals aged 15–64 had used a drug in the past 12 months, with the total number of drug users rising from 240 million in 2011 to 296 million in 2021.\nThailand, in particular, is in a unique geopolitical position near the Golden Triangle of Indochina—the largest drug production site in Asia. This, combined with ongoing transportation infrastructure development, has made Thailand not only a significant market for drug consumption but also a critical transit route for drug trafficking to other countries. As a result, the nation faces a growing challenge in managing the social and health issues associated with drug abuse.\nAmong Thailand’s youth population, drug abuse is a major social issue. With approximately 2.7 million youths involved in drug use, it is estimated that around 300,000 individuals aged between 15 and 19 require drug treatment. Alarmingly, drug involvement is particularly prevalent among vocational-school students, almost double that of secondary-school students, indicating that certain sub-populations may be at higher risk.\nGiven this context, the primary objective of this exercise is to explore whether key drug abuse indicators in Thailand are spatially independent or exhibit patterns of spatial dependence. Understanding these spatial dynamics is crucial for identifying clusters, outliers, and potential hotspots that can inform targeted interventions. Additionally, the temporal evolution of these spatial patterns from 2017 to 2022 will be analyzed to uncover trends and shifts over time.\nThis exercise aims to provide a comprehensive understanding of the spatial and temporal dynamics of drug abuse in Thailand. By identifying areas of concern and tracking their changes over time, the results can support policymakers and stakeholders in designing more effective, location-based strategies to mitigate the impact of drug abuse in the country."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#data-acquisition",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#data-acquisition",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.2 Data Acquisition",
    "text": "2.2 Data Acquisition\nFor the purpose of this take-home exercise, two data sets shall be used, they are: Thailand Drug Offenses [2017-2022] at Kaggle. Thailand - Subnational Administrative Boundaries at HDX. You are required to use the province boundary data set."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#getting-started",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#getting-started",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.3 Getting Started",
    "text": "2.3 Getting Started\nFor this exercise, the following R packages will be used:\n\nsf for handling geospatial data.\nspatstat, a comprehensive package for point pattern analysis. We’ll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.\nraster, a package for reading, writing, manipulating, and modeling gridded spatial data (rasters). We will use it to convert image outputs generated by spatstat into raster format.\ntmap, a package for creating high-quality static and interactive maps, leveraging the Leaflet API for interactive visualizations.\ntidyverse for performing data science tasks such as importing, wrangling and visualising data.\nRColorBrewer for creating nice looking color palettes especially for thematic maps.\nspdep for spatial dependence analysis, including computing spatial weights and conducting spatial autocorrelation tests such as Moran’s I and Geary’s C\nsfdep for computing spatial weights, global and local spatial autocorrelation statistics\nggplot2 for data visualization within the tidyverse. It will be used for creating a variety of plots, including temporal line charts and exploratory data visualizations that complement spatial maps\n\nAs readr, tidyr and dplyr are part of tidyverse package. The code chunk below will suffice to install and load the required packages in RStudio.\nTo install and load these packages into the R environment, we use the p_load function from the pacman package:\n\npacman::p_load(sf, raster, spatstat, tmap, tidyverse, RColorBrewer, spdep, sfdep, ggplot2)"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#importing-data-into-r",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#importing-data-into-r",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.4 Importing Data into R",
    "text": "2.4 Importing Data into R\nNext, we will import the thai_drug_offenses_2017_2022.csv file into the R environment and save it into an R dataframe called acled_sf. The task can be performed using the read_csv() function from the readr package, as shown below:\n\nthai_drug_offenses &lt;- read.csv(\"data/archive/thai_drug_offenses_2017_2022.csv\")%&gt;% \n  select(-province_th)\n\n\ndrug_summary &lt;- thai_drug_offenses %&gt;%\n  group_by(fiscal_year, province_en, types_of_drug_offenses) %&gt;%\n  summarize(no_cases = sum(no_cases, na.rm = TRUE), .groups = 'drop')\n\n\n\n\n\n\n\nNotes\n\n\n\nWe used the select() function to ensure that the province_th column is not included in the dataframe.\nWe then perform summary operation on the thai_drug_offenses dataset:\n\nGrouping: The data is grouped by fiscal_year, province_en, and types_of_drug_offenses, which organizes the data by year, province, and type of drug offense.\nSummarizing: For each group, it calculates the total number of cases (no_cases) by summing them while ignoring any missing values (na.rm = TRUE).\nOutput: The resulting drug_summary dataset will contain the summarized number of drug offense cases (no_cases) for each combination of year, province, and offense type.\n\nThe .groups = 'drop' argument ensures that the grouping is removed from the final summarized data.\n\n\nWe then import the boundaries and provinces of Thailand using the st_read() function to import the tha_adm_rtsd_itos_20210121_shp shapefile into R as a simple feature data frame named regions_sf. We also check the validity of the imported dataset, ensuring that it is in the right format with the st_crs() function:\n\nregions_sf &lt;- st_read(dsn = \"data/tha_adm_rtsd_itos_20210121_shp\", \n                layer = \"tha_admbnda_adm1_rtsd_20220121\")\n\nReading layer `tha_admbnda_adm1_rtsd_20220121' from data source \n  `C:\\Users\\blzll\\OneDrive\\Desktop\\Y3S1\\IS415\\Quarto\\IS415\\Take-home_ex\\Take-home_ex02\\data\\tha_adm_rtsd_itos_20210121_shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 77 features and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n\nst_crs(regions_sf)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#data-wrangling",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#data-wrangling",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.5 Data Wrangling",
    "text": "2.5 Data Wrangling\nBefore proceed we will do some data wrangling, this step primarily consist of checking for possible mismatches due to differences in the imported datasets. We will create a function to identify this.\n\n# Function to check province differences\nprov_diff &lt;- function(thai_drug_offenses_provinces, regions_sf_provinces) {\n  # Create sets for efficient comparison\n  drug_set &lt;- unique(thai_drug_offenses_provinces)\n  regions_set &lt;- unique(regions_sf_provinces)\n  \n  # Check for mismatches\n  missing_in_regions &lt;- setdiff(drug_set, regions_set)\n  missing_in_drug &lt;- setdiff(regions_set, drug_set)\n  \n  if (length(missing_in_regions) == 0 && length(missing_in_drug) == 0) {\n    cat(\"All province names match.\\n\")\n  } else {\n    cat(\"There are mismatches in province names.\\n\")\n    if (length(missing_in_regions) &gt; 0) {\n      cat(\"Missing in regions_sf:\", paste(missing_in_regions, collapse = \", \"), \"\\n\")\n    }\n    if (length(missing_in_drug) &gt; 0) {\n      cat(\"Missing in drug_sf:\", paste(missing_in_drug, collapse = \", \"), \"\\n\")\n    }\n  }\n}\n\nprov_diff(unique(thai_drug_offenses$province_en), unique(regions_sf$ADM1_EN))\n\nThere are mismatches in province names.\nMissing in regions_sf: Loburi, buogkan \nMissing in drug_sf: Lop Buri, Bueng Kan \n\n\nBased on the derived results, we would need to reassign the misaligned values such that they match exactly. In the code chunk below, we will perform the reassignment in the regions_sf\n\nthai_drug_offenses &lt;- thai_drug_offenses %&gt;%\n  mutate(province_en = case_when(\n    province_en == \"Loburi\" ~ \"Lop Buri\",\n    province_en == \"buogkan\" ~ \"Bueng Kan\",\n    TRUE ~ province_en\n  ))\n\nprov_diff(unique(thai_drug_offenses$province_en), unique(regions_sf$ADM1_EN))\n\nAll province names match.\n\n\nWe will then join both datasets togther based on the province_en and ADM1_EN columns\n\ndrug_region_1 &lt;- left_join(thai_drug_offenses, regions_sf, by = c(\"province_en\" = \"ADM1_EN\")) %&gt;%\n  select(1:6, \"date\", \"geometry\")\n\nWe then perform data validation checks on the newly created drug_region_1 dataset, checking for missing values in key columns: geometry, province_en, types_of_drug_offenses, and no_cases. It uses the summarise() function to count how many NA values exist in each of these columns, helping to identify any incomplete or missing data.\n\n# Check for null values in key columns\nna_count &lt;- drug_region_1 %&gt;%\n  summarise(na_geometry = sum(is.na(geometry)),\n            na_province = sum(is.na(province_en)),\n            na_drug_offense = sum(is.na(types_of_drug_offenses)),\n            na_cases = sum(is.na(no_cases)))\n\nprint(na_count)\n\n  na_geometry na_province na_drug_offense na_cases\n1           0           0               0        0\n\n\nWe then look for duplicate rows by grouping the data by province_en, fiscal_year, and types_of_drug_offenses. If any rows have the same combination of these fields (i.e., they are duplicates), they will be filtered and displayed; otherwise, a message indicating no duplicates will be printed. These steps ensure data quality before proceeding with any spatial or statistical analysis.\n\nduplicates &lt;- drug_region_1 %&gt;%\n  group_by(province_en, fiscal_year, types_of_drug_offenses) %&gt;%\n  filter(n() &gt; 1) %&gt;%\n  ungroup()\n\nif (nrow(duplicates) &gt; 0) {\n  cat(\"Duplicates found:\\n\")\n  print(duplicates)\n} else {\n  cat(\"No duplicates found.\\n\")\n}\n\nNo duplicates found.\n\n\nWe then ensure that drug_region_1 is an sf object by using the st_crs() function, which returns the coordinate reference system (CRS) if the object is spatial, converting the drug_region_1 data frame into an sf object using st_as_sf(), specifying EPSG:4326 as the CRS. This corresponds to the WGS 84 geographic coordinate system which is suitable for country of Thailand. This conversion is necessary to perform spatial analysis, as it ensures the dataset includes spatial information with proper geographic coordinates.\n\n# check if drug_region_1 is an sf object\nst_crs(drug_region_1)\n\nCoordinate Reference System: NA\n\n\n\n# Convert data frame to sf object and specify the CRS (EPSG:4326)\ndrug_region_thailand_sf &lt;- st_as_sf(drug_region_1, crs = 4326)\n\n\nwrite_rds(drug_region_thailand_sf, \"data/rds/drug_region_thailand_sf.rds\")\ndrug_region_thailand_sf &lt;- read_rds(\"data/rds/drug_region_thailand_sf.rds\")"
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#global-measures-of-spatial-autocorrelation",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#global-measures-of-spatial-autocorrelation",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.6 Global Measures of Spatial Autocorrelation",
    "text": "2.6 Global Measures of Spatial Autocorrelation\nGlobal measures of spatial autocorrelation, such as Moran’s I and Geary’s C, are critical in understanding the overall spatial structure of geographic data. They help detect patterns of clustering or dispersion by assessing whether similar values occur near each other across an entire study area. This insight is essential for identifying spatial dependencies and guiding decisions in fields like epidemiology, economics, and environmental science. By quantifying spatial relationships on a broad scale, global measures provide a foundational perspective for spatial analysis.\n\nnum_colors &lt;- length(unique(regions_sf$ADM1_EN))\ncolors &lt;- brewer.pal(n = num_colors, name = \"Set1\")\n\n# as there are 77 provinces in thailand\ntmap_options(max.categories = 77)\n\ntm_shape(regions_sf) +\n  tm_polygons(col = \"ADM1_EN\", palette = colors) +\n  tm_layout(main.title = \"Provinces in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.6,\n            legend.outside = TRUE) +\n  tm_legend(title = \"Provinces\")\n\n\n\n\n\n\n\n\n\n2.6.1 Defining Scope of Analysis\nTo ensure a data-driven analysis of drug-related offenses, we aim to focus exclusively on cases that have resulted in concrete legal outcomes, such as convictions or possession cases. cases based solely on suspicion may not lead to prosecution or final legal action, potentially inflating the data without accurately reflecting the true extent of confirmed criminal activity. By narrowing our scope to finalized or substantiated cases, we intend to provide more reliable insights into the patterns of drug-related crime and its impact.\n\n# Group by types_of_drug_offenses and summarize by summing the no_cases\ntop_drug_offenses &lt;- thai_drug_offenses %&gt;%\n  filter(!grepl(\"suspect\", types_of_drug_offenses, ignore.case = TRUE)) %&gt;%\n  group_by(types_of_drug_offenses) %&gt;%\n  summarise(total_cases = sum(no_cases, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_cases))\n\n# View non-suspicion based types of drug offenses\ntop_drug_offenses\n\n# A tibble: 8 × 2\n  types_of_drug_offenses                     total_cases\n  &lt;chr&gt;                                            &lt;int&gt;\n1 drug_use_cases                                  915529\n2 possession_cases                                538893\n3 possession_with_intent_to_distribute_cases      341283\n4 trafficking_cases                                68379\n5 production_cases                                 56892\n6 conspiracy_cases                                   920\n7 import_cases                                       860\n8 export_cases                                        84\n\n\nWe are further refining our analysis exclusively on drug use cases. This choice is driven by the nature of these offenses, which represent direct instances of illicit drug consumption and are critical to understanding the broader context of drug-related issues in Thailand. Unlike cases that involve suspicion or potential possession, drug use cases have clear legal implications and societal impacts, making them essential for our analysis. By focusing solely on these confirmed instances, we aim to provide accurate insights into the patterns of drug use and its repercussions.\n\ndrug_region_thailand_sf &lt;- drug_region_thailand_sf %&gt;% filter(types_of_drug_offenses == \"drug_use_cases\")\n\nFocusing exclusively on drug use cases allows us to concentrate our efforts on a significant area of concern, thereby providing clearer recommendations for law enforcement and policy development. This targeted approach ensures that our insights align with the most impactful drug-related offenses, facilitating more effective interventions and resource allocation.\n\nregion_2017_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2017)\nregion_2018_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2018)\nregion_2019_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2019)\nregion_2020_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2020)\nregion_2021_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2021)\nregion_2022_sf &lt;- drug_region_thailand_sf %&gt;% filter(fiscal_year == 2022)\n\n\n\n2.6.2 Computing Contiguity Neighbours\n\nYear 2017\n\nthailand_nb_q &lt;- st_contiguity(region_2017_sf, queen=TRUE)\nsummary(thailand_nb_q)\n\nNeighbour list object:\nNumber of regions: 77 \nNumber of nonzero links: 352 \nPercentage nonzero weights: 5.93692 \nAverage number of links: 4.571429 \n1 region with no links:\n68\n2 disjoint connected subgraphs\nLink number distribution:\n\n 0  1  2  3  4  5  6  7  8  9 \n 1  1  5 17 15 17 10  5  4  2 \n1 least connected region:\n14 with 1 link\n2 most connected regions:\n28 48 with 9 links\n\n\n1 region with no links can be observed in the summary above. This is due to the island province of Phuket having no direct land neighbours, and being connected to Phangnga province via a bridge. As such, we can manually assign Phuket a neighbor, Phangnga, to help avoid issues in the spatial analysis, particularly with Moran’s I, which requires each region to have at least one neighbor.\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame.\n\nphuket_index &lt;- which(region_2017_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2017_sf$province_en == \"Phangnga\")\n\nPurpose: This code modifies the neighborhood relationship between “Phuket” and “Phangnga” by manually assigning them as neighbors to each other within the thailand_nb_q object.\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\nAs seen from the summary above all regions are linked and have at least 1 neighbour\n\n\nComputing Row-Standardised Weight Matrix\nNext, we need to assign spatial weights to each neighboring polygon.\nst_weights() function from sfdep packge can be used to supplement a neighbour list with spatial weights based on the chosen coding scheme. There are as least 5 different coding scheme styles supported by this function:\n\nB is the basic binary coding\nW is row standardised (sums over all links to n)\nC is globally standardised (sums over all links to n)\nU is equal to C divided by the number of neighbours (sums over all links to unity)\nS is the variance-stabilizing coding scheme proposed by Tiefelsdorf et al. (1999) (sums over all links to n).\n\nIn this study, we will use row-standardised weight matrix (style=\"W\"). Row standardisation of a matrix ensure that the sum of the values across each row add up to 1. This is accomplished by assigning the fraction 1/(# of neighbors) to each neighboring county then summing the weighted income values. Row standardisation ensures that all weights are between 0 and 1. This facilities the interpretation of operation with the weights matrix as an averaging of neighboring values, and allows for the spatial parameter used in our analyses to be comparable between models.\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe will mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2017_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2017 &lt;- region_2017_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2017$no_cases,\n                        wm_q_2017$nb,\n                        wm_q_2017$wt)\nmoranI\n\n$I\n[1] 0.08216344\n\n$K\n[1] 30.4821\n\n\n\n\n\nglobal_moran_test_2017 &lt;- global_moran_test(wm_q_2017$no_cases,\n                            wm_q_2017$nb,\n                            wm_q_2017$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2017_statistics &lt;- global_moran_test_2017$estimate[\"Moran I statistic\"]\nglobal_moran_test_2017_p_value &lt;- global_moran_test_2017$p.value\nglobal_moran_test_2017\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.5745, p-value = 0.05768\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.082163436      -0.013157895       0.003665038 \n\n\nFor the year of 2017, the Moran I statistic shows slight positive spatial autocorrelation, meaning there is some clustering of similar values of drug-related cases, but this clustering is weak and not statistically significant at the 5% level (though close, with a p-value of 0.0577). There is weak evidence suggesting that nearby provinces might have similar levels of drug-related cases, but the relationship is not strong enough to definitively conclude spatial clustering. As such, further investigation is needed to show stronger spatial autocorrelation.\n\n\n\nset.seed(4242)\ngmoranMC_2017 &lt;- global_moran_perm(wm_q_2017$no_cases,\n                  wm_q_2017$nb,\n                  wm_q_2017$wt,\n                  nsim = 999)\ngmoranMC_2017\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.082163, observed rank = 933, p-value = 0.134\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2017 &lt;- global_c_test(wm_q_2017$no_cases,\n                                    wm_q_2017$nb,\n                                    wm_q_2017$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2017_statistics &lt;- global_c_test_2017$estimate [\"Geary C statistic\"]\nglobal_c_test_2017_p_value &lt;- global_c_test_2017$p.value\nglobal_c_test_2017\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = -0.17983, p-value = 0.5714\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       1.02584500        1.00000000        0.02065461 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2017 &lt;- global_c_perm(wm_q_2017$no_cases,\n                  wm_q_2017$nb,\n                  wm_q_2017$wt,\n                  nsim = 999)\nbperm_2017\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 1.0258, observed rank = 565, p-value = 0.565\nalternative hypothesis: greater\n\n\n\n\n\n\n\nYear 2018\nSimilar that of 2017, we will compute a contiguity weight matrix for the study area, assigning spatial weights to each neighboring polygon, while also manually assigning “Phuket” and “Phangnga” as neighbours.\n\nthailand_nb_q &lt;- st_contiguity(region_2018_sf, queen=TRUE)\n\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame, assigning them as neighbors to each other within the thailand_nb_q object.\n\nphuket_index &lt;- which(region_2018_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2018_sf$province_en == \"Phangnga\")\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\n\n\nComputing Row-Standardised Weight Matrix\nUsing the contiguity weight matrix, we will use row-standardised weight matrix (style = “W”).\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe then mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2018_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2018 &lt;- region_2018_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2018$no_cases,\n                        wm_q_2018$nb,\n                        wm_q_2018$wt)\nmoranI\n\n$I\n[1] 0.09520252\n\n$K\n[1] 27.02001\n\n\n\n\n\nglobal_moran_test_2018 &lt;- global_moran_test(wm_q_2018$no_cases,\n                            wm_q_2018$nb,\n                            wm_q_2018$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2018_statistics &lt;- global_moran_test_2018$estimate[\"Moran I statistic\"]\nglobal_moran_test_2018_p_value &lt;- global_moran_test_2018$p.value\nglobal_moran_test_2018\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.7246, p-value = 0.0423\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.095202524      -0.013157895       0.003947668 \n\n\nIn 2018, the results of the Moran’s I test reveal a slight positive spatial autocorrelation for drug-related cases in Thailand, indicated by a Moran I statistic of 0.0952. This suggests that there is some degree of clustering among provinces with similar levels of drug-related incidents. However, the significance of this clustering is marginal, as evidenced by the p-value of 0.0423, which is just below the conventional threshold of 0.05 for statistical significance.\nWhile the results imply a weak tendency for nearby provinces to exhibit similar drug-related case counts, the evidence is insufficient to draw definitive conclusions about robust spatial clustering. The expectation value of -0.0132 and variance of 0.0039 further support the interpretation that, although there are clusters present, they do not exhibit a strong or clear pattern. This indicates a need for additional analyses or data to better understand the underlying dynamics of drug use in the region. Authorities may consider more detailed investigations to explore factors influencing these patterns, such as socio-economic conditions, access to treatment, or enforcement measures in surrounding areas.\n\n\n\nset.seed(4242)\ngmoranMC_2018 &lt;- global_moran_perm(wm_q_2018$no_cases,\n                  wm_q_2018$nb,\n                  wm_q_2018$wt,\n                  nsim = 999)\ngmoranMC_2018\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.095203, observed rank = 943, p-value = 0.114\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2018 &lt;- global_c_test(wm_q_2018$no_cases,\n                                    wm_q_2018$nb,\n                                    wm_q_2018$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2018_statistics &lt;- global_c_test_2018$estimate [\"Geary C statistic\"]\nglobal_c_test_2018_p_value &lt;- global_c_test_2018$p.value\nglobal_c_test_2018\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = -0.026547, p-value = 0.5106\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       1.00365196        1.00000000        0.01892375 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2018 &lt;- global_c_perm(wm_q_2018$no_cases,\n                  wm_q_2018$nb,\n                  wm_q_2018$wt,\n                  nsim = 999)\nbperm_2018\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 1.0037, observed rank = 524, p-value = 0.524\nalternative hypothesis: greater\n\n\n\n\n\n\n\nYear 2019\nSimilar that of the previous years, we will compute a contiguity weight matrix for the study area, assigning spatial weights to each neighboring polygon, while also manually assigning “Phuket” and “Phangnga” as neighbours.\n\nthailand_nb_q &lt;- st_contiguity(region_2019_sf, queen=TRUE)\n\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame, assigning them as neighbors to each other within the thailand_nb_q object.\n\nphuket_index &lt;- which(region_2019_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2019_sf$province_en == \"Phangnga\")\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\n\n\nComputing Row-Standardised Weight Matrix\nUsing the contiguity weight matrix, we will use row-standardised weight matrix (style = “W”).\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe then mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2018_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2019 &lt;- region_2019_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2019$no_cases,\n                        wm_q_2019$nb,\n                        wm_q_2019$wt)\nmoranI\n\n$I\n[1] 0.1410203\n\n$K\n[1] 13.70039\n\n\n\n\n\nglobal_moran_test_2019 &lt;- global_moran_test(wm_q_2019$no_cases,\n                            wm_q_2019$nb,\n                            wm_q_2019$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2019_statistics &lt;- global_moran_test_2019$estimate[\"Moran I statistic\"]\nglobal_moran_test_2019_p_value &lt;- global_moran_test_2019$p.value\nglobal_moran_test_2019\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.1728, p-value = 0.0149\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.141020279      -0.013157895       0.005035023 \n\n\nIn 2019, the results of the Moran’s I test indicate a moderate positive spatial autocorrelation for drug-related cases in Thailand, reflected by a Moran I statistic of 0.1410. This suggests a more pronounced clustering effect, where nearby provinces are likely to have similar levels of drug-related incidents.\nThe p-value of 0.0149 is statistically significant, indicating that the observed clustering is unlikely to be due to random chance at the 5% significance level. This finding reinforces the notion that there are regions in Thailand where drug-related cases are concentrated, pointing to potential hotspots that may require targeted interventions.\n\n\n\nset.seed(4242)\ngmoranMC_2019 &lt;- global_moran_perm(wm_q_2019$no_cases,\n                  wm_q_2019$nb,\n                  wm_q_2019$wt,\n                  nsim = 999)\ngmoranMC_2019\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.14102, observed rank = 975, p-value = 0.05\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2019 &lt;- global_c_test(wm_q_2019$no_cases,\n                                    wm_q_2019$nb,\n                                    wm_q_2019$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2019_statistics &lt;- global_c_test_2019$estimate [\"Geary C statistic\"]\nglobal_c_test_2019_p_value &lt;- global_c_test_2019$p.value\nglobal_c_test_2019\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 0.7522, p-value = 0.226\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       0.91669667        1.00000000        0.01226465 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2019 &lt;- global_c_perm(wm_q_2019$no_cases,\n                  wm_q_2019$nb,\n                  wm_q_2019$wt,\n                  nsim = 999)\nbperm_2019\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.9167, observed rank = 204, p-value = 0.204\nalternative hypothesis: greater\n\n\n\n\n\n\n\nYear 2020\nSimilar that of the previous years, we will compute a contiguity weight matrix for the study area, assigning spatial weights to each neighboring polygon, while also manually assigning “Phuket” and “Phangnga” as neighbours.\n\nthailand_nb_q &lt;- st_contiguity(region_2020_sf, queen=TRUE)\n\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame, assigning them as neighbors to each other within the thailand_nb_q object.\n\nphuket_index &lt;- which(region_2020_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2020_sf$province_en == \"Phangnga\")\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\n\n\nComputing Row-Standardised Weight Matrix\nUsing the contiguity weight matrix, we will use row-standardised weight matrix (style = “W”).\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe then mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2018_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2020 &lt;- region_2020_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2020$no_cases,\n                        wm_q_2020$nb,\n                        wm_q_2020$wt)\nmoranI\n\n$I\n[1] 0.0874654\n\n$K\n[1] 10.43646\n\n\n\n\n\nglobal_moran_test_2020 &lt;- global_moran_test(wm_q_2020$no_cases,\n                            wm_q_2020$nb,\n                            wm_q_2020$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2020_statistics &lt;- global_moran_test_2020$estimate[\"Moran I statistic\"]\nglobal_moran_test_2020_p_value &lt;- global_moran_test_2020$p.value\nglobal_moran_test_2020\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 1.382, p-value = 0.08349\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.087465400      -0.013157895       0.005301475 \n\n\nFor the year 2020, the results of the Moran’s I test reveal a slight positive spatial autocorrelation for drug-related cases in Thailand, with a Moran I statistic of 0.0875. This indicates that there is some level of clustering of similar values, although the strength of this clustering is weak.\nThe p-value of 0.08349 suggests that the observed spatial autocorrelation is not statistically significant at the conventional 5% level, indicating that the clustering might be due to random chance rather than a definitive spatial pattern. Despite being close to significance, this p-value reflects uncertainty regarding the presence of meaningful spatial clusters.\nWith an expectation value of -0.0132 and a variance of 0.0053, the results imply that while there is a slight tendency for neighboring provinces to exhibit similar drug-related cases, the evidence is insufficient to draw strong conclusions about spatial clustering. Authorities may need to continue monitoring drug-related incidents in this year, as the potential for clustering exists, but further analysis and data may be required to identify any significant patterns or trends.\n\n\n\nset.seed(4242)\ngmoranMC_2020 &lt;- global_moran_perm(wm_q_2020$no_cases,\n                  wm_q_2020$nb,\n                  wm_q_2020$wt,\n                  nsim = 999)\ngmoranMC_2020\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.087465, observed rank = 903, p-value = 0.194\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2020 &lt;- global_c_test(wm_q_2020$no_cases,\n                                    wm_q_2020$nb,\n                                    wm_q_2020$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2020_statistics &lt;- global_c_test_2020$estimate [\"Geary C statistic\"]\nglobal_c_test_2020_p_value &lt;- global_c_test_2020$p.value\nglobal_c_test_2020\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 0.45817, p-value = 0.3234\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       0.95275528        1.00000000        0.01063286 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2020 &lt;- global_c_perm(wm_q_2020$no_cases,\n                  wm_q_2020$nb,\n                  wm_q_2020$wt,\n                  nsim = 999)\nbperm_2020\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.95276, observed rank = 308, p-value = 0.308\nalternative hypothesis: greater\n\n\n\n\n\n\n\nYear 2021\nSimilar that of the previous years, we will compute a contiguity weight matrix for the study area, assigning spatial weights to each neighboring polygon, while also manually assigning “Phuket” and “Phangnga” as neighbours.\n\nthailand_nb_q &lt;- st_contiguity(region_2021_sf, queen=TRUE)\n\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame, assigning them as neighbors to each other within the thailand_nb_q object.\n\nphuket_index &lt;- which(region_2021_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2021_sf$province_en == \"Phangnga\")\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\n\n\nComputing Row-Standardised Weight Matrix\nUsing the contiguity weight matrix, we will use row-standardised weight matrix (style = “W”).\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe then mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2018_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2021 &lt;- region_2021_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2021$no_cases,\n                        wm_q_2021$nb,\n                        wm_q_2021$wt)\nmoranI\n\n$I\n[1] 0.2012584\n\n$K\n[1] 4.710498\n\n\n\n\n\nglobal_moran_test_2021 &lt;- global_moran_test(wm_q_2021$no_cases,\n                            wm_q_2021$nb,\n                            wm_q_2021$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2021_statistics &lt;- global_moran_test_2021$estimate[\"Moran I statistic\"]\nglobal_moran_test_2021_p_value &lt;- global_moran_test_2021$p.value\nglobal_moran_test_2021\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.823, p-value = 0.002379\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.201258399      -0.013157895       0.005768917 \n\n\nFor the year 2021, the results of the Moran’s I test demonstrate a significant positive spatial autocorrelation for drug-related cases in Thailand, with a Moran I statistic of 0.2013. This indicates a notable clustering of similar values, suggesting that provinces with higher drug-related cases are concentrated near each other.\nThe p-value of 0.002379 is highly significant, well below the conventional 5% threshold, which provides strong evidence against the null hypothesis of randomness. This result suggests that the observed clustering is not likely to be due to chance, indicating a robust spatial pattern in drug-related incidents.\nWith an expectation value of -0.0132 and a variance of 0.0058, the findings imply a strong tendency for neighboring provinces to exhibit similar levels of drug-related cases. The identified clustering may warrant focused interventions and policy responses from authorities to address the growing concentration of drug-related issues in these regions. Such targeted strategies could be crucial in mitigating the potential escalation of drug-related activities in the identified hotspots.\n\n\n\nset.seed(4242)\ngmoranMC_2021 &lt;- global_moran_perm(wm_q_2021$no_cases,\n                  wm_q_2021$nb,\n                  wm_q_2021$wt,\n                  nsim = 999)\ngmoranMC_2021\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.20126, observed rank = 993, p-value = 0.014\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2021 &lt;- global_c_test(wm_q_2021$no_cases,\n                                    wm_q_2021$nb,\n                                    wm_q_2021$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2021_statistics &lt;- global_c_test_2021$estimate [\"Geary C statistic\"]\nglobal_c_test_2021_p_value &lt;- global_c_test_2021$p.value\nglobal_c_test_2021\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 1.7139, p-value = 0.04328\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n       0.84892396        1.00000000        0.00777019 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2021 &lt;- global_c_perm(wm_q_2021$no_cases,\n                  wm_q_2021$nb,\n                  wm_q_2021$wt,\n                  nsim = 999)\nbperm_2021\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.84892, observed rank = 35, p-value = 0.035\nalternative hypothesis: greater\n\n\n\n\n\n\n\nYear 2022\nSimilar that of the previous years, we will compute a contiguity weight matrix for the study area, assigning spatial weights to each neighboring polygon, while also manually assigning “Phuket” and “Phangnga” as neighbours.\n\nthailand_nb_q &lt;- st_contiguity(region_2022_sf, queen=TRUE)\n\nThe following code chunk finds the index positions of the provinces “Phuket” and “Phangnga” within the region_2017_sf spatial data frame, assigning them as neighbors to each other within the thailand_nb_q object.\n\nphuket_index &lt;- which(region_2022_sf$province_en == \"Phuket\")\nphangnga_index &lt;- which(region_2022_sf$province_en == \"Phangnga\")\n\nthailand_nb_q[phuket_index][1] &lt;- phangnga_index\nthailand_nb_q[phangnga_index][2] &lt;- phuket_index\n\n\n\nComputing Row-Standardised Weight Matrix\nUsing the contiguity weight matrix, we will use row-standardised weight matrix (style = “W”).\n\nthailand_wm_rs &lt;- st_weights(thailand_nb_q, style = \"W\")\n\nWe then mutate the newly created neighbour list object thailand_nb_q and weight matrix thailand_wm_rs into our existing region_2018_sf. The result will be a new object, which we will call wm_q_&lt;current-year&gt;.\n\nwm_q_2022 &lt;- region_2022_sf %&gt;%\n  mutate(nb = thailand_nb_q,\n         wt = thailand_wm_rs,\n         .before = 1) \n\n\n\nGlobal Moran’s I\n\nGlobal Moran’s IGlobal Moran’s I testGlobal Moran’s I permutation test\n\n\n\nmoranI &lt;- global_moran(wm_q_2022$no_cases,\n                        wm_q_2022$nb,\n                        wm_q_2022$wt)\nmoranI\n\n$I\n[1] 0.2133052\n\n$K\n[1] 3.883933\n\n\n\n\n\nglobal_moran_test_2022 &lt;- global_moran_test(wm_q_2022$no_cases,\n                            wm_q_2022$nb,\n                            wm_q_2022$wt,\n                            alternative = \"greater\")\nglobal_moran_test_2022_statistics &lt;- global_moran_test_2022$estimate[\"Moran I statistic\"]\nglobal_moran_test_2022_p_value &lt;- global_moran_test_2022$p.value\nglobal_moran_test_2022\n\n\n    Moran I test under randomisation\n\ndata:  x  \nweights: listw    \n\nMoran I statistic standard deviate = 2.9643, p-value = 0.001517\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.213305190      -0.013157895       0.005836395 \n\n\nFor the year 2022, the Moran’s I test results indicate a significant positive spatial autocorrelation in drug-related cases in Thailand, with a Moran I statistic of 0.2133. This suggests a strong clustering of similar values, indicating that provinces with high rates of drug-related cases are likely situated near other high-rate provinces.\nThe p-value of 0.001517 is highly significant, well below the 5% threshold, providing robust evidence against the null hypothesis of randomness. This strong clustering suggests that the pattern of drug-related incidents is not due to chance but rather reflects systematic geographical trends.\nWith an expectation value of -0.0132 and a variance of 0.0058, these findings underscore the importance of focusing intervention efforts on the identified clusters. The continued presence of significant spatial autocorrelation in drug-related cases across the years highlights the necessity for targeted policies and interventions in these areas to effectively address and mitigate the ongoing drug-related issues in Thailand.\n\n\n\nset.seed(4242)\ngmoranMC_2022 &lt;- global_moran_perm(wm_q_2022$no_cases,\n                  wm_q_2022$nb,\n                  wm_q_2022$wt,\n                  nsim = 999)\ngmoranMC_2022\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.21331, observed rank = 995, p-value = 0.01\nalternative hypothesis: two.sided\n\n\n\n\n\n\n\nGlobal Geary’s C\nIntroduced by Geary, Geary’s C statistic studies the degree of intensity of a given feature in spatial objects described with the use of a weight matrix. Similarly to Moran’s analysis, Geary’s C can be used to quantify the extent of spatial autocorrelation in the data.\n\nGlobal Geary’s C testGlobal Geary’s C Permutation Test\n\n\nThe Global Geary’s C test, which can be implemented using the global_c_test() function from the sfdep package.\n\nglobal_c_test_2022 &lt;- global_c_test(wm_q_2022$no_cases,\n                                    wm_q_2022$nb,\n                                    wm_q_2022$wt,\n                                    alternative = \"greater\")\nglobal_c_test_2022_statistics &lt;- global_c_test_2022$estimate [\"Geary C statistic\"]\nglobal_c_test_2022_p_value &lt;- global_c_test_2022$p.value\nglobal_c_test_2022\n\n\n    Geary C test under randomisation\n\ndata:  x \nweights: listw   \n\nGeary C statistic standard deviate = 1.8924, p-value = 0.02922\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n      0.837683654       1.000000000       0.007356952 \n\n\n\n\nSimilar to what we did in Moran’s I test, we will use global_c_perm() function from sfdep package with nsim = 999 which represent 1000 Monte Carlo simulations to be carried out.\n\nset.seed(4242)\nbperm_2022 &lt;- global_c_perm(wm_q_2022$no_cases,\n                  wm_q_2022$nb,\n                  wm_q_2022$wt,\n                  nsim = 999)\nbperm_2022\n\n\n    Monte-Carlo simulation of Geary C\n\ndata:  x \nweights: listw  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.83768, observed rank = 27, p-value = 0.027\nalternative hypothesis: greater\n\n\n\n\n\n\n\n\n2.6.3 Global Moran’s I Permutation test\n\n# List of gmoranMC objects for each year\ngmoranMC_list &lt;- list(gmoranMC_2017, gmoranMC_2018, gmoranMC_2019, \n                      gmoranMC_2020, gmoranMC_2021, gmoranMC_2022)\n\n# Corresponding year labels for the titles\nyear_labels &lt;- c(\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\")\n\n# Set up the plotting area to have 3 rows and 2 columns for the six histograms\npar(mfrow = c(3, 2))\n\n# Loop through each year and plot the histogram\nfor (i in 1:length(gmoranMC_list)) {\n  gmoranMC &lt;- gmoranMC_list[[i]]\n  year &lt;- year_labels[i]\n  \n  # Plot the histogram for the current year\n  hist(gmoranMC$res, \n       main = paste(\"Global Moran's I MC Results\", year), \n       breaks = 20,\n       xlab = \"Monte-Carlo Results\", \n       ylab = \"Frequency\")\n  \n  # Add a vertical line for the observed Moran's I statistic\n  abline(v = gmoranMC$statistic, col = \"red\")\n}\n\n\n\n\n\n\n\n\n\n\n2.6.4 Global Geary’s C Permutation test\n\n# List of bperm objects for each year\ngmoranMC_list &lt;- list(bperm_2017, bperm_2018, bperm_2019, \n                      bperm_2020, bperm_2021, bperm_2022)\n\n# Corresponding year labels for the titles\nyear_labels &lt;- c(\"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\")\n\n# Set up the plotting area to have 3 rows and 2 columns for the six histograms\npar(mfrow = c(3, 2))\n\n# Loop through each year and plot the histogram\nfor (i in 1:length(gmoranMC_list)) {\n  gmoranMC &lt;- gmoranMC_list[[i]]\n  year &lt;- year_labels[i]\n  \n  # Plot the histogram for the current year\n  hist(gmoranMC$res, \n       main = paste(\"Global Moran's I MC Results\", year),\n       breaks = 20,\n       xlab = \"Monte-Carlo Results\", \n       ylab = \"Frequency\")\n  \n  # Add a vertical line for the observed Moran's I statistic\n  abline(v = gmoranMC$statistic, col = \"red\")\n}\n\n\n\n\n\n\n\n\n\n\n2.6.5 Temporal Trends (2017-2022)\nWe can then analyze the spatial patterns of drug-related cases in Thailand over the period from 2017 to 2022 using Moran’s I and Geary’s C global spatial autocorrelation tests. The Moran’s I statistic identifies whether similar case values are clustered across regions, while Geary’s C focuses on local-level similarity, both crucial in understanding the distribution of drug-related offenses over time.\n\n# Create a data frame to store Moran's I statistics and p-values\nmoran_i_results &lt;- data.frame(\n  Year = c(2017, 2018, 2019, 2020, 2021, 2022),\n  Moran_I_Stat = c(global_moran_test_2017_statistics, global_moran_test_2018_statistics,\n                   global_moran_test_2019_statistics, global_moran_test_2020_statistics,\n                   global_moran_test_2021_statistics, global_moran_test_2022_statistics),\n  Moran_I_p_value = c(global_moran_test_2017_p_value, global_moran_test_2018_p_value,\n                      global_moran_test_2019_p_value, global_moran_test_2020_p_value,\n                      global_moran_test_2021_p_value, global_moran_test_2022_p_value)\n)\n\n# Consolidate the Geary C test data into a data frame\ngeary_c_results &lt;- data.frame(\n  Year = c(2017, 2018, 2019, 2020, 2021, 2022),\n  Geary_C_Stat = c(global_c_test_2017_statistics, global_c_test_2018_statistics, \n                   global_c_test_2019_statistics, global_c_test_2020_statistics, \n                   global_c_test_2021_statistics, global_c_test_2022_statistics),\n  Geary_C_p_value = c(global_c_test_2017_p_value, global_c_test_2018_p_value, \n                      global_c_test_2019_p_value, global_c_test_2020_p_value, \n                      global_c_test_2021_p_value, global_c_test_2022_p_value)\n)\n\n\n\n\n\n\n\nNotes\n\n\n\nMoran’s I (2017 - 2022) 2017: Moran’s I = 0.0821, p-value = 0.0577 2018: Moran’s I = 0.0952, p-value = 0.0423 2019: Moran’s I = 0.1410, p-value = 0.0149 2020: Moran’s I = 0.0875, p-value = 0.0835 2021: Moran’s I = 0.2013, p-value = 0.0024 2022: Moran’s I = 0.2133, p-value = 0.0015\nGeary’s C (2017 - 2022) 2017: Geary’s C = 1.0258, p-value = 0.5714 2018: Geary’s C = 1.0037, p-value = 0.5106 2019: Geary’s C = 0.9167, p-value = 0.2260 2020: Geary’s C = 0.9528, p-value = 0.3234 2021: Geary’s C = 0.8489, p-value = 0.0433 2022: Geary’s C = 0.8377, p-value = 0.0292\n\n\n\n# Plot Moran's I Statistic over the years\nggplot(moran_i_results, aes(x = Year, y = Moran_I_Stat)) +\n  geom_line() + \n  geom_point() +\n  labs(title = \"Moran's I Statistic Trend (2017-2022)\", \n       x = \"Year\", \n       y = \"Moran's I Statistic\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Plot p-values over the years\nggplot(moran_i_results, aes(x = Year, y = Moran_I_p_value)) +\n  geom_line() + \n  geom_point() +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +  # Significance threshold\n  labs(title = \"Moran's I Test p-values (2017-2022)\", \n       x = \"Year\", \n       y = \"p-value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nMoran’s I (2017 - 2022)\n2017: Moran’s I = 0.0821, p-value = 0.0577\n2018: Moran’s I = 0.0952, p-value = 0.0423\n2019: Moran’s I = 0.1410, p-value = 0.0149\n2020: Moran’s I = 0.0875, p-value = 0.0835\n2021: Moran’s I = 0.2013, p-value = 0.0024\n2022: Moran’s I = 0.2133, p-value = 0.0015\nKey Insights:\n\n2017–2019: There is a gradual increase in spatial autocorrelation, with clustering becoming statistically significant by 2018 and peaking in 2019.\n2020: A slight drop in Moran’s I indicates weaker spatial clustering, and the p-value suggests the autocorrelation is no longer significant. This could indicate that drug-related cases became more dispersed or random in 2020.\n2021–2022: A sharp rise in Moran’s I shows that spatial clustering of drug-related cases became very strong in these years, and it is statistically significant with p-values well below 0.05. Drug-related cases are now highly concentrated in certain areas.\n\n\n\n\n# Plot Geary C Statistic over the years\nggplot(geary_c_results, aes(x = Year, y = Geary_C_Stat)) +\n  geom_line() + \n  geom_point() +\n  labs(title = \"Geary C Statistic Trend (2017-2022)\", \n       x = \"Year\", \n       y = \"Geary C Statistic\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n# Plot p-values over the years\nggplot(geary_c_results, aes(x = Year, y = Geary_C_p_value)) +\n  geom_line() + \n  geom_point() +\n  geom_hline(yintercept = 0.05, linetype = \"dashed\", color = \"red\") +  # Mark significance threshold\n  labs(title = \"Geary C Test p-values (2017-2022)\", \n       x = \"Year\", \n       y = \"p-value\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReflection\n\n\n\nGeary’s C (2017 - 2022)\n2017: Geary’s C = 1.0258, p-value = 0.5714\n2018: Geary’s C = 1.0037, p-value = 0.5106\n2019: Geary’s C = 0.9167, p-value = 0.2260\n2020: Geary’s C = 0.9528, p-value = 0.3234\n2021: Geary’s C = 0.8489, p-value = 0.0433\n2022: Geary’s C = 0.8377, p-value = 0.0292\nKey Insights:\n\n2017–2018: Geary’s C values are very close to 1, indicating no significant spatial autocorrelation, meaning the distribution of drug-related cases was largely random.\n2019: The Geary’s C statistic starts to dip below 1, indicating emerging spatial autocorrelation, though it is not yet statistically significant.\n2020: Geary’s C rises slightly, indicating a slight weakening of spatial autocorrelation, but the cases are still mostly random with no significant clustering.\n2021–2022: A marked decrease in Geary’s C below 1, coupled with p-values dropping below 0.05, suggests significant clustering of similar values. This means that in the last two years, drug-related cases are no longer random and are now highly clustered.\n\n\n\n\n\n2.6.6 Conclusion\nFrom 2017 to 2022, both Moran’s I and Geary’s C statistics reveal an evolving spatial structure of drug-related cases. While earlier years exhibit weaker or random spatial patterns, by 2021 and 2022, significant clustering emerged, indicating an increase in spatial autocorrelation. This shift reflects that drug-related incidents are becoming more concentrated in specific areas, which could suggest targeted intervention zones for policy and law enforcement."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#local-measures-of-spatial-autocorrelation",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#local-measures-of-spatial-autocorrelation",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.7 Local Measures of Spatial Autocorrelation",
    "text": "2.7 Local Measures of Spatial Autocorrelation\nBuilding on the insights gained from global measures, local spatial autocorrelation focuses on identifying specific regions within the broader area that deviate from global trends. Techniques like Local Moran’s I allow for the detection of localized clusters and outliers, revealing spatial heterogeneity that might be masked by global statistics. This localized approach is crucial for pinpointing areas of high significance, enabling targeted interventions and more refined spatial decision-making.\n\n2.7.1 Local Moran’s I\nFor each year from 2017 to 2022, Local Moran’s I is calculated for each province in Thailand. This involves assessing the spatial autocorrelation of drug use cases, and for each year, a statistical test is performed with 99 simulations to generate a p-value for significance testing. Provinces with a p-value below 0.05 are considered statistically significant, and the resulting spatial autocorrelation patterns are visualized. The results for each year are presented using maps showing both Local Moran’s I values and their corresponding p-values, followed by a final map that highlights only statistically significant clusters (p &lt; 0.05). This iterative approach for multiple years enables the detection of persistent clusters of drug use cases across time, helping to identify long-term trends and regional patterns.\n\nYear 2017Year 2018Year 2019Year 2020Year 2021Year 2022\n\n\n\nset.seed(4242)\nlisa_2017 &lt;- wm_q_2017 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2017\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n       ii        eii var_ii    z_ii          p_ii p_ii_sim p_folded_sim skewness\n    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;         &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.556 -0.726     3.18    0.0955 0.924             0.84         0.42     1.15\n 2  0.335  0.00121   0.110   1.01   0.314             0.06         0.03    -2.24\n 3 -0.652  0.0429    0.0203 -4.87   0.00000109        0.04         0.02    -2.46\n 4 -0.492 -0.0000714 0.0516 -2.17   0.0303            0.12         0.06    -2.22\n 5  0.171  0.00626   0.0340  0.892  0.372             0.3          0.15    -1.52\n 6  0.122 -0.00370   0.0132  1.09   0.276             0.06         0.03    -2.73\n 7 -0.929  0.00822   0.0243 -6.00   0.00000000192     0.02         0.01    -3.07\n 8  0.142 -0.00256   0.0784  0.516  0.606             0.58         0.29    -1.47\n 9  0.329  0.00292   0.0827  1.13   0.256             0.04         0.02    -1.99\n10  0.264  0.0694    0.0565  0.818  0.413             0.42         0.21    -2.03\n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2017_sig &lt;- lisa_2017  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2017)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2017_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4242)\nlisa_2018 &lt;- wm_q_2018 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2018\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n         ii       eii    var_ii   z_ii       p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.192   -0.708    3.37       0.490    6.24e-1     0.62         0.31     1.16\n 2  0.358    0.00374  0.130      0.984    3.25e-1     0.16         0.08    -1.86\n 3 -0.188    0.0101   0.00188   -4.57     4.85e-6     0.04         0.02    -2.20\n 4 -0.0355   0.000684 0.000313  -2.04     4.11e-2     0.14         0.07    -2.21\n 5  0.0580   0.00852  0.0157     0.395    6.93e-1     0.84         0.42    -1.30\n 6  0.00332 -0.000511 0.0000984  0.387    6.99e-1     0.76         0.38    -2.42\n 7  1.74    -0.00597  0.122      5.00     5.82e-7     0.04         0.02     2.73\n 8 -0.0724  -0.0104   0.0568    -0.260    7.95e-1     0.64         0.32    -1.59\n 9  0.280    0.0107   0.0816     0.943    3.46e-1     0.22         0.11    -1.72\n10  0.178    0.0436   0.0545     0.573    5.66e-1     0.66         0.33    -1.63\n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2018_sig &lt;- lisa_2018  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2018)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2018_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4242)\nlisa_2019 &lt;- wm_q_2019 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2019\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n          ii       eii    var_ii    z_ii     p_ii p_ii_sim p_folded_sim skewness\n       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.341    -0.478    3.34       0.448  0.654        0.6          0.3     1.09 \n 2  0.306    -0.000190 0.0941     0.997  0.319        0.18         0.09   -1.30 \n 3 -0.371     0.0183   0.0126    -3.47   0.000528     0.06         0.03   -1.64 \n 4  0.216    -0.0101   0.0188     1.65   0.0991       0.18         0.09    1.64 \n 5 -0.0149   -0.00255  0.000641  -0.488  0.625        0.76         0.38    0.733\n 6 -0.000229 -0.000528 0.0000344  0.0510 0.959        0.9          0.45   -1.78 \n 7  2.73      0.00364  0.517      3.79   0.000154     0.04         0.02    1.67 \n 8 -0.270    -0.0190   0.0714    -0.938  0.348        0.3          0.15   -1.21 \n 9  0.318     0.0122   0.0941     0.998  0.318        0.2          0.1    -1.15 \n10  0.166     0.0420   0.107      0.379  0.704        0.94         0.47   -1.13 \n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2019_sig &lt;- lisa_2019  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2019)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2019_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4242)\nlisa_2020 &lt;- wm_q_2020 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2020\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n        ii       eii   var_ii    z_ii  p_ii p_ii_sim p_folded_sim skewness\n     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.0216 -0.0130   0.0485   -0.0392 0.969     0.82         0.41   -0.977\n 2 -0.0896 -0.0233   0.0160   -0.524  0.600     0.76         0.38    0.955\n 3 -0.0366 -0.000725 0.00435  -0.543  0.587     0.84         0.42    0.587\n 4  0.0565 -0.0138   0.0512    0.310  0.756     0.9          0.45   -0.699\n 5  0.0349 -0.0253   0.0500    0.269  0.788     0.92         0.46   -0.821\n 6  0.0160  0.000767 0.000482  0.692  0.489     0.6          0.3    -0.828\n 7 -0.121   0.0814   0.240    -0.413  0.680     0.54         0.27   -1.55 \n 8  0.0184 -0.000515 0.00185   0.441  0.659     0.86         0.43   -1.19 \n 9  1.52    0.0979   1.16      1.32   0.188     0.26         0.13    1.48 \n10  0.325  -0.106    1.30      0.377  0.706     0.62         0.31    0.841\n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2020_sig &lt;- lisa_2020  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2020)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2020_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nset.seed(4242)\nlisa_2021 &lt;- wm_q_2021 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2021\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n        ii      eii  var_ii   z_ii   p_ii p_ii_sim p_folded_sim skewness\n     &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1  0.792   0.0225  0.159    1.93  0.0535     0.02         0.01   -0.447\n 2  0.0221 -0.00327 0.00190  0.581 0.561      0.6          0.3     0.601\n 3 -0.150   0.0186  0.0389  -0.858 0.391      0.38         0.19   -0.813\n 4  0.294   0.0143  0.0412   1.38  0.169      0.06         0.03   -0.960\n 5  0.118   0.0250  0.0245   0.594 0.553      0.6          0.3    -0.651\n 6 -0.321  -0.0164  0.0243  -1.96  0.0501     0.14         0.07   -0.681\n 7  0.0681 -0.0366  0.131    0.289 0.773      0.82         0.41   -0.675\n 8  0.718   0.0329  0.191    1.57  0.117      0.06         0.03   -0.554\n 9  0.635  -0.0222  0.276    1.25  0.211      0.18         0.09   -0.582\n10 -0.125  -0.00554 0.0230  -0.790 0.429      0.36         0.18   -0.886\n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2021_sig &lt;- lisa_2021  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2021)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2021_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\nlisa_2022 &lt;- wm_q_2022 %&gt;% \n  mutate(local_moran = local_moran(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_moran)\nlisa_2022\n\nSimple feature collection with 77 features and 21 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 97.34336 ymin: 5.613038 xmax: 105.637 ymax: 20.46507\nGeodetic CRS:  WGS 84\n# A tibble: 77 × 22\n         ii      eii  var_ii    z_ii    p_ii p_ii_sim p_folded_sim skewness\n      &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;        &lt;dbl&gt;    &lt;dbl&gt;\n 1 -0.495    0.0371  0.364   -0.882  0.378       0.36         0.18   -0.139\n 2 -0.285    0.0270  0.169   -0.758  0.449       0.46         0.23    0.419\n 3  0.0512   0.00125 0.00556  0.670  0.503       0.56         0.28   -0.435\n 4  2.11    -0.00674 0.596    2.75   0.00605     0.02         0.01    0.336\n 5  0.860    0.0412  0.142    2.17   0.0300      0.02         0.01   -0.661\n 6  1.43    -0.0541  0.462    2.18   0.0293      0.04         0.02    0.222\n 7 -0.00992 -0.0333  0.0286   0.138  0.890       0.88         0.44   -0.144\n 8 -0.00621 -0.00279 0.00210 -0.0747 0.940       0.96         0.48   -0.367\n 9  0.0762   0.0177  0.402    0.0922 0.927       0.98         0.49    0.327\n10  0.672    0.0326  0.207    1.41   0.159       0.16         0.08   -0.388\n# ℹ 67 more rows\n# ℹ 14 more variables: kurtosis &lt;dbl&gt;, mean &lt;fct&gt;, median &lt;fct&gt;, pysal &lt;fct&gt;,\n#   nb &lt;nb&gt;, wt &lt;list&gt;, fiscal_year &lt;int&gt;, types_of_drug_offenses &lt;chr&gt;,\n#   no_cases &lt;int&gt;, province_en &lt;chr&gt;, Shape_Leng &lt;dbl&gt;, Shape_Area &lt;dbl&gt;,\n#   date &lt;date&gt;, geometry &lt;MULTIPOLYGON [°]&gt;\n\n\n\nVisualising Local Moran’s I_i\n\n\nShow the code\ntm_shape(lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Province-level Spatial Autocorrelation \\n of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Local Moran’s I_i p-value\n\n\nShow the code\ntm_shape(lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#b7dce9\",\"#c9e3d2\",\"#f5f3a6\",\"#ec9a64\",\"#d21b1c\"),\n          title = \"p-value\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial \\n Autocorrelation of drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\nVisualising Statistically Significant Local Spatial Autocorrelation Map\n\n\nShow the code\nlisa_2022_sig &lt;- lisa_2022  %&gt;%\n  filter(p_ii_sim &lt; 0.05) %&gt;% mutate(label = province_en)\n\ntm_shape(lisa_2022)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2022_sig)+\n  tm_fill(\"ii\", \n          palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                      \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n          title = \"Local Moran's I (p &lt; 0.05)\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Village-Level Spatial \\n Autocorrelation Map of drug use cases \\n in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.7.2 Statistically Significant Local Spatial Autocorrelation Map (2017 - 2022)\nWe now try to get a detailed view of spatial clusters and outliers in drug use cases across Thailand over a six-year period (2017 - 2022). These maps use Local Moran’s I to detect localized spatial patterns of drug use incidents, identifying regions where there is a statistically significant concentration of high or low case counts compared to neighboring provinces. Each year, the statistically significant clusters (p &lt; 0.05) are highlighted using a color-coded palette that distinguishes between hotspots (areas with high case counts surrounded by similarly high values) and cold spots (areas with low case counts surrounded by low values). By focusing on these spatial patterns, the maps help to uncover specific provinces that either contribute to or deviate from the broader regional trends.\nUltimately, this yearly comparisons aims to allow researchers and policymakers to observe how the spatial distribution of drug-related incidents changes over time. The maps serve as a critical tool for identifying regions where drug use clusters persist or evolve, offering insights into areas that may require targeted interventions. By visualizing the significant local spatial autocorrelation for each year, these maps reveal temporal dynamics, enabling a deeper understanding of the spatial heterogeneity in drug use cases across Thailand.\n\n# List of data for each year\nlisa_data &lt;- list(\n  \"2017\" = list(lisa = lisa_2017, sig = lisa_2017_sig),\n  \"2018\" = list(lisa = lisa_2018, sig = lisa_2018_sig),\n  \"2019\" = list(lisa = lisa_2019, sig = lisa_2019_sig),\n  \"2020\" = list(lisa = lisa_2020, sig = lisa_2020_sig),\n  \"2021\" = list(lisa = lisa_2021, sig = lisa_2021_sig),\n  \"2022\" = list(lisa = lisa_2022, sig = lisa_2022_sig)\n)\n\n# Initialize an empty list to store tmap objects\nmaps &lt;- list()\n\n# Loop through each year's data and create a map\nfor (year in names(lisa_data)) {\n  map &lt;- tm_shape(lisa_data[[year]]$lisa) +\n    tm_polygons(id = \"label\") +\n    tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(lisa_data[[year]]$sig) +\n    tm_fill(\"ii\", \n            palette = c(\"#b7dce9\",\"#e1ecbb\",\"#f5f3a6\",\n                        \"#f8d887\",\"#ec9a64\",\"#d21b1c\"),\n            breaks = c(0, 0.001, 0.01, 0.05, 1),\n            labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"),\n            title = paste(\"Local Moran's I\", year, \"(p &lt; 0.05)\"),\n            midpoint = NA,\n            id = \"label\") +\n    tm_borders(col = \"black\", alpha = 0.6) +\n    # Add title to individual plot\n    tm_layout(title = paste(\"Year\", year), title.position = c(\"center\", \"top\"))\n  \n  # Store the map in the list\n  maps[[year]] &lt;- map\n}\n\n# Arrange the maps side by side\ntmap_arrange(\n  maps$`2017`, maps$`2018`, maps$`2019`,\n  maps$`2020`, maps$`2021`, maps$`2022`,\n  ncol = 3\n)\n\n\n\n\n\n\n\n\n\n\n2.7.3 Visualising Statistically Significant Local Spatial Autocorrelation Map\nThe Local Indicator of Spatial Association (LISA) can provide insights into spatial clustering and outliers of drug-related incidents. Specifically, LISA identifies areas with significant spatial patterns, where the clustering of similar values occurs or where outliers stand out. This can help detect areas with unusually high or low concentrations of drug offenses.\nHere’s how we can interpret the LISA classifications for drug use cases:\n\nHigh-Low Outliers: Provinces with a high number of drug use cases surrounded by provinces with lower numbers. These could be hotspots of drug activity that differ significantly from their neighbors.\nLow-High Outliers: Provinces with a low number of drug use cases, but surrounded by provinces with higher levels of drug offenses. This could indicate areas with protective factors or lower vulnerability, even though they are located near hotspots.\nHigh-High Clusters: Provinces with a high concentration of drug use cases, surrounded by provinces that also have high numbers of offenses. This indicates regional hotspots of drug activity where intervention may be needed.\nLow-Low Clusters: Provinces with a low number of drug use cases, surrounded by provinces with similarly low levels. These regions could represent areas with effective prevention measures or lower exposure to drug-related issues.\n\nIn each year’s lisa sf data.frame that we created when calculating local Moran’s I, we can find three fields contain the LISA categories. They are mean, median and pysal. We will use mean column to visualise LISA classification maps with relevant tmap functions.\n\n2.7.3.1 Country-wide view\n\n\nShow the code\ntmap_mode(\"plot\")\nstudy_area_lisa_2017 &lt;- tm_shape(lisa_2017)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2017_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2017 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nstudy_area_lisa_2018 &lt;- tm_shape(lisa_2018)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2018_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2018 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nstudy_area_lisa_2019 &lt;- tm_shape(lisa_2019)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2019_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2019 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nstudy_area_lisa_2020 &lt;- tm_shape(lisa_2020)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2020_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2020 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nstudy_area_lisa_2021 &lt;- tm_shape(lisa_2021)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2021_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2021 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nstudy_area_lisa_2022 &lt;- tm_shape(lisa_2022)+\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6)+\ntm_shape(lisa_2022_sig)+\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2022 Thai LISA map\",\n            main.title.size = 1,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\",\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\nYear 2017Year 2018Year 2019Year 2020Year 2021Year 2022\n\n\n\nstudy_area_lisa_2017\n\n\n\n\n\n\n\n\n\n\n\nstudy_area_lisa_2018\n\n\n\n\n\n\n\n\n\n\n\nstudy_area_lisa_2019\n\n\n\n\n\n\n\n\n\n\n\nstudy_area_lisa_2020\n\n\n\n\n\n\n\n\n\n\n\nstudy_area_lisa_2021\n\n\n\n\n\n\n\n\n\n\n\nstudy_area_lisa_2022\n\n\n\n\n\n\n\n\n\n\n\nOn a national scale, provinces, especially smaller ones, may appear too small to analyze effectively, making it difficult to clearly see the distribution of the LISA classifications. A regional view, with better zoom and focus, can improve the clarity of visualization. It becomes easier to distinguish between clusters and outliers, especially in densely populated or small-area provinces.\n\n\n2.7.3.2 Regional view\nThailand is variably divided into different sets of regions, the most notable of which are the six-region grouping used in geographic studies, and the four-region grouping consistent with the Monthon administrative regional grouping system formerly used by the Ministry of Interior. These regions are the largest subdivisions of the country.\nIn contrast to the administrative divisions of the provinces of Thailand, the regions no longer have an administrative character, but are used for statistical or academic purposes.\nA six-region system is commonly used for geographical and scientific purposes. This system dates to 1935. It was formalised in 1977 by the National Geographical Committee, which was appointed by the National Research Council. It divides the country into the following regions:\n\nNorthern Thailand\nNortheastern Thailand\nWestern Thailand\nCentral Thailand\nEastern Thailand\nSouthern Thailand\n\nThe four-region system, used in some administrative and statistical contexts, and also as a loose cultural grouping, includes the western and eastern regions within the central region, while grouping the provinces of Sukhothai, Phitsanulok, Phichit, Kamphaeng Phet, Phetchabun, Nakhon Sawan, and Uthai Thani in the northern region. This is also the regional system most commonly used on national television, when discussing regional events. It divides the country into the following regions:\n\nNorthern Thailand\nNortheastern Thailand (Isan)\nCentral Thailand\nSouthern Thailand\n\nThe Thai Meteorological Department divides the country into six regions for meteorological purposes. It differs from the four-region system in that the east is regarded as a separate region, the south is divided into east and west coasts, and Nakhon Sawan and Uthai Thani are grouped in the central region.\n\n\n\n\n\n\n\nNotes\n\n\n\nLISA relies on the spatial relationships between neighboring areas. If you remove certain provinces from the analysis when zooming into a region, the LISA statistics could change due to the loss of spatial context. To maintain the integrity of LISA classifications in a regional view, we will ensure that the entire neighborhood structure is still considered. Even though you may only visualize a specific region, the calculations should still include all neighboring provinces, not just those within the selected region.\nIt is important to keep the spatial dependencies intact by including all neighboring provinces in the LISA calculations. This ensures that the regional LISA classifications remain consistent with the national analysis, and the spatial clustering or outlier detection is not compromised due to changes in the geographical scope. The regional view should be treated as a zoomed-in perspective of the national LISA results, without altering the underlying spatial relationships.\n\n\nGiven the geographical scope of the study, we will adopt a six-region geographical distribution, focusing on the provincial level. This approach not only allows for a regionally nuanced analysis but also reduces the computational load within the R environment, making the analysis more efficient.\n\n# Define provinces for each region\nnortheastern &lt;- c(\"Amnat Charoen\", \"Bueng Kan\", \"Buri Ram\", \"Chaiyaphum\", \"Kalasin\", \n                  \"Khon Kaen\", \"Loei\", \"Maha Sarakham\", \"Mukdahan\", \"Nakhon Phanom\", \n                  \"Nakhon Ratchasima\", \"Nong Bua Lam Phu\", \"Nong Khai\", \"Roi Et\", \n                  \"Sakon Nakhon\", \"Si Sa Ket\", \"Surin\", \"Ubon Ratchathani\", \"Udon Thani\", \n                  \"Yasothon\")\n\nnorthern &lt;- c(\"Chiang Mai\", \"Chiang Rai\", \"Lampang\", \"Lamphun\", \"Mae Hong Son\", \n              \"Nan\", \"Phayao\", \"Phrae\", \"Uttaradit\")\n\nwestern &lt;- c(\"Tak\", \"Kanchanaburi\", \"Ratchaburi\", \"Phetchaburi\", \"Prachuap Khiri Khan\")\n\ncentral &lt;- c(\"Kamphaeng Phet\", \"Phetchabun\", \"Phichit\", \"Phitsanulok\", \"Sukhothai\", \n             \"Nakhon Sawan\", \"Uthai Thani\", \"Ang Thong\", \"Bangkok\", \"Chai Nat\", \n             \"Lop Buri\", \"Nakhon Pathom\", \"Nonthaburi\", \"Pathum Thani\", \n             \"Phra Nakhon Si Ayutthaya\", \"Samut Prakan\", \"Samut Sakhon\", \n             \"Samut Songkhram\", \"Saraburi\", \"Sing Buri\", \"Suphan Buri\", \"Nakhon Nayok\")\n\neastern &lt;- c(\"Chachoengsao\", \"Chanthaburi\", \"Chon Buri\", \"Prachin Buri\", \"Rayong\", \n             \"Sa Kaeo\", \"Trat\")\n\nsouthern &lt;- c(\"Chumphon\", \"Nakhon Si Thammarat\", \"Narathiwat\", \"Pattani\", \n              \"Phatthalung\", \"Songkhla\", \"Surat Thani\", \"Yala\", \"Krabi\", \n              \"Phangnga\", \"Phuket\", \"Ranong\", \"Satun\", \"Trang\")\n\nUsing a combination of the Local Moran’s I plot, which visualizes the degree of spatial autocorrelation, and the p-value plot, which highlights statistically significant areas, we can gain deeper insights into the spatial dynamics of drug use incidents within the region. This dual visualization approach ensures that identified patterns are both meaningful and reliable, allowing for more informed decision-making in policy development and resource allocation to tackle drug-related issues in specific regions.\n\n\n\n\n\n\nNotes\n\n\n\nThe Local Moran’s I plot and the p-value of Local Moran’s I plot work together to help identify significant spatial patterns in the distribution of drug use cases across regions. The Local Moran’s I plot shows the degree of spatial autocorrelation, indicating where clusters of similar values (either high or low) occur. This plot helps highlight potential hotspots (high values surrounded by high values) or cold spots (low values surrounded by low values), as well as potential outliers (where high values are surrounded by low values or vice versa).\nHowever, the Local Moran’s I values alone do not indicate whether these patterns are statistically significant. This is where the p-value of Local Moran’s I plot comes into play. It shows the significance levels of the spatial patterns, with red areas indicating highly significant clusters and blue/green areas representing non-significant patterns. This plot helps validate whether the clusters or outliers seen in the Local Moran’s I plot are meaningful or if they occurred randomly.\nBy using both plots together, we can accurately classify regions into LISA categories such as High-High clusters (significant hotspots of high drug use cases), Low-Low clusters (regions of low drug use cases surrounded by similar values), and outliers (provinces where values deviate significantly from their neighbors). The combination of these plots ensures that we can distinguish between true spatial patterns and random variation, leading to more reliable insights into the distribution of drug-related incidents.\n\n\n\nYear 2017Year 2018Year 2019Year 2020Year 2021Year 2022\n\n\n\n\nShow the code\nnortheastern_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% western)\ncentral_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% central)\neastern_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2017 &lt;- lisa_2017 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2017_sig &lt;- lisa_2017_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Central Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Central Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2017)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2017)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the second map for northeastern_lisa_2017\nnortheastern_map &lt;- tm_shape(northeastern_lisa_2017) +\n  tm_polygons(id=\"label\") +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(northeastern_lisa_2017_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2017 LISA plot of northeastern region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the first map for central_lisa_2017\ncentral_map &lt;- tm_shape(central_lisa_2017) +\n  tm_polygons(id=\"label\") +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2017_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2017 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(northeastern_map, central_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nWithin the year 2017, the northeastern and central regions of Thailand present an intriguing spatial autocorrelation pattern characterized by the co-existence of Low-Low and Low-High clusters in the central region, and High-High clusters in the northeastern region.\nIn contrast, the Northeastern region (left plot) shows a pronounced High-High cluster in the eastern border provinces, where both the province and its neighbors experience high rates of drug use. This significant clustering highlights a potential hotspot in the northeastern part of Thailand, indicating areas that may require targeted interventions for drug-related issues.\nIn the Central region (right plot), we observe a combination of Low-Low clusters in the province of Singburi, where areas with low drug use rates are surrounded by similarly low-use neighbors, and Low-High clusters in the south, where provinces with higher drug use rates are adjacent to those with lower rates. This pattern suggests a transitional area where drug use may be increasing, potentially influenced by neighboring provinces that are experiencing higher levels of drug-related incidents. The close proximity could indicate a spillover effect, notably into the provinces of Nonthaburi and Samut Prakan, highlighting the importance of monitoring and addressing drug use in these interconnected areas to prevent further escalation. Overall, the central region’s mixed clustering patterns reveal a complex landscape of drug use, necessitating tailored strategies for intervention and prevention.\n\n\n\n\n\nShow the code\nnortheastern_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% western)\ncentral_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% central)\neastern_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2018 &lt;- lisa_2018 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2018_sig &lt;- lisa_2018_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Central Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Central Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2018)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2018)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), ,\n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the second map for northeastern_lisa_2018\nnortheastern_map &lt;- tm_shape(northeastern_lisa_2018) +\n  tm_polygons(id=\"label\") +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(northeastern_lisa_2018_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2018 LISA plot of northeastern region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the first map for central_lisa_2018\ncentral_map &lt;- tm_shape(central_lisa_2018) +\n  tm_polygons(id=\"label\") +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2018_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2018 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(northeastern_map, central_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nIn 2018, the spatial autocorrelation patterns in the northeastern and central regions of Thailand reveal notable shifts in the classification of drug use incidents compared to the previous year.\nIn the Northeastern region (left plot), we observe a significant presence of High-Low clusters, particularly in the northern provinces. This indicates that areas with high drug use rates are bordered by regions with lower rates, suggesting a potential influence or spillover effect where increased drug activity in some areas may affect their neighbors. The rest of the region largely remains unclassified, highlighting a shift in the drug use dynamics in this area.\nConversely, in the Central region (right plot), there is a noticeable increase in High-High clusters, especially in the southern provinces, where areas with high drug use rates are surrounded by similarly high-use neighbors. This indicates that drug-related issues may be more concentrated in these provinces, necessitating targeted interventions to address the growing problem. Additionally, Low-Low clusters can be seen in some provinces, where low drug use rates are observed alongside similarly low-use areas, signifying pockets of stability amidst rising drug use in surrounding regions.\nOverall, both regions illustrate the evolving landscape of drug use in Thailand in 2018, emphasizing the importance of spatial analysis in understanding and responding to changing patterns in drug-related incidents. The identification of clusters can inform policy decisions and resource allocation for effective intervention strategies.\n\n\n\n\n\nShow the code\nnortheastern_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% western)\ncentral_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% central)\neastern_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2019 &lt;- lisa_2019 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2019_sig &lt;- lisa_2019_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Western Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Eastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2019)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2019)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Southern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the second map for northeastern_lisa_2019\nnortheastern_map &lt;- tm_shape(northeastern_lisa_2019) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(northeastern_lisa_2019_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2019 LISA plot of northeastern region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the first map for central_lisa_2019\ncentral_map &lt;- tm_shape(central_lisa_2019) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2019_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2019 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(northeastern_map, central_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nIn 2019, the spatial autocorrelation patterns in the northeastern and central regions of Thailand present distinct shifts in drug use classifications compared to previous years.\nIn the Northeastern region (left plot), there is a notable concentration of High-High clusters in the southern part, indicating that provinces with high drug use rates are situated near other high-use provinces. Combined with the data from previous years, this suggests a persistence of drug-related issues in this area, requiring ongoing attention from policymakers and law enforcement. Additionally, some border provinces in the northern part of the region are classified as Low-Low, showing that these areas are characterized by low drug use rates surrounded by similarly low-use neighbors. This combination of clustering patterns highlights the complex landscape of drug use in the northeastern region, where areas of high intensity coexist with regions exhibiting stability in low usage.\nIn the Central region (right plot), we observe a significant presence of High-High clusters concentrated in the southern provinces, particularly in the province of Samut Prakan. This reinforces the trend of increased drug-related activities in this part of the region compared to the rest of the region as seen from the past 2 years.\nOverall, both regions reveal a continued need for targeted interventions and policy adaptations to address the shifting patterns of drug use across Thailand’s northeastern and central regions. The persistence of high-use clusters in specific areas highlights the importance of focused resource allocation and strategic planning to combat drug-related challenges effectively.\n\n\n\n\n\nShow the code\nnortheastern_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% western)\ncentral_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% central)\neastern_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2020 &lt;- lisa_2020 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2020_sig &lt;- lisa_2020_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in Northeastern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in Northern Region\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2020)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2020)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the first map for central_lisa_2020\ncentral_map &lt;- tm_shape(central_lisa_2020) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2020_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2020 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the second map for eastern_lisa_2020\neastern_map &lt;- tm_shape(eastern_lisa_2020) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(eastern_lisa_2020_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2020 LISA plot of eastern region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(central_map, eastern_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nIn 2020, the spatial autocorrelation patterns in the eastern and central regions of Thailand present distinct shifts in drug use classifications compared to previous years.\nIn the Central region (left plot), there is a notable concentration of Low-High clusters in the southern part, indicating that provinces with high drug use rates are situated near other high-use provinces. Combined with the data from previous years, this suggests a persistence of drug-related issues in this area, requiring ongoing attention from policymakers and law enforcement.\nIn the Eastern region (right plot), we observe some border provinces in the northern part of the region are classified as Low-High, showing that these areas are characterized by low drug use rates surrounded by high-use neighbors. It is noteworthy that the area is also at the eastern border, similar to those clusters in the previous years. Additionally, a significant presence of High-High clusters concentrated in the western provinces, particularly in the province of Chachoengsao. This cluster is neigbhouring the Low-High cluster of Central region, connecting the 2020 highlighted clusters together in both regions.\nOverall, both regions reveal a continued need for targeted interventions and policy adaptations to address the shifting patterns of drug use across Thailand’s regions. The persistence of high-use clusters in the eastern border provinces and central region specifically highlights the importance of focused resource allocation and strategic planning to combat drug-related challenges effectively.\n\n\n\n\n\nShow the code\nnortheastern_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% western)\ncentral_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% central)\neastern_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2021 &lt;- lisa_2021 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2021_sig &lt;- lisa_2021_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2021)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2021)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the second map for western_lisa_2021\nwestern_map &lt;- tm_shape(western_lisa_2021) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(western_lisa_2021_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2021 LISA plot of western region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the first map for central_lisa_2021\ncentral_map &lt;- tm_shape(central_lisa_2021) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2021_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2021 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(western_map, central_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nIn 2021, the spatial autocorrelation patterns in the western and central regions of Thailand present distinct shifts in drug use classifications compared to previous years.\nIn the Western region (left plot), there is a notable concentration of Low-Low clusters in the central part. These clusters indicate that these provinces and their neighbors experience consistently lower drug-related cases compared to the rest of the region.\nIn the Central region (right plot), we observe a significant presence of Low-Low clusters concentrated in the western and southern provinces. These cluster is neigbhouring the Low-Low cluster of Western region, connecting the 2021 highlighted clusters together in both regions. This shows that this areas are characterized by low drug use rates surrounded by low-use neighbors.\nOverall, the plots highlight a significant presence of Low-Low clusters in both the Western and Central regions, suggesting that several provinces in these areas have lower-than-average drug-related cases compared to their neighbors. The patterns are consistent across multiple neighbouring provinces, indicating potential coldspots that may benefit from maintaining existing preventative measures. Additionally, the absence of High-High clusters in all regions for 2021 implies that there were no significant hotspots for drug abuse activity, indicating either a reduction in drug-related cases or a more uniform distribution across these regions.\n\n\n\n\n\nShow the code\nnortheastern_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% northern)\nwestern_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% western)\ncentral_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% central)\neastern_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2022 &lt;- lisa_2022 %&gt;% filter(province_en %in% southern)\n\nnortheastern_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% northeastern)\nnorthern_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% northern)\nwestern_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% western)\ncentral_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% central)\neastern_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% eastern)\nsouthern_lisa_2022_sig &lt;- lisa_2022_sig %&gt;% filter(province_en %in% southern)\n\n\n\nNortheastern Region\n\n\nShow the code\nnortheastern_local &lt;- tm_shape(northeastern_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnortheastern_sig &lt;- tm_shape(northeastern_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northeastern_local,northeastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nNorthern Region\n\n\nShow the code\nnorthern_local &lt;- tm_shape(northern_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nnorthern_sig &lt;- tm_shape(northern_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(northern_local,northern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nWestern Region\n\n\nShow the code\nwestern_local &lt;- tm_shape(western_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nwestern_sig &lt;- tm_shape(western_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(western_local,western_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nCentral Region\n\n\nShow the code\ncentral_local &lt;- tm_shape(central_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ncentral_sig &lt;- tm_shape(central_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(central_local,central_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nEastern Region\n\n\nShow the code\neastern_local &lt;- tm_shape(eastern_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\neastern_sig &lt;- tm_shape(eastern_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(eastern_local,eastern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nSouthern Region\n\n\nShow the code\nsouthern_local &lt;- tm_shape(southern_lisa_2022)+\n  tm_fill(\"ii\", \n          palette = c(\"#e1ecbb\",\"#f5f3a6\", \"#ec9a64\",\"#de573e\",\"#d21b1c\"),\n          title = \"Local Moran's I\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Village-Level Spatial Autocorrelation \\nof drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\nsouthern_sig &lt;- tm_shape(southern_lisa_2022)+\n  tm_fill(\"p_ii_sim\", \n          palette = c(\"#d21b1c\",\"#ec9a64\",\"#f5f3a6\",\"#c9e3d2\",\"#b7dce9\"),\n          breaks = c(0, 0.001, 0.01, 0.05, 1),\n          labels = c(\"0.001\", \"0.01\", \"0.05\", \"Not sig\"), \n          title = \"p-value\",\n          midpoint = NA) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistical Significance of Spatial Autocorrelation\\n of drug use cases in North District\",\n            main.title.position = \"center\",\n            main.title.size = 1.3,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1,\n            legend.text.size = 0.8,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\ntmap_arrange(southern_local,southern_sig, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\n\n\nAnalysis & Discussion\n\n\nShow the code\n# Create the second map for northeastern_lisa_2022\nnortheastern_map &lt;- tm_shape(northeastern_lisa_2022) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(northeastern_lisa_2022_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2022 LISA plot of northeastern region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Create the first map for central_lisa_2022\ncentral_map &lt;- tm_shape(central_lisa_2022) +\n  tm_polygons() +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_shape(central_lisa_2022_sig) +\n  tm_fill(\"mean\", \n          palette = c(\"#b7dce9\",\"#ec9a64\",\"#e1ecbb\", \"#d21b1c\"),\n          title = \"LISA class\",\n          midpoint = NA,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.5) +\n  tm_borders(col = \"black\", alpha = 0.6) +\n  tm_layout(main.title = \"2022 LISA plot of central region\",\n            main.title.size = 0.8,\n            legend.outside = TRUE)\n\n# Arrange the two maps side by side\ntmap_arrange(northeastern_map, central_map, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nIn 2022, the spatial autocorrelation patterns in the northeastern and central regions of Thailand present distinct shifts in drug use classifications compared to previous years.\nIn the Northeastern region (left plot), there is a notable concentration of High-High clusters, covering a few central provinces. This indicates that these provinces and their neighboring areas have higher-than-average drug-related cases, creating a significant hotspot. There is also a Low-High cluster in one province to the west of the hotspot. This pattern suggests that the province itself has low drug-related cases, but it is surrounded by high-value neighbors.\nIn the Central region (right plot), we observe a significant presence of Low-Low clusters in a few western and central provinces. Referencing the cluster data of 2021, this coldspot have consistently shown lower drug-related cases compared to the rest of the region.\nOverall, the Northeastern region exhibits significant hotspots indicating provinces with elevated drug-related cases, which are surrounded by other high-case provinces. This is a marked contrast from the absence of such clusters in the Central region, which only shows Low-Low clusters representing coldspots.\nThe emergence of High-High clusters in the Northeastern region could point to new areas of concern that require targeted intervention strategies, while the presence of Low-Low clusters in the Central region suggests continued effectiveness in maintaining low levels of drug-related activities."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#hot-spot-and-cold-spot-area-analysis",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#hot-spot-and-cold-spot-area-analysis",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.8 Hot Spot and Cold Spot Area Analysis",
    "text": "2.8 Hot Spot and Cold Spot Area Analysis\nThe Local Getis-Ord Gi* statistic is a spatial analysis technique used to identify hotspots and coldspots within geographic data. It measures spatial clustering by determining whether features with high or low values are spatially clustered.\n\n2.8.1 Local Getis-Ord Gi for Hot Spot and Cold Spot Area Analysis\nIn the context of this analysis, Gi* helps identify areas with significantly high or low values of interest relative to their neighbors. A hotspot is an area where high values cluster, while a coldspot is where low values cluster.\nKey aspects of the Getis-Ord Gi* statistic include:\n\nZ-Scores and p-values: These indicate the statistical significance of the clustering. A high positive Gi* value with a low p-value suggests a hotspot, while a low negative Gi* value indicates a coldspot. Statistical significance is often represented using thresholds (e.g., p &lt; 0.05).\nSpatial Weighting: Gi* takes into account not just the value of the feature but also the values of neighboring features within a specified distance. The statistic compares the local mean to the global mean to assess whether clustering is due to chance or significant spatial patterns.\nApplication in Hotspot & Coldspot Analysis: In this analysis, the Gi* statistic is applied to geographical areas to identify statistically significant areas of unusually high or low values of the phenomenon under study, such as drug use cases. These areas can then be visualized using a color scale, helping researchers or decision-makers focus on regions that exhibit non-random spatial patterns.\n\nBy visualizing Gi* results on a map, we can better understand the spatial dynamics of an issue and prioritize interventions in areas of concern.\nWe start by calculating Inverse Distance Weighted (IDW) spatial weight matrices for the years 2017-2022 using contiguity-based neighborhoods. Each region is considered as its own neighbor (with include_self), and spatial weights are assigned based on the inverse distance between regions (st_inverse_distance), giving more weight to closer regions. This creates a foundation for spatial autocorrelation analysis by providing the necessary spatial relationships for each year.\n\nwm_idw_2017 &lt;- region_2017_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw_2018 &lt;- region_2018_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw_2019 &lt;- region_2019_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw_2020 &lt;- region_2020_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw_2021 &lt;- region_2021_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\nwm_idw_2022 &lt;- region_2022_sf %&gt;%\n  mutate(nb = include_self(st_contiguity(geometry)),\n         wt = st_inverse_distance(nb, geometry,\n                                   scale = 1,\n                                   alpha = 1),\n         .before = 1)\n\nWe store the yearly spatial weight matrices for ease of use\n\nwrite_rds(wm_idw_2017, \"data/rds/wm_idw_2017.rds\")\nwrite_rds(wm_idw_2018, \"data/rds/wm_idw_2018.rds\")\nwrite_rds(wm_idw_2019, \"data/rds/wm_idw_2019.rds\")\nwrite_rds(wm_idw_2020, \"data/rds/wm_idw_2020.rds\")\nwrite_rds(wm_idw_2021, \"data/rds/wm_idw_2021.rds\")\nwrite_rds(wm_idw_2022, \"data/rds/wm_idw_2022.rds\")\n\n\nwm_idw_2017 &lt;- read_rds(\"data/rds/wm_idw_2017.rds\")\nwm_idw_2018 &lt;- read_rds(\"data/rds/wm_idw_2018.rds\")\nwm_idw_2019 &lt;- read_rds(\"data/rds/wm_idw_2019.rds\")\nwm_idw_2020 &lt;- read_rds(\"data/rds/wm_idw_2020.rds\")\nwm_idw_2021 &lt;- read_rds(\"data/rds/wm_idw_2021.rds\")\nwm_idw_2022 &lt;- read_rds(\"data/rds/wm_idw_2022.rds\")\n\nWe apply the Local Getis-Ord Gi* statistic to identify spatial clusters (hotspots and coldspots) of cases for each year (2017-2022) onto the yearly spatial weight matrices. Using the local_gstar_perm() function, it calculates Gi values for each region, based on the case counts (no_cases), spatial neighbors (nb), and their corresponding weights (wt), with 99 Monte Carlo simulations (nsim = 99) for statistical significance. The results are then added back to the dataset for visualization and further analysis.\n\nset.seed(4242)\n\nHCSA_2017 &lt;- wm_idw_2017 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2018 &lt;- wm_idw_2018 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2018 &lt;- wm_idw_2018 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2019 &lt;- wm_idw_2019 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2020 &lt;- wm_idw_2020 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2021 &lt;- wm_idw_2021 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\nHCSA_2022 &lt;- wm_idw_2022 %&gt;% \n  mutate(local_Gi_star = local_gstar_perm(\n    no_cases, nb, wt, nsim = 99),\n         .before = 1) %&gt;%\n  unnest(local_Gi_star)\n\n\n201720182019202020212022\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2017)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2017 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2017_sig &lt;- HCSA_2017  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\ntm_shape(HCSA_2017_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\n\n# Get the top 3 hotspots (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2017_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n# Get the top 3 cold spots (lowest negative gi_star values)\ntop_coldspots &lt;- HCSA_2017_sig %&gt;%\n  filter(!(province_en %in% top_hotspots)) %&gt;%\n  arrange(gi_star) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2017_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2017_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_2017) +\n  tm_polygons() +\ntm_shape(HCSA_top_coldspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\", auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Coldspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2018)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2018 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2018_sig &lt;- HCSA_2018  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2018) +\n  tm_polygons() +\ntm_shape(HCSA_2018_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\nFrom the plot above, it, there is only 1 statistically significant hotspot during the year 2018. We will get the top hotspot based on gi_star value.\n\n# Get the top hotspot (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2018_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(1) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2018_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2018_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2018) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2019)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2019 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2019_sig &lt;- HCSA_2019  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2019) +\n  tm_polygons() +\ntm_shape(HCSA_2019_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\nFrom the plot above, it, there is only 1 statistically significant hotspot during the year 2018. We will get the top hotspot based on gi_star value.\n\n# Get the top hotspot (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2019_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(1) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2019_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2019_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2019) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2020)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2020 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2020_sig &lt;- HCSA_2020  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\ntm_shape(HCSA_2020_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\n\n# Get the top 3 hotspots (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2020_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n# Get the top 3 cold spots (lowest negative gi_star values)\ntop_coldspots &lt;- HCSA_2020_sig %&gt;%\n  filter(!(province_en %in% top_hotspots)) %&gt;%\n  arrange(gi_star) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2020_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2020_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_2020) +\n  tm_polygons() +\ntm_shape(HCSA_top_coldspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\", auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Coldspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2021)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2021 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2021_sig &lt;- HCSA_2021  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\ntm_shape(HCSA_2021_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\n\n# Get the top 3 hotspots (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2021_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n# Get the top 3 cold spots (lowest negative gi_star values)\ntop_coldspots &lt;- HCSA_2021_sig %&gt;%\n  filter(!(province_en %in% top_hotspots)) %&gt;%\n  arrange(gi_star) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2021_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2021_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_2021) +\n  tm_polygons() +\ntm_shape(HCSA_top_coldspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\", auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Coldspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\nMap of Hotspots & Coldspots of Drug Use Cases in Thailand\nFirst we generate a map of Thailand for the current year, showing the hotspots and coldspots of drug use cases using Gi statistics. The fill color is determined by the gi_star column using a specified color palette, with a midpoint of 0 to distinguish between hotspots (positive Gi) and coldspots (negative Gi). The map also includes borders, a title, a compass, a scale bar, and a grid.\n\ntm_shape(HCSA_2022)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          title = \"Gi*\",\n          midpoint = 0) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"2022 Hotspots & Coldspots of drug\\n use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nMap of Statistically Significant Hotspots & Coldspots of Drug Use Cases\nWe then create a map similar to the previous one but filters the data to only show provinces where the p_sim value is less than 0.05 (indicating statistically significant results). It visualizes the statistically significant hotspots and coldspots, with gi_star values categorized into specific intervals (breaks = c(-2, 0, 2, 4, 6, 8)), and includes a histogram in the legend for distribution reference.\n\nHCSA_2022_sig &lt;- HCSA_2022  %&gt;%\n  filter(p_sim &lt; 0.05)\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\ntm_shape(HCSA_2022_sig)+\n  tm_fill(\"gi_star\", \n          title = \"Gi*\",\n          palette = c(\"#57bfc0\", \"#7977f3\",\"#f8d673\",\"#f8b675\",\"#f67774\"),\n          breaks = c(-2, 0, 2, 4, 6, 8), \n          midpoint = 0,\n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_layout(main.title = \"Statistically Significant Hotspots & Coldspots \\nof Drug use cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.title.size = 1.8,\n            legend.text.size = 1.3,\n            legend.outside = TRUE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\nTop Hotspots and Coldspots Identification\nWe then identify the top hotspot provinces (with the highest positive gi_star values) and the top coldspot provinces (with the lowest negative gi_star values). It uses the filtered HCSA_&lt;current_year&gt;_sig dataset and arranges the values in descending and ascending order, respectively, to extract the top provinces.\n\n# Get the top 3 hotspots (highest positive gi_star values)\ntop_hotspots &lt;- HCSA_2022_sig %&gt;%\n  arrange(desc(gi_star)) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n# Get the top 3 cold spots (lowest negative gi_star values)\ntop_coldspots &lt;- HCSA_2022_sig %&gt;%\n  filter(!(province_en %in% top_hotspots)) %&gt;%\n  arrange(gi_star) %&gt;%\n  head(3) %&gt;%\n  pull(province_en)\n\n\nHCSA_top_hotspots &lt;- HCSA_2022_sig %&gt;% filter(province_en %in% top_hotspots)\nHCSA_top_coldspots &lt;- HCSA_2022_sig %&gt;% filter(province_en %in% top_coldspots)\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\ntm_shape(HCSA_top_hotspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#f67774\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\",auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Hotspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\ntm_shape(HCSA_2022) +\n  tm_polygons() +\ntm_shape(HCSA_top_coldspots)+\n  tm_fill(\"gi_star\", \n          palette = c(\"#57bfc0\")) +\n  tm_borders(col = \"black\", alpha = 0.6)+\n  tm_text(\"province_en\", auto.placement = T)+\n  tm_layout(main.title = \"Most Significant Coldspots of Drug use\\n cases in Thailand\",\n            main.title.position = \"center\",\n            main.title.size = 1.7,\n            main.title.fontface = \"bold\",\n            legend.show = FALSE,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", text.size = 1.5, size = 3, position=c(\"RIGHT\", \"TOP\")) +\n  tm_scale_bar(position=c(\"LEFT\", \"BOTTOM\"), text.size=1.2) +\n  tm_grid(labels.size = 1,alpha =0.2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.8.2 Discussion and Analysis\nThis spatial analysis enables better decision-making by highlighting areas that require focused attention. Identifying hotspots helps in targeting resources and interventions effectively, while coldspot areas provide insights into regions with fewer concerns. As demonstrated through the visualization, the Gi* analysis provides a clear and interpretable way to detect and map statistically significant clusters, facilitating data-driven policies and more informed public health strategies.\nIn general, the trend of drug use cases in Thailand from 2017 to 2022 generally aligns with the patterns revealed by the Local Indicator of Spatial Association (LISA) analysis. This suggests a consistent spatial clustering of drug-related incidents, where certain regions experience persistent high or low rates of drug use. The LISA analysis helps identify statistically significant hotspots and coldspots, reinforcing the spatial dependency observed in the distribution of these cases over the years."
  },
  {
    "objectID": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#conclusion-1",
    "href": "Take-home_ex/Take-home_ex02/Take-home_ex02.html#conclusion-1",
    "title": "Take-home Exercise 2: Application of Geospatial Analysis Methods to Discover Thailand Drug Abuse at the Province Level",
    "section": "2.9 Conclusion",
    "text": "2.9 Conclusion\nThe spatial analysis of drug-related cases in Thailand from 2017 to 2022, using Local Getis-Ord Gi and Local Indicator of Spatial Association (LISA), reveals distinct regional patterns that indicate both persistent hotspots and coldspots across different years. The northeastern region consistently exhibits High-High clusters, particularly in border provinces, suggesting an ongoing concentration of drug-related issues in those areas, highlighting them as persistent hotspots. These regions demand focused interventions to curb drug-related activities.\nConversely, the central and western regions show a contrasting trend with Low-Low clusters, signifying areas with stable, low drug-use rates, referred to as coldspots. The continued presence of these clusters across multiple years suggests the effectiveness of existing measures in maintaining lower levels of drug-related incidents in these regions. The spillover effects between neighboring regions, such as the emergence of Low-High and High-Low clusters, reflect transitional areas where drug-use trends might be shifting, requiring proactive monitoring and intervention strategies.\nOverall, the combination of High-High and Low-Low clusters over the years demonstrates the evolving drug-use landscape in Thailand, necessitating a tailored approach to addressing both the hotspots and coldspots identified by spatial autocorrelation techniques like LISA and Local Getis-Ord Gi.\n\n\n\n\n\n\nKey Recommendations\n\n\n\nTo effectively address the evolving landscape of drug use in Thailand, the authorities should adopt a data-driven, region-specific approach based on the spatial patterns observed in drug-related incidents from 2017 to 2022. Here are some key recommendations:\n\nFocus on Persistent Hotspots: The northeastern region, particularly along the border provinces, consistently shows High-High clusters, indicating areas with a high concentration of drug-related cases. Thai authorities should prioritize these areas by intensifying law enforcement efforts, increasing surveillance, and providing targeted interventions. Coordinated cross-border efforts with neighboring countries might also help reduce the flow of drugs in these regions.\nStrengthen Monitoring in Transitional Areas: The presence of High-Low and Low-High clusters in both the northeastern and central regions indicates areas where drug use trends may be shifting. Thai authorities should closely monitor these transitional areas to prevent the potential spillover of drug-related activities from high-incident to low-incident regions. Early intervention in these areas can help prevent further escalation of drug use.\nSustain Coldspots with Preventive Measures: In regions such as the central and western areas where Low-Low clusters are observed, authorities should continue supporting community-based preventive programs, education campaigns, and rehabilitation services. These measures have likely contributed to maintaining low levels of drug-related cases, and ensuring their sustainability will help preserve these coldspots."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex12.html",
    "href": "In-class_Ex/In-class_Ex12.html",
    "title": "In Class exercise 12",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, httr, performance)\n\nThe code chunk below imports multiple csv files in a specified folder and append them into a single tibble data frame.\n\nfolder_path &lt;- \"data/In-class_Ex12/aspatial\"\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^realis.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\nThe following code chunk converts values in Sale Date field from character to numerical date format, and - extracting resale and condominium transaction records.\n\ncondo_resale &lt;- realis_data %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %&gt;%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex12.html#loading-the-r-packages",
    "href": "In-class_Ex/In-class_Ex12.html#loading-the-r-packages",
    "title": "In Class exercise 12",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, httr, performance)\n\nThe code chunk below imports multiple csv files in a specified folder and append them into a single tibble data frame.\n\nfolder_path &lt;- \"data/In-class_Ex12/aspatial\"\nfile_list &lt;- list.files(path = folder_path, \n                        pattern = \"^realis.*\\\\.csv$\", \n                        full.names = TRUE)\n\nrealis_data &lt;- file_list %&gt;%\n  map_dfr(read_csv)\n\nThe following code chunk converts values in Sale Date field from character to numerical date format, and - extracting resale and condominium transaction records.\n\ncondo_resale &lt;- realis_data %&gt;%\n  mutate(`Sale Date` = dmy(`Sale Date`)) %&gt;%\n  filter(`Type of Sale` == \"Resale\" &\n           `Property Type` == \"Condominium\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex12.html#data-preparation",
    "href": "In-class_Ex/In-class_Ex12.html#data-preparation",
    "title": "In Class exercise 12",
    "section": "Data preparation",
    "text": "Data preparation\n\npostcode &lt;- unique(condo_resale$`Postal Code`)\n\n\nurl &lt;- \"https://onemap.gov.sg/api/common/elastic/search\"\nfound &lt;- data.frame()\nnot_found &lt;- data.frame()\n\nfor (postcode in postcode){\n  query &lt;- list('searchVal'=postcode, 'returnGeom'='Y', \n                'getAddrDetails'='Y', 'pageNum'='1')\n  res &lt;- GET(url, query=query)\n  if ((content(res)$found)!=0){\n    found &lt;- rbind(found, data.frame(content(res))[4:13])\n  } else {not_found = data.frame(postcode)\n  }\n}"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex12.html#tidying-up-field-names",
    "href": "In-class_Ex/In-class_Ex12.html#tidying-up-field-names",
    "title": "In Class exercise 12",
    "section": "Tidying up field names",
    "text": "Tidying up field names\n\nfound &lt;- found %&gt;%\n  select(c(6:8)) %&gt;%\n  rename(POSTAL = `results.POSTAL`,\n         XCOORD = `results.X`,\n         YCOORD = `results.Y`)\n\n\nwrite_rds(found, \"data/In-class_Ex12/found.rds\")\n\n\nfound &lt;- read_rds(\"data/In-class_Ex12/found.rds\")\n\nThe following chunk of code is to join condo_resale and found\n\ncondo_resale_geocoded = left_join(\n  condo_resale, found, \n  by = c('Postal Code' = 'POSTAL'))\n\nThe following chunk of code is to convert condo_resale_geocoded from tibble data frame to sf point feature data frame\n\ncondo_resale_sf &lt;- st_as_sf(condo_resale_geocoded, \n                            coords = c(\"XCOORD\",\n                                       \"YCOORD\"),\n                            crs=3414)\n\n\nCleaning spatial data\nThe code chunk below is used to check if there are overlapping point features.\n\noverlapping_points &lt;- condo_resale_sf %&gt;%\n  mutate(overlap = lengths(st_equals(., .)) &gt; 1)\n\nIn the code code chunk below, st_jitter() of sf package is used to move the point features by 5m to avoid overlapping point features.\n\ncondo_resale_sf &lt;- condo_resale_sf %&gt;%\n  st_jitter(amount = 2)"
  },
  {
    "objectID": "In-class_Ex/data/In-class_Ex04/Kepulauan_Bangka_Belitung.html",
    "href": "In-class_Ex/data/In-class_Ex04/Kepulauan_Bangka_Belitung.html",
    "title": "Brian’s IS415 Experience",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n       GEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],MEMBER[“World Geodetic System 1984 (G2139)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],CS[ellipsoidal,2],AXIS[“geodetic latitude (Lat)”,north,ORDER[1],ANGLEUNIT[“degree”,0.0174532925199433]],AXIS[“geodetic longitude (Lon)”,east,ORDER[2],ANGLEUNIT[“degree”,0.0174532925199433]],USAGE[SCOPE[“Horizontal component of 3D system.”],AREA[“World.”],BBOX[-90,-180,90,180]],ID[“EPSG”,4326]] +proj=longlat +datum=WGS84 +no_defs 3452 4326 EPSG:4326 WGS 84 longlat EPSG:7030 true"
  },
  {
    "objectID": "In-class_Ex/data/MasterPlan2019SubzoneBoundaryWebSHP/MPSZ-2019.html",
    "href": "In-class_Ex/data/MasterPlan2019SubzoneBoundaryWebSHP/MPSZ-2019.html",
    "title": "Brian’s IS415 Experience",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n        0 0     false"
  }
]