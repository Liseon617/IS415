---
title: "In Class exercise 6"
author: "Brian Lim"
date: "September 23, 2024"
date-modified: "last-modified"
categories:
  - Analysis
  - R
  - sf
  - tidyverse
format: html
editor: visual
execute: 
  eval: true
  echo: true
  warning: false
  freeze: true  
  cache: true
---

## **6.0 Notes:**

-   Local statistics

    -   Identifying outliers based on a certain attribute of its neighbours

    -   Tobler's First law of Geography: Everything is related to everything else, but near things are more related than distant things

-   Geospatial Dependency

    -   Spatial dependence is the spatial relationship of variable values (for themes defined over space, such as rainfall) or locations (for themes defined as objects, such as cities).

-   Spatial Autocorrelation

    -   Spatial autocorrelation is the term used to describe the presence of systematic spatial variation in a variable.
    -   Inferred after the rejections of the null hypothesis
    -   Positive autocorrelation: A big lump, congregation of points on the grid
    -   Negative autocorrelation: More outliers can be seen, checkers board pattern seen

-   Local Indicator of Spatial Analysis (LISA)

    -   A subset of localised geospatial statistics methods.

    -   Any spatial statistics that satisfies the following two requirements (Anselin, L. 1995):

        -   the LISA for each observation gives an indication of the extent of significant spatial clustering of similar values around that observation;

        -   the sum of LISAs for all observations is proportional to a global indicator of spatial association.

    -   Identify outliers or clusters

## **6.1 Installing and Loading the R packages**

For the purpose of this study, five R packages will be used. They are:

-   [**sf**](https://r-spatial.github.io/sf/), a relatively new R package specially designed to import, manage and process vector-based geospatial data in R.

-   [**spatstat**](https://spatstat.org/), a comprehensive package for point pattern analysis. We'll use it to perform first- and second-order spatial point pattern analyses and to derive kernel density estimation (KDE) layers.

-   [**sfdep**](https://cran.r-project.org/web/packages/sfdep/), an R package that acts as an interface to 'spdep' to integrate with 'sf' objects and the 'tidyverse'.

-   [**tidyverse**](https://cran.r-project.org/web/packages/tidyverse/index.html), a collection of R packages designed for data science. It includes packages like `dplyr` for data manipulation, `ggplot2` for data visualization, and `tidyr` for data tidying, all of which are essential for handling and analyzing data efficiently in a clean and consistent manner.

```{r}
pacman::p_load(sf, sfdep, tmap, tidyverse)
```

### **6.1.1 Import shapefile into r environment**

The code chunk below uses [*st_read()*](https://r-spatial.github.io/sf/reference/st_read.html) of **sf** package to import Hunan shapefile into R. The imported shapefile will be **simple features** Object of **sf**.

```{r}
hunan_sf <- st_read(dsn = "data/In-class_Ex05/geospatial", 
                 layer = "Hunan")
```

### **6.1.2 Import csv file into r environment**

Next, we will import *Hunan_2012.csv* into R by using *read_csv()* of **readr** package. The output is R dataframe class.

```{r}
hunan2012 <- read_csv("data/In-class_Ex05/aspatial/Hunan_2012.csv")
hunan2012
```

### **6.1.3 Performing relational join**

The code chunk below will be used to update the attribute table of *hunan*'s SpatialPolygonsDataFrame with the attribute fields of *hunan2012* data frame. This is performed by using *left_join()* of **dplyr** package.

```{r}
hunan_GDPPC <- left_join(hunan_sf,hunan2012)%>%
  select(1:4, 7, 15)
```

### **6.2 Plotting the chloropleth map**

#### **Deriving Queen's contiguity weights: sfdep methods**

```{r}
wm_q <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wt = st_weights(nb, style = "W"),
         .before = 1)
```

#### **Computing Global Moran's I**

```{r}
moranI <- global_moran(wm_q$GDPPC, wm_q$nb, wm_q$wt)
glimpse(moranI)
```

In general, Moran's I test will be performed instead of just computing the Moran's statistics. With sfdep package, Moran's I test can be performed by using `global_moran_test()` as shown in the code chunk below:

```{r}
global_moran_test(wm_q$GDPPC, wm_q$nb, wm_q$wt)
```

`Expectation: -0.011494253` negative value suggests clustering

p-value will determine whether the null hypothesis is rejected or not. Not rejecting the null hypothesis would result in the statistic derived from Moran I to be unusable

```{r}
global_moran_perm(wm_q$GDPPC, wm_q$nb, wm_q$wt, nsim=99)
```

As seen from the moran I statistic, even thought the p-value is far smaller, the statistic is stable, approaching `0.30075`

```{r}
set.seed(1234)
```

It is always good to `set.seed()` before performing simulation, to ensure reproducibility.

```{r}
lisa <- wm_q %>%
  mutate(local_moran = local_moran(
    GDPPC, nb, wt, nsim = 99),
    .before = 1) %>%
  unnest(local_moran)
```

To ensure consistency, stay with 1 type of p-value **either p_ii, p_ii_sim or p_folded_sim**

Mean useful if the data follows the trend of standard distribution and Median would be useful if skewness (close to 0) is detected - Note that row consistency also applies to mean or median - Examine the current trend of the skewness to make these decisions

```{r}
tmap_mode("plot")
tm_shape(lisa) + 
  tm_fill("ii") +
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(
    main.title = "local Moran's I of GDPPC",
    main.title.size = 1
  )
```

```{r}
tmap_mode("plot")
map1 <- tm_shape(lisa) + 
  tm_fill("ii") +
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(
    main.title = "local Moran's I of GDPPC",
    main.title.size = 1
  )

map2 <- tm_shape(lisa) + 
  tm_fill("p_ii", breaks = c(0, 0.001, 0.01, 0.05, 1),
          labels = c("0.001", "0.01", "0.05", "Not sig")) +
  tm_borders(alpha = 0.5) +
  tm_layout(
    main.title = "p-value of local Moran's I",
    main.title.size = 0.8
  )

tmap_arrange(map1, map2, ncol = 2)
```

#### Visualising LISA map

```{r}
lisa_sig <- lisa %>%
  filter(p_ii < 0.05)
tmap_mode("plot")
tm_shape(lisa) + 
  tm_polygons() +
  tm_borders(alpha = 0.5) +
tm_shape(lisa_sig) +
  tm_fill("mean") +
  tm_borders(alpha = 0.4)
```

LISA map is categorical map showing outliers and clusters. There are two types of outliers namely: High-Low and Low-High outliers. Likewise, there are two types of clusters namely: High-High and Low-Low

#### Computing local Gi\* statistics

As usual we will need to derive a spatial weight matrix before we can compute local Gi\* statistics. Code chunk below will be used to derive a spatial weight matrix by using sfdep functions and tidyverse approach.

```{r}
wm_idw <- hunan_GDPPC %>%
  mutate(nb = st_contiguity(geometry),
         wts = st_inverse_distance(nb, geometry,
                                   scale = 1,
                                   alpha = 1),
         .before = 1)
```

Calculating the local Gi\* by using the code chunk below:

```{r}
HCSA <- wm_idw %>% 
  mutate(local_Gi = local_gstar_perm(
    GDPPC, nb, wt, nsim = 99),
         .before = 1) %>%
  unnest(local_Gi)
HCSA
```

#### Visualising hot spot and cold spot areas

```{r}
#| code-fold: true
#| code-summary: "Show the code"
tmap_mode("plot")
map1 <- tm_shape(HCSA) +
  tm_fill("gi_star") + 
  tm_borders(alpha = 0.5) +
  tm_view(set.zoom.limits = c(6,8)) +
  tm_layout(main.title = "Gi* of GDPPC",
            main.title.size = 0.8)

map2 <- tm_shape(HCSA) +
  tm_fill("p_value",
          breaks = c(0, 0.001, 0.01, 0.05, 1),
              labels = c("0.001", "0.01", "0.05", "Not sig")) + 
  tm_borders(alpha = 0.5) +
  tm_layout(main.title = "p-value of Gi*",
            main.title.size = 0.8)

tmap_arrange(map1, map2, ncol = 2)
```

```{r}
HCSA_sig <- HCSA %>% 
  filter(p_sim < 0.05)
tmap_mode("plot")
tm_shape(HCSA) +
  tm_polygons() +
  tm_borders(alpha = 0.5) +
  tm_shape(HCSA_sig) +
  tm_fill("gi_star") +
  tm_borders(alpha = 0.4)
```
